[
  {
    "post": {
      "id": "7220d09a92c80c16106ef31ff2d2abca",
      "source_id": "46946464",
      "title": "Ask HN: Do provisional patents matter for early-stage startups?",
      "content": {
        "text": "<div class=\"toptext\" style=\"margin-top:4px\">I am a solo founder building in AI B2B infra.<p>I am filing provisional patents on some core technical approaches so I can share more openly with early design partners and investors.<p>Curious from folks who have raised Pre-Seed/Seed or worked with early-stage companies:\n- Do provisionals meaningfully help in fundraising or partnerships?\n- Or were they mostly noise until later rounds / real traction?<p>I am trying to calibrate how much time/energy to put into IP vs just shipping + user traction at this stage.<p>Would love to hear real world experiences.</p></p></p></p></div>",
        "format": "html",
        "media": []
      },
      "created_at": "2026-02-09T16:18:30.197737",
      "updated_at": "2026-02-09T16:18:30.197737",
      "category": {
        "id": "f31af88693e43c7e98a65941d54a8cd6",
        "name": "Ask HN"
      },
      "tags": [
        "Ask HN",
        "hacker news",
        "tech"
      ],
      "author": {
        "id": "82056ca419d805a1eeb635e1bd0019b5",
        "source_id": "gdad",
        "username": "gdad",
        "avatar": "",
        "role": "user",
        "signature": ""
      },
      "stats": {
        "views": 0,
        "likes": 3,
        "dislikes": 0,
        "replies": 0,
        "shares": 0
      }
    },
    "source": {
      "forum": "hackernews",
      "url": "https://news.ycombinator.com/item?id=46946464",
      "section": "Ask HN"
    },
    "replies": [
      {
        "id": "e3766f016299a2d421b5e5212bc43c19",
        "source_id": "46946799",
        "content": {
          "text": "From what I have seen, early investors care far more about speed, adoption, and clarity of problem than provisionals. Patents help later, but at pre-seed/seed they rarely change a decision unless IP is the product. Shipping and learning usually wins. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:32.235675",
        "updated_at": "2026-02-09T16:18:32.235675",
        "author": {
          "id": "2cd653acb0f63ece1e126a7e0c08b41d",
          "source_id": "allinonetools_",
          "username": "allinonetools_",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      }
    ],
    "metadata": {
      "crawled_at": "2026-02-09T16:18:32.235819",
      "language": "en-US",
      "keywords": [
        "tech",
        "startup",
        "programming",
        "ask",
        "question"
      ],
      "is_nsfw": false
    }
  },
  {
    "post": {
      "id": "d64e76974718ebe6404f7a0ffc38b0ea",
      "source_id": "46937696",
      "title": "Ask HN: What are you working on? (February 2026)",
      "content": {
        "text": "<div class=\"toptext\" style=\"margin-top:4px\">What are you working on?  Any new ideas that you're thinking about?</div>",
        "format": "html",
        "media": []
      },
      "created_at": "2026-02-09T16:18:30.198485",
      "updated_at": "2026-02-09T16:18:30.198485",
      "category": {
        "id": "f31af88693e43c7e98a65941d54a8cd6",
        "name": "Ask HN"
      },
      "tags": [
        "Ask HN",
        "hacker news",
        "tech"
      ],
      "author": {
        "id": "bec7335d8f4973f3cc1886331a825dda",
        "source_id": "david927",
        "username": "david927",
        "avatar": "",
        "role": "user",
        "signature": ""
      },
      "stats": {
        "views": 0,
        "likes": 207,
        "dislikes": 0,
        "replies": 0,
        "shares": 0
      }
    },
    "source": {
      "forum": "hackernews",
      "url": "https://news.ycombinator.com/item?id=46937696",
      "section": "Ask HN"
    },
    "replies": [
      {
        "id": "821179858802b4afcfb5f444efcf63ce",
        "source_id": "46946866",
        "content": {
          "text": "A simple HN-like web app that indexes security (and security adjacent) write-ups. Imagine you, as a security researcher (or any other persona in the security field), wanted to see what prior works are available around bypassing v8 sandbox using webasm, or if what’s been done or found targeting deserialization in Go. Using this web app, you can search the indexed and tagged write ups. Also adding MCP support to it so your agents can search too. Hopefully going live soon. P.S: I said HN-like, but tbh it’s just the UI that looks a bit like HN (I’m not a good designer, so got heavy inspiration from HN listing style), otherwise there’s no other overlap in functionality yet. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.289845",
        "updated_at": "2026-02-09T16:18:36.289845",
        "author": {
          "id": "f6d514f698a1f0adc654bd89e0a64e64",
          "source_id": "Goofy_Coyote",
          "username": "Goofy_Coyote",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "1bdcd4ba56f20ea39fc53cd0ed09a0d8",
        "source_id": "46946868",
        "content": {
          "text": "Cross-platform book management and reading application: https://github.com/Eoic/Papyrus . This isn't a serious project by any means, but rather a prototype. Also, I really got carried away using Claude Code, although my initial goal was simply to glue a quick proof-of-concept and see how it could look like. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.290452",
        "updated_at": "2026-02-09T16:18:36.290452",
        "author": {
          "id": "3a54209dd480100f0033256b4b3c5552",
          "source_id": "ZpJuUuNaQ5",
          "username": "ZpJuUuNaQ5",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "cadd6fd2a8ae440f2e13e0d76985b018",
        "source_id": "46945142",
        "content": {
          "text": "I'm a solo dev building a handful of apps across different niches.. - Kvile ( https://kvile.app ) — A lightweight desktop HTTP client built with Rust + Tauri. Native .http file support (JetBrains/VS Code/Kulala compatible), Monaco editor, JS pre/post scripts, SQLite-backed history. Sub-second startup. MIT licensed, no cloud, your requests stay on your machine. Think Postman without the bloat and login walls. - Mockingjay ( https://apps.apple.com/us/app/mockingjay-secure-recorder/id6... ) — iOS app that records video and streams AES-256-GCM encrypted chunks to your Google Drive in real-time. By the time someone takes your phone, the footage is already safe in the cloud. Built for journalists, activists, and anyone who needs tamper-proof evidence. Features a duress PIN that wipes local keys while preserving cloud backups, and a fake sleep mode that makes the phone look powered off during recording. - Stao ( https://stao.app ) — A simple sit/stand reminder for standing desk users. Runs in the system tray, tracks your streaks, zero setup. Available on macOS, Windows, Linux, iOS, and Android. - MyVisualRoutine ( https://myvisualroutine.com ) — This one is personal. I have three kids, two with severe disabilities. Visual schedules (laminated cards, velcro boards) are a lifeline for non-verbal children, but they're a nightmare to manage and they don't leave the house. So I built an app that lets you create a full visual routine in about 20 seconds and take it anywhere. Choice boards, First/Then boards, day  plans, 50+ preloaded activities, works fully offline. Free tier is genuinely usable. Available on iOS and Android. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.291161",
        "updated_at": "2026-02-09T16:18:36.291161",
        "author": {
          "id": "6f1bc3015cc493f1f8ae3bbc4c26d9a6",
          "source_id": "tskulbru",
          "username": "tskulbru",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "d67f9e50fa11fdb61d29bcc52339f2c2",
        "source_id": "46945485",
        "content": {
          "text": "Really neat!  Also as a Linux user, I deeply appreciate the linux support :-) A few questions and comments: | Kvile | - Awesome, really happy to see a reasonable take on this (open source, offline-first, no telemetry, no acount, etc).  Do you think at some point you'll try to monetize it in some way? - Looks like build assets didn't get attached for the latest release (v0.2.1) in Github: https://github.com/tskulbru/kvile/releases/tag/kvile-v0.2.1 | Mockingjay | - Awesome, definitely a valuable project.  I'll be sharing this with some friends who could really use this. | Stao | - The website says it's open source, but I couldn't find a link to the source repo.  I looked at your github repos and didn't see it in there either. - Great idea!  I'm so bad about forgetting to stand so something like this could be super useful. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.291868",
        "updated_at": "2026-02-09T16:18:36.291868",
        "author": {
          "id": "4865f683392ba90a9ced02c11af20a25",
          "source_id": "freedomben",
          "username": "freedomben",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "6253800cff1c108085954bff61a84a57",
        "source_id": "46946439",
        "content": {
          "text": "I love the idea behind MyVisualRoutine as a father with a disabled kiddo, thanks for sharing. The app is beautiful - much better than I could build - what tech is it using if you don't mind me asking? Is it flutter, react native, something else? Just want to get better at mobile dev. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.292488",
        "updated_at": "2026-02-09T16:18:36.292488",
        "author": {
          "id": "061c90c3d42a550b68a08320b95eee2a",
          "source_id": "faxmeyourcode",
          "username": "faxmeyourcode",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "f7f6490e14d71d678e36a277082bc609",
        "source_id": "46946420",
        "content": {
          "text": "> and a fake sleep mode that makes the phone look powered off during recording. That's going to be used for recording women in public. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.293158",
        "updated_at": "2026-02-09T16:18:36.293158",
        "author": {
          "id": "2d4b3413078f17832ceeb21b1bc1a450",
          "source_id": "delusional",
          "username": "delusional",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "3fb32eaf7c754e0551ca9d8c826f7960",
        "source_id": "46943648",
        "content": {
          "text": "I've been working with my wife on Uruky [1] for a couple of months, now. It's a EU-based Kagi [2] alternative (privacy-focused and ad-free search with domain boosting/exclusion rules). We've been using it with friends and family semi-successfully (hashbangs work for edge cases we're still working on). It's really difficult to get bigger indexes other than Mojeek and Marginalia to want to work with us and improve the results further, so that's something I've been researching more, lately. EUSP (the new Ecosia/Qwant-effort-related index) has finally replied to me last week, but I'm still waiting on an API key. If you're interested in trying it for a few days and are a human, reach out with your account number and I'll give you a couple of weeks for free. We're pushing improvements daily. [1] https://uruky.com [2] https://kagi.com P. S. It's weird to see this duplicate (posted less than a week ago in https://news.ycombinator.com/item?id=46874385 ), but this post has a lot more comments! reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.293969",
        "updated_at": "2026-02-09T16:18:36.293969",
        "author": {
          "id": "f202cf58148469b2848db50a7d14ae51",
          "source_id": "BrunoBernardino",
          "username": "BrunoBernardino",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "d773e4ba99390c3f34659c003ff604ee",
        "source_id": "46945505",
        "content": {
          "text": "Eventual source code access is an interesting idea. \nWhat language is Uruky implemented in? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.294642",
        "updated_at": "2026-02-09T16:18:36.294642",
        "author": {
          "id": "5f76419f1a4ca4425b663408f8d87f3c",
          "source_id": "chokma",
          "username": "chokma",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "0c17bd29546ca2624106bf115297951b",
        "source_id": "46945557",
        "content": {
          "text": "Thanks! It's intentionally very \"boring\" (as in, it generates and serves the HTML + bits of JS to enhance settings and such), using Deno in the backend and PostgreSQL for the DB. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.295375",
        "updated_at": "2026-02-09T16:18:36.295375",
        "author": {
          "id": "f202cf58148469b2848db50a7d14ae51",
          "source_id": "BrunoBernardino",
          "username": "BrunoBernardino",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "f4a1fa823e5fc99a1f83e09fec8eadd7",
        "source_id": "46944257",
        "content": {
          "text": "Hi HN, I am working on Circuitscript, a language based on python to describe electronic schematics: https://circuitscript.net/ . A basic IDE (called the Bench) to try Circuitscript is available online: https://bench.circuitscript.net/ I have created a usb-uart converter board with the CH340 chip. The complete schematic was coded with Circuitscript and then imported as a netlist into kicad pcbnew to do the pcb layout. The design was produced with JLCPCB and after receiving the boards I tested them and they do work! The design files are here https://github.com/liu3hao/usb-uart-bridge . The circuitscript code file is here https://raw.githubusercontent.com/liu3hao/usb-uart-bridge/re... and the generated pdf from the circuitscript code is here: https://github.com/liu3hao/usb-uart-bridge/blob/main/usb_uar... The motivation for creating Circuitscript is to describe schematics in terms of code rather than graphical UIs after using different CAD packages extensively (Allegro, Altium, KiCAD) for work in the past. I wanted to spend more time thinking about the schematic design itself rather than fiddling around with GUIs. Please check it out and I look forward to your feedback, especially from electronics designers/hobbyists. Thanks! reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.296292",
        "updated_at": "2026-02-09T16:18:36.296292",
        "author": {
          "id": "18cd304f8a2c3358dfa5953b4daab753",
          "source_id": "liu3hao",
          "username": "liu3hao",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "58692395f12c5d027b25519849990b7a",
        "source_id": "46944460",
        "content": {
          "text": "This looks awesome, great job. How effective at circuit generation are LLM's with the language? I tried similar, and could get syntactically correct files, but the content always had errors: https://www.mikeayles.com/#tokn What are your thoughts on atopile and tscircuit? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.297121",
        "updated_at": "2026-02-09T16:18:36.297121",
        "author": {
          "id": "bd6ca78cf41e5bc4c3aeb9d00fbe0a56",
          "source_id": "mikeayles",
          "username": "mikeayles",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "a71af4c67538e2923720049af46b3ccc",
        "source_id": "46941213",
        "content": {
          "text": "https://sampler.meiji.industries/ I built a TUI sampler which cherry-picks my favourite features from modern & vintage hardware samplers, DAWs, plugins, outboard FX gear, and DJ equipment. If you know what an AKAI MPC Live, MPC 3000, SP404, SP1200, BOSS RC-202, Alesis 3630, Serato Sample, S950 filters, and stem separation does, then you'll love seeing these \"greatest hits\" up in a terminal interface. Last year while on vacation in Costa Rica, I started scratching my own itch for locating and organizing samples, which quickly evolved into adding more and more features while keeping it tactile and immediate.  It was too fun to stop so I kept going.  After a few days I was happily making beats in it, and since then it's only gotten better. It's live and totally free to use, and works in macos & Linux (Windows soon). I'm about to launch v1.0 now, just working with folks in the community to round out the Factory Kits a little more for users new to beatmaking. Turns out, making beats with no mouse and a terminal interface strikes the perfect balance of hardware feel and software power, and I'm loving the result.  Been sharing it with folks in my beatmaking sphere and have plans to continue expanding its reach through more collaborations, contests, and in-person events. Hope it brings you as much joy as it does to me :) reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.298028",
        "updated_at": "2026-02-09T16:18:36.298028",
        "author": {
          "id": "6fef34459b55067da3cf74676e798eb1",
          "source_id": "AdamMeghji",
          "username": "AdamMeghji",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "4ea5cfc3ba72e3b5ae89efb9841e0991",
        "source_id": "46942945",
        "content": {
          "text": "I love working on the terminal and this looks great, but can I ask why do you require to sign in? To be that's a bit of a downer :( reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.298870",
        "updated_at": "2026-02-09T16:18:36.298870",
        "author": {
          "id": "566ebd3df7d5e80eec6c0c1ff92fbb79",
          "source_id": "discoinverno",
          "username": "discoinverno",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "3541c19ee90c92f416256cc377f0f2ea",
        "source_id": "46944681",
        "content": {
          "text": "totally fair point! the medium/long-term roadmap is to layer in a BBS-esque community, so identity is required. more on this later!  regardless, might be nice to have an unauthenticated / \"Skip sign in\" flow for the folks who just want to use the tool. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.299762",
        "updated_at": "2026-02-09T16:18:36.299762",
        "author": {
          "id": "6fef34459b55067da3cf74676e798eb1",
          "source_id": "AdamMeghji",
          "username": "AdamMeghji",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "beb576e29baf566d978cbcc8bee1d87a",
        "source_id": "46943356",
        "content": {
          "text": "Looks very promising! Unfortunately Docs and GitHub repo don‘t work reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.300659",
        "updated_at": "2026-02-09T16:18:36.300659",
        "author": {
          "id": "6e2f55121d6c9e62314c43a61b3d62bb",
          "source_id": "hilti",
          "username": "hilti",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "91251fd7d3d5c378939fed66e0541b4b",
        "source_id": "46944693",
        "content": {
          "text": "apologies, those broken links are misleading (docs coming soon, but not open source atm).  Removed. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.301619",
        "updated_at": "2026-02-09T16:18:36.301619",
        "author": {
          "id": "6fef34459b55067da3cf74676e798eb1",
          "source_id": "AdamMeghji",
          "username": "AdamMeghji",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "f3178cc829ea352685a5bfa616fe6538",
        "source_id": "46941436",
        "content": {
          "text": "Was this previously open source? There's a broken link to a repo at the bottom of the marketing page that results in a 404. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.302599",
        "updated_at": "2026-02-09T16:18:36.302599",
        "author": {
          "id": "00d15f9971d3dcefc43181ebe62c8ec1",
          "source_id": "aoyama1chome",
          "username": "aoyama1chome",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "8b9311d8eec1db348f3fbb2b55a5ef30",
        "source_id": "46944702",
        "content": {
          "text": "it was not, so that's a mistake that's been fixed, thanks! reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.303615",
        "updated_at": "2026-02-09T16:18:36.303615",
        "author": {
          "id": "6fef34459b55067da3cf74676e798eb1",
          "source_id": "AdamMeghji",
          "username": "AdamMeghji",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "9f0707fabe171a3fb28debd379f4390b",
        "source_id": "46941343",
        "content": {
          "text": "Great intro video! reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.304654",
        "updated_at": "2026-02-09T16:18:36.304654",
        "author": {
          "id": "1ba51ff6492f2c34025ef0f554acb527",
          "source_id": "nedwin",
          "username": "nedwin",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "fe7fc1b69a0a0f387a08fb12e4158542",
        "source_id": "46942779",
        "content": {
          "text": "This is sick, great job! reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.305728",
        "updated_at": "2026-02-09T16:18:36.305728",
        "author": {
          "id": "ad44150ebab512ff5ea280253958c561",
          "source_id": "s3tt3mbr1n1",
          "username": "s3tt3mbr1n1",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "21835b91ebdc3addfdf34dca628a552d",
        "source_id": "46943780",
        "content": {
          "text": "TUI triggered me, so I had to take a look... It appears the GitHub link on your landing page is 404? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.306820",
        "updated_at": "2026-02-09T16:18:36.306820",
        "author": {
          "id": "bf564de0727e317cc00d30682af80ff0",
          "source_id": "lynx97",
          "username": "lynx97",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "62a85c1fa7131f572fa4f92ec3be7bc9",
        "source_id": "46943353",
        "content": {
          "text": "Very cool! reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.307933",
        "updated_at": "2026-02-09T16:18:36.307933",
        "author": {
          "id": "f00cd7ac4017d20661b83f83637c9e9e",
          "source_id": "strobby",
          "username": "strobby",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "49d720b383aa0d3e3ef901122aaba738",
        "source_id": "46942699",
        "content": {
          "text": "here goes my Monday reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.309074",
        "updated_at": "2026-02-09T16:18:36.309074",
        "author": {
          "id": "4a0617291080208e7d05441c768cfab0",
          "source_id": "lmf4lol",
          "username": "lmf4lol",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "054cc0586882680a1053028792000479",
        "source_id": "46944276",
        "content": {
          "text": "https://instagit.com I’ve been shipping AI-written code for 2 years now. I can build something amazing in 40 mins but then spend 4+ hours debugging because the agent has no idea how the libraries it’s calling actually work. Docs are stale, StackOverflow is dead, training data is outdated. Every engineer I talk to has the same problem. So I built Instagit, an MCP server that lets your coding agent understand any GitHub repo in depth so it can get it right on the first try. Works with Claude Code, Codex, Cursor, OpenClaw, etc. No API key or account needed to try it out. Just need to share these instructions with your coding agent to get started: curl -s https://instagit.com/install.md reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.310329",
        "updated_at": "2026-02-09T16:18:36.310329",
        "author": {
          "id": "97afb52a539def2a37342b8b26a76a17",
          "source_id": "instalabsai",
          "username": "instalabsai",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "cf8608c6229377f1c9a87c0b8fffdc3a",
        "source_id": "46944747",
        "content": {
          "text": "Interesting! How does it work under the hood? If you can share. Would like to understand if this improves my Claude Code's understanding of my codebase. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.311530",
        "updated_at": "2026-02-09T16:18:36.311530",
        "author": {
          "id": "3fbc0d45f6514205a446a9dbfe910236",
          "source_id": "morgengold",
          "username": "morgengold",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "5e966db8e15048284853b6171f9f489d",
        "source_id": "46945063",
        "content": {
          "text": "It’s basically scanning the source code for each question (you can also check out specific branches or release tags if you need to debug a particular version) and then writes up the answer once it finds it. It’s not really meant to query your own code base (Claude Code already does a great job at that) but more to explore other code bases you want to integrate with. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.312806",
        "updated_at": "2026-02-09T16:18:36.312806",
        "author": {
          "id": "97afb52a539def2a37342b8b26a76a17",
          "source_id": "instalabsai",
          "username": "instalabsai",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "f0692fac5fc5e6457f702fe6031aff42",
        "source_id": "46944892",
        "content": {
          "text": "Why not context 7? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.314094",
        "updated_at": "2026-02-09T16:18:36.314094",
        "author": {
          "id": "84e4f62f6eea165f45d52badc43fc57e",
          "source_id": "unsaved159",
          "username": "unsaved159",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "7178a470fe0c9e810671579759b5bedd",
        "source_id": "46945032",
        "content": {
          "text": "Context7 is great but ultimately it’s just a pre-generated static summarization that might not include the specific answers the agent needs. I have a slightly different approach where the actual source code is scanned for each question so it’s much more targeted and never out of date. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.315379",
        "updated_at": "2026-02-09T16:18:36.315379",
        "author": {
          "id": "97afb52a539def2a37342b8b26a76a17",
          "source_id": "instalabsai",
          "username": "instalabsai",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "61cd778621a3070f7465633ded822086",
        "source_id": "46944344",
        "content": {
          "text": "hey irrelevant question, what tools you use to make such great landing pages for your products? your instagit.com looks great, what's your vibe coding workflow? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.316703",
        "updated_at": "2026-02-09T16:18:36.316703",
        "author": {
          "id": "21176d9379a28f2b6185f7e5c16c5312",
          "source_id": "vishnu2ko4",
          "username": "vishnu2ko4",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "6f0db9a1fbd54c41bc1f76b2486f6921",
        "source_id": "46944542",
        "content": {
          "text": "Thanks! No fancy tooling, I made it by just prompting Claude Code with the \"frontend-design\" skill from Anthropic: https://skillsmp.com/skills/anthropics-skills-skills-fronten... reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.318062",
        "updated_at": "2026-02-09T16:18:36.318062",
        "author": {
          "id": "97afb52a539def2a37342b8b26a76a17",
          "source_id": "instalabsai",
          "username": "instalabsai",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "173da6e3c1e7a87731a6c4917a3dbae3",
        "source_id": "46945160",
        "content": {
          "text": "Any promoting tips for this sort of result? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.319436",
        "updated_at": "2026-02-09T16:18:36.319436",
        "author": {
          "id": "7db44ab450b1efbba9b80ff0305fa5c0",
          "source_id": "cpursley",
          "username": "cpursley",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "d6dd80d92f0b084d2ba9cb9095593ed4",
        "source_id": "46945344",
        "content": {
          "text": "Sure, here are a few tips: - Use a static website generator (I use Astro but there are others) where the agent can fully control every aspect of the website - Use skills to enhance the prompting, like this frontend-design one but can also combine it with copy writing/seo skills etc - Give the agent control access to the browser to give it visibility into the result in order to iteratively improve upon it - The last thing is to just be very demanding and setting a high bar, so ask for animations and ask the agent over and over again “ok and now let’s improve what you just did” reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.320955",
        "updated_at": "2026-02-09T16:18:36.320955",
        "author": {
          "id": "97afb52a539def2a37342b8b26a76a17",
          "source_id": "instalabsai",
          "username": "instalabsai",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "76ce2570f8e8a659898e44fc2172f360",
        "source_id": "46941915",
        "content": {
          "text": "https://github.com/jsattler/BetterCapture It's a lightweight screen recorder for macOS that lives in your menu bar. It's built with SwiftUI and ScreenCaptureKit, uses the native Content Picker to select what you record, and supports ProRes 422/4444, HEVC, and H.264 — including alpha channel and HDR. Frame rates from 24 to 120fps. System audio and mic simultaneously. You can also exclude specific things from recordings, like the menu bar, dock, or wallpaper. No tracking, no analytics, no cloud uploads, no account. MIT licensed. Everything stays on your Mac. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.322431",
        "updated_at": "2026-02-09T16:18:36.322431",
        "author": {
          "id": "932469948220b24a3554b251345ec287",
          "source_id": "jsattler",
          "username": "jsattler",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "866ee98ea767b72a0e88e4f47b2a5a08",
        "source_id": "46946519",
        "content": {
          "text": "Looks really sharp! I've been on the lookout for a new screen cap tool for Mac and this looks great, bookmarked. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.323898",
        "updated_at": "2026-02-09T16:18:36.323898",
        "author": {
          "id": "1cc7c015628023b4b1cba3b7546cc069",
          "source_id": "SunshineTheCat",
          "username": "SunshineTheCat",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "0b6d67565038aeb92ca7225e62ec149f",
        "source_id": "46946828",
        "content": {
          "text": "Thanks, really appreciate the feedback! reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.325389",
        "updated_at": "2026-02-09T16:18:36.325389",
        "author": {
          "id": "932469948220b24a3554b251345ec287",
          "source_id": "jsattler",
          "username": "jsattler",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "dc5bfb1e275f55d8c17ae9af769b1290",
        "source_id": "46940392",
        "content": {
          "text": "A Jellyfin music client for Linux written in Rust and GTK: https://github.com/Fingel/gelly I thought it would be pretty simple, but here I am almost 6 months later still adding features. The positive feedback has been nice, though! People seem to appreciate (like I do) that its fast and doesn't use Electron or some other cross platform toolkit. Learning a lot. It's not vibe coded. Sad that I have to make that qualification these days, but here we are. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.327032",
        "updated_at": "2026-02-09T16:18:36.327032",
        "author": {
          "id": "46ab4e808b3cdc1cf08edb8040834947",
          "source_id": "WD-42",
          "username": "WD-42",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "520a5d598326022808134ee37b9b61a0",
        "source_id": "46946649",
        "content": {
          "text": "I think you can still make the distinction of vibe coded vs using LLM for specific things(like review your code and write tests). Vibe coding signifies a lack of control over one's own code and generally only if it's to generate ideas or throwaway. The negative connotation that goes with it is appropriate too. In reality any project that takes 6 months means your have invested a lot of time thinking about the code, in which case LLMs become more useful for the things you care about e.g. maintainability, forcing LLMs to bend to your will, which is like saying: \" I know this design is the best so just make this instead of whatever abstraction you think is better\". reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.328611",
        "updated_at": "2026-02-09T16:18:36.328611",
        "author": {
          "id": "56a36ef8ca96617e0c8c8bc647c754b8",
          "source_id": "ghm2199",
          "username": "ghm2199",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "95b0a9dc400828b70329bfa6df38e390",
        "source_id": "46946863",
        "content": {
          "text": "Yes to be clear what I meant was that it’s not a prompt engineered project. I actually, for the most part, understand the code I’ve written :p I have used LLMs to understand certain concepts and unfamiliar APIs. Gtk and Rust is actually a pretty funky combo. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.330205",
        "updated_at": "2026-02-09T16:18:36.330205",
        "author": {
          "id": "46ab4e808b3cdc1cf08edb8040834947",
          "source_id": "WD-42",
          "username": "WD-42",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "f36bcf2ba98af98928b031c552f873c9",
        "source_id": "46946513",
        "content": {
          "text": "Very nice, ran well in a VM on my home NAS. I've always noodled about this marketplace idea where an optimization algorithm could match your interests and a dollar amount you can afford to let you rent/buy artist's music. The optimization would maximize the purchase of the differently valued music(analogus to the weighted  knapsack problem but this could have multiple solutions, knapsack is a nice way of thinking about it logically, in reality implementation may be completely different) based only on your interests, like history and dollars u have. I am wondering how might one apply a distributed systems approach without having music pirated and shotgunned all across the internet? Like how would you quickly match a person to all the available music metadata? How would you model for interest matching if the music library is spread out across multiple nodes. I would imagine a lot of people are ok with paying 5-10$ a month instead of 15-20$ for music they like from a set of artists they like. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.331844",
        "updated_at": "2026-02-09T16:18:36.331844",
        "author": {
          "id": "56a36ef8ca96617e0c8c8bc647c754b8",
          "source_id": "ghm2199",
          "username": "ghm2199",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "e6949b0e31725c1743b2267b92879098",
        "source_id": "46943502",
        "content": {
          "text": "Does GTK work for your use case therein? Does the documentation work for you? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.333485",
        "updated_at": "2026-02-09T16:18:36.333485",
        "author": {
          "id": "ec23afae3692d2ddf474121bf1d14869",
          "source_id": "shevy-java",
          "username": "shevy-java",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "e4af68cac0bee92f0f46b110d3dde03f",
        "source_id": "46941961",
        "content": {
          "text": "This is pretty darn awesome. I haven’t checked it out yet, but I’m already psyched about it. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.335168",
        "updated_at": "2026-02-09T16:18:36.335168",
        "author": {
          "id": "21dcb5f51b9e4932a186cba60369b3bf",
          "source_id": "winter_blue",
          "username": "winter_blue",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "734b3c62174347aae8c3cc6cfb667d2d",
        "source_id": "46944054",
        "content": {
          "text": "Looks incredible, well done reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.336878",
        "updated_at": "2026-02-09T16:18:36.336878",
        "author": {
          "id": "8939994858a241507fdc7279e8867a72",
          "source_id": "HugoTea",
          "username": "HugoTea",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "beda41c4f8a53d8bf29566a591fe8712",
        "source_id": "46940883",
        "content": {
          "text": "This is awesome, gonna check it out. Thanks! Helpful to look at a big rust project too as I’m learning rust. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.338588",
        "updated_at": "2026-02-09T16:18:36.338588",
        "author": {
          "id": "5a8ecfb61e053d3d72b819be9d49e942",
          "source_id": "ryan_n",
          "username": "ryan_n",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "3f90546562da75ce1b83f0c338be6222",
        "source_id": "46941783",
        "content": {
          "text": "This is cool but who owns music collection these days? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.340339",
        "updated_at": "2026-02-09T16:18:36.340339",
        "author": {
          "id": "81829e0eee1a28655e6242d0fe0aeb2d",
          "source_id": "quaintdev",
          "username": "quaintdev",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "52b1ba88367cb250335165c021202a47",
        "source_id": "46944353",
        "content": {
          "text": "Definitely more common to just use streaming services like Spotify, but some people do own their music library. There’s probably a decent sized overlap of those who buy music and those who self host things like jellyfin reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.342231",
        "updated_at": "2026-02-09T16:18:36.342231",
        "author": {
          "id": "5a8ecfb61e053d3d72b819be9d49e942",
          "source_id": "ryan_n",
          "username": "ryan_n",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "44effc423d22c86912be4514103fa290",
        "source_id": "46944050",
        "content": {
          "text": "I do, I buy albums on Bandcamp, rip my CDs, and as a last report buy MP3s on Amazon, which are surprisingly DRM free. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.344059",
        "updated_at": "2026-02-09T16:18:36.344059",
        "author": {
          "id": "8939994858a241507fdc7279e8867a72",
          "source_id": "HugoTea",
          "username": "HugoTea",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "a4f6629338b586b079f076d506840cc0",
        "source_id": "46940693",
        "content": {
          "text": "Nice, thanks! I’ve been looking for a decent alternative to PlexAmp for Jellyfin. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.345901",
        "updated_at": "2026-02-09T16:18:36.345901",
        "author": {
          "id": "b845af5eacb4e98601c83a2d29ec712e",
          "source_id": "meeb",
          "username": "meeb",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "9423f5e849647fbc97d0ec45ee74e7ef",
        "source_id": "46940970",
        "content": {
          "text": "curious about not vibe coded, is it because you wanted to learn? or some thing else as well? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.347778",
        "updated_at": "2026-02-09T16:18:36.347778",
        "author": {
          "id": "2646b0205139bbb333ad36ceaa196fa9",
          "source_id": "animeshjain",
          "username": "animeshjain",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "218ffae247c5fc41a12e99a90b2039cf",
        "source_id": "46943055",
        "content": {
          "text": "Maybe they care about it being robust in the long run, maintainable, secure and/or not too bloated. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.349666",
        "updated_at": "2026-02-09T16:18:36.349666",
        "author": {
          "id": "cecb7c12a09c740158d78fdaec3ea1db",
          "source_id": "me_bx",
          "username": "me_bx",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "c78769e9e1cd5c42a68fa1d4bbe1a23f",
        "source_id": "46944341",
        "content": {
          "text": "Pretty much. I plan on using this program for a long time. I don’t want a codebase that looks like something out of a H.P. Lovecraft novel when I have to fix something in the future. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.351603",
        "updated_at": "2026-02-09T16:18:36.351603",
        "author": {
          "id": "46ab4e808b3cdc1cf08edb8040834947",
          "source_id": "WD-42",
          "username": "WD-42",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "6c4e34e679375b8d962d4e1d5b78bc00",
        "source_id": "46944828",
        "content": {
          "text": "Here's an analysis of your codebase by Claude Opus 4.6 and Kimi 2.5 -- I don't code in Rust or GTK so I can't vouch for how spot on this is but I hope it's not too far off the mark and helps you improve your code. (Claude is wrapping both analyses together.) Strong agreement                                                                                                                                                                                                             \n                                                                                                                                                                                                                               \n  - Panicking error handling — both flag unwrap()/expect() on fallible operations (secrets, HTTP client, GStreamer). Kimi specifically calls out get_stream_uri returning String instead of Result, which I missed — good      \n  catch.                                                                                                                                                                                                                       \n  - Excessive cloning — both note the Jellyfin client and string cloning. Kimi's phrasing (\"host.to_string() on every request construction\") is more specific than mine.\n  - Application struct overloaded — both agree it holds too many responsibilities. Kimi suggests splitting into LibraryService, PlaybackService, etc. I focused more on the RefCell exposure.\n  - Silent error suppression — both flag let _ = sender.send(...) and unwrap_or_default() patterns.\n  - Code duplication in UI — both identify the repetitive list/detail/sorter patterns. Kimi specifically calls out call_on_visible_page widget comparisons, which I grouped under the broader \"5+ copies of factory setup\"\n  observation.\n  - Missing HTTP timeouts — Kimi flags this explicitly. I noted it indirectly via the buffer_unordered without timeout, but Kimi is clearer.\n\n  Things Kimi caught that I didn't emphasise\n\n  - get_stream_uri returning String instead of Result — a genuine API design issue I glossed over.\n  - String-based signal names being error-prone with no compile-time checking — fair point, though it's idiomatic GTK4/Rust.\n  - glycin potentially unused — I didn't check dependency usage.\n  - Position polling not accounting for seeks — a practical UX observation I missed.\n  - /proc/sys/kernel/hostname read being cached in OnceLock — Kimi approves the caching but notes it could be done once at startup. Minor but valid.\n\n  Things I caught that Kimi missed\n\n  - Actual bugs — queue reorder off-by-one, playlist DnD index error, toast format string \"HTTP {} error\" never substituted, double-wrapped Result in stream_info.rs, reversed comment in shuffle logic. These are concrete\n  defects, not just style issues.\n  - Concurrency issues in depth — the Cell<bool> shuffle state race, futures::Mutex inside glib::spawn_future_local deadlock risk, queue mutation race between remove_all() and extend_from_slice().\n  - Signal handler accumulation on widget reuse in ListView factories — a slow memory leak.\n  - Main-thread blocking from synchronous library filtering in detail views.\n  - Image cache with no eviction — unbounded disk growth.\n  - bytes_to_texture panicking inside a Result-returning function — defeats the entire error contract. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.353606",
        "updated_at": "2026-02-09T16:18:36.353606",
        "author": {
          "id": "9f9837cac41f25d40a136fbe2ce44394",
          "source_id": "igravious",
          "username": "igravious",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "91c937e4a43dfae641c4a4db80d0c8ef",
        "source_id": "46945370",
        "content": {
          "text": "Are you serious? You don’t think I’m capable of running the codebase through an LLM? Or is this supposed to be some kind of gotchya? Rude and lame. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.355597",
        "updated_at": "2026-02-09T16:18:36.355597",
        "author": {
          "id": "46ab4e808b3cdc1cf08edb8040834947",
          "source_id": "WD-42",
          "username": "WD-42",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "26f0091d2a3919e35067f4ee2f7619a2",
        "source_id": "46945643",
        "content": {
          "text": "I'm not the OP. Not everyone is paying for LLMs, even now. So I think it is perfectly reasonable to assume good intentions, here. Someone spent their own tokens to ponder your code and thought they'd share the result. For anyone else looking, like me, I can see that this is probably going to come up relatively clean without having to spend my own tokens, or install it, and I'm more likely to, now that I can see that. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.357661",
        "updated_at": "2026-02-09T16:18:36.357661",
        "author": {
          "id": "f070b8a2449dd5cb016372ddaf36fab6",
          "source_id": "ericb",
          "username": "ericb",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "360ef1c88bf873ca44c99ee4682d9fcd",
        "source_id": "46946599",
        "content": {
          "text": "Ignore them. These people are insane, don't ruin your day reading their messages. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.359735",
        "updated_at": "2026-02-09T16:18:36.359735",
        "author": {
          "id": "2d4b3413078f17832ceeb21b1bc1a450",
          "source_id": "delusional",
          "username": "delusional",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "06f9f33b20823007acdbce39e8ed9bd1",
        "source_id": "46945716",
        "content": {
          "text": "I built https://measuretocut.com after too many DIY projects ended with another trip to the hardware store. It figures out how much material you actually need and how to cut it to minimize waste or costs. When I released it in December it just handled  1D cuts for things like boards, bars, and pipes. You enter what you need, and it lays everything out visually on stock lengths. This morning I released the 2D sheet cut calculator to do cut plans for plywood and similar sheet materials. Any feedback is welcomed from fellow engineers turned woodworkers! reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.361878",
        "updated_at": "2026-02-09T16:18:36.361878",
        "author": {
          "id": "2fc2d6e0585e880af1e2fa472e0eeb55",
          "source_id": "happiness0067",
          "username": "happiness0067",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "9dbb45338eadb46b3a8fc23b55688ac9",
        "source_id": "46946501",
        "content": {
          "text": "Fine tuning Gemini 2.5 flash on EVM Blockchain execution structures and using perplexity with PageRank to perform transaction anomaly detection. https://lite.chaingenius.ai/theory [SMILES]( https://en.wikipedia.org/wiki/Simplified_Molecular_Input_Lin... ) or [SELFIES]( https://resources.wolframcloud.com/PacletRepository/resource... ), but for EVM Blockchain executions. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.364080",
        "updated_at": "2026-02-09T16:18:36.364080",
        "author": {
          "id": "9d566f5c4a28ed3dcbbc21096704d403",
          "source_id": "spennant",
          "username": "spennant",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "2c29f0591894e6d433c75715e9e743b2",
        "source_id": "46944590",
        "content": {
          "text": "I’m building datenba.ch, a hyper-local “digital village” for a few small communities in rural Germany (Neckartal/Odenwald-ish). Instead of another social network, it’s a bundle of small, practical community tools under one umbrella, combining of the shelf-software with purpose-built projects of our own. Our current areas of focus are - help! a neighbor-to-neighbor help board (rides, errands, PC help, garden/handwork) - hubs! for shared spaces / tool-sharing / events / social hubs Right now I’m building the integration surface (claims, roles, provisioning), polishing onboarding, and trying to design help!/hubs! so they’re useful even with low activity. If anyone’s done (hyper-)local community platforms: I’d love to hear what actually drove adoption and what did not work out for you. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.366281",
        "updated_at": "2026-02-09T16:18:36.366281",
        "author": {
          "id": "f789d3e5ef8d7d872111c1e38c00e9b9",
          "source_id": "foxtrottbravo",
          "username": "foxtrottbravo",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "10c34d2a412ff78e499321b500de33f9",
        "source_id": "46946203",
        "content": {
          "text": "Still working on: https://www.votivus.org A hobby project I started putting together late last year; a little spot on the internet for prayer and reflection. https://dugnad.stavanger-digital.no/ A pro bono tech consultancy for local non profits. The idea is to help them use tech to better deliver on their mission. Just today I finished off building a little PWA to help a couple of non-profits offload the admin of volunteer scheduling (mostly done through whatsapp, messenger, etc). I'd recommend others try the same pro bono consulting in their local area, it's quite rewarding! reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.368550",
        "updated_at": "2026-02-09T16:18:36.368550",
        "author": {
          "id": "1bcf445e13accf83136eb9ed13f1ab23",
          "source_id": "starwatch",
          "username": "starwatch",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "42415515cba5f02e5b4fdd548be42413",
        "source_id": "46946429",
        "content": {
          "text": "This looks awesome. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.370749",
        "updated_at": "2026-02-09T16:18:36.370749",
        "author": {
          "id": "5b1fe02d1fcd6849c89148588fb8d4ae",
          "source_id": "aavci",
          "username": "aavci",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "18f16b6765d0c910348a178b3dbba727",
        "source_id": "46946562",
        "content": {
          "text": "Thanks! reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.373004",
        "updated_at": "2026-02-09T16:18:36.373004",
        "author": {
          "id": "1bcf445e13accf83136eb9ed13f1ab23",
          "source_id": "starwatch",
          "username": "starwatch",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "2f76fc5ff4dabe7fc53c28d2d92c779d",
        "source_id": "46946302",
        "content": {
          "text": "Couple of scratch-my-itch apps. 1. Plimsoll Line for dealing with anxieties from mountains of Reminder items, by surfacing the stress factors and taking small actions such as quick journalling and a breathing exercise. The new version with Widget should be released within the next week or two. Version 1 is currently in the iOS App Store. ( https://apps.apple.com/us/app/calm-to-do-list-tasks-plimsoll... Calm To Do List&Tasks-Plimsoll). Made it to help my wife (and me!) not get so overwhelmed with things she has yet to do but hasn't started. Also to make it easy to write down things weighing heavy on her mind to alleviate the vicious cycle of emotional decay. 2. Yet-unnamed and -unreleased weather app for planning outdoor activities at times of the day when the weather will be most favorable (or least bad). Made it so that I can plan when to go out to the back yard to bring in more fire wood for the stove in my house. The weather has been tough this winter in the Northeastern US so it finally made me work on the app. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.375300",
        "updated_at": "2026-02-09T16:18:36.375300",
        "author": {
          "id": "5604792fbe8e09b9132230067b4b661d",
          "source_id": "tunaoftheland",
          "username": "tunaoftheland",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "6255cf9611aaf7371c7d44ee794798da",
        "source_id": "46946674",
        "content": {
          "text": "An iOS build size analysis app that runs locally on your Mac: https://apps.apple.com/us/app/dotipa/id6742254881 reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.377592",
        "updated_at": "2026-02-09T16:18:36.377592",
        "author": {
          "id": "dd394d06772360effde18575ce36f87f",
          "source_id": "elpakal",
          "username": "elpakal",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "394f4f35c38164ee4e146b67d77ce7d8",
        "source_id": "46946448",
        "content": {
          "text": "Working on https://github.com/wiseprobe/patchpal , an open-source agentic coding assistant in Python. While it's true that the agentic coding assistant space is crowded (Claude Code, Aider, Opencode, Codex, etc.), we needed something supporting both local and cloud models that we could easily modify/extend for custom workflows. Being able to access the agent through both a terminal and a Python API/REPL has come in handy. Recent releases includes custom tools, agent skills, and built-in support for Ralph Wiggum loops. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.380029",
        "updated_at": "2026-02-09T16:18:36.380029",
        "author": {
          "id": "ba809d46b6efd9348e85f8279457f835",
          "source_id": "wiseprobe",
          "username": "wiseprobe",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "01edd12e225d10b7005bb9253e1aadec",
        "source_id": "46943597",
        "content": {
          "text": "I've been working on the demo for Globs, a daily puzzle game about finding the hidden theme behind a jumble of tiles: https://threeemojis.com/en-US/play/globs It was inspired by 2025 by thomaswc, a 45x45 connections-like puzzle. Globs jumped off from there and it's been very fun to make. I have AI generating the puzzle groups and it keeps surprising me everyday with what it comes up with. I've got demos up for over 20 different languages, and many different sizes of puzzle. Just recently, I got the puzzle to be generated daily for American English, British English, High German and European Spanish. It can also do custom theme puzzles like the following: Big YC https://threeemojis.com/en-US/play/globs/en-US/demo?size=big... Jumbo HN https://threeemojis.com/en-US/play/globs/en-US/demo?size=jum... There is still some bugs I am tracking down (open the page in a private browser if you hit stale data) but the game has really come together lately and been a lot of fun, I hope you all like it! reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.382482",
        "updated_at": "2026-02-09T16:18:36.382482",
        "author": {
          "id": "0c8a77bc5f527d73e6b21f1405b57348",
          "source_id": "knuckleheads",
          "username": "knuckleheads",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "29e7fc20976cbddc461010882e6bbb91",
        "source_id": "46942802",
        "content": {
          "text": "I built a Pokédex for zoo trips for my girlfriend: https://www.zookeeperapp.com https://www.mikeayles.com/#zookeeper-wip It lets you take photos of all the animals you see to collect them, when you 'capture' a new animal, it gives you fun facts about them. I seeded it with UK zoos, but there's no reason it can't work elsewhere. It was built because the signage at a zoo we went to was terrible and we had no idea what some animals were, so it matches your photo with the list of animals to the best of its ability. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.384987",
        "updated_at": "2026-02-09T16:18:36.384987",
        "author": {
          "id": "bd6ca78cf41e5bc4c3aeb9d00fbe0a56",
          "source_id": "mikeayles",
          "username": "mikeayles",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "9ecf46e65263b7e12b8aa6b3ddb4e300",
        "source_id": "46944406",
        "content": {
          "text": "That's a lovely idea! I wanted to build something similar for safaris but the lack of network in remote areas makes it a bit tricky to use online image recognition models. I never went down the rabbit hole to use offline ones. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.387424",
        "updated_at": "2026-02-09T16:18:36.387424",
        "author": {
          "id": "5ee04d143f69d6a0938870d696dba910",
          "source_id": "keraf",
          "username": "keraf",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "b8efbd08ef265e6f2ba8130656fa7375",
        "source_id": "46940050",
        "content": {
          "text": "https://concludia.org/ - I've mentioned it here before, it's a site to help people reason through and understand arguments together. No real business purpose for it yet, it's more an idea I've had for years and have been wanting to see it through to something actually usable. You can graphically explore arguments, track their logical sufficiency/necessity, and make counterpoints. It's different than other types of argument theory that just have points \"in favor\" and \"against\" because of how it tries to propagate logical truth and provability. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.389888",
        "updated_at": "2026-02-09T16:18:36.389888",
        "author": {
          "id": "06293b30b484f0847c469ad1b1ee7593",
          "source_id": "tunesmith",
          "username": "tunesmith",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "71269801d027b9a475e85d493e51ef9e",
        "source_id": "46942903",
        "content": {
          "text": "We would have saved so many wasted hours in the last company I worked for if we had this... you have no idea, to give you a sense, the decision to move from a Neo4J db to MySQL (the service was failing, the DB was failing, it was a bad architecture decision) took 6 months, when it should have been at most a couple days discussion. Nurture this, it will become a great tool in the belt for a lot of people reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.392360",
        "updated_at": "2026-02-09T16:18:36.392360",
        "author": {
          "id": "8d6db8f4fe9ca9d397a1ebd590433404",
          "source_id": "oscarcp",
          "username": "oscarcp",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "092751b23b24990df1e49ab092d624fd",
        "source_id": "46945602",
        "content": {
          "text": "Do you mind me asking, what kind of problems did you run into with Neo4j? Did you encounter performance issues after the DB grew to a certain size, or did you realize that the data wasn't suited to a graph DB and weird query patterns started causing trouble, or was it something else entirely? I'm considering using a Neo4j self hosted instance for a project, but having only played around with it in low-stakes + small-data toy projects, I'm not really familiar with the footguns and failure modes... All that aside, plugging holes in a sinking database for six months because you can't come to a descision does not sound like a fun time :D reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.394909",
        "updated_at": "2026-02-09T16:18:36.394909",
        "author": {
          "id": "ebf9a8a054cba7a9a59728ef1d7217f3",
          "source_id": "smnc",
          "username": "smnc",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "568c9a5bfac3d38ab9259cdd17b62816",
        "source_id": "46940082",
        "content": {
          "text": "This is pretty cool! I'm not sure how you'd make a business out of it, but I can definitely see myself using it to justify some decisions on my day to day stuff. I'm also a sucker for serif fonts so points for that. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.397429",
        "updated_at": "2026-02-09T16:18:36.397429",
        "author": {
          "id": "efd33098b6b54391cb01d885a4982976",
          "source_id": "rmonvfer",
          "username": "rmonvfer",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "d9940768153b464654afcc5ff8037f4b",
        "source_id": "46942930",
        "content": {
          "text": "I wanted to add more value to this comment about monetisation - regardless if that's doable or not, it's an extremely cool project!! What if you could sell the data for each argument? That might be valuable to LLM labs, because then you can essentially guarantee that every single argument you provide is human checked, and you could accumulate a large DB of those. Of course you'll never be able to capture every single argument possible, but it's rather a mechanism that would allow incremental improvement with time. But codifying logic and natural language is a very nice idea. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.400026",
        "updated_at": "2026-02-09T16:18:36.400026",
        "author": {
          "id": "d85edd7b4ace474c1a5e65b27d77f0de",
          "source_id": "calculated",
          "username": "calculated",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "ccedc8e5679bd22e8820208b25671cf6",
        "source_id": "46940155",
        "content": {
          "text": "Yeah, I only just yesterday got it to the point where people can create their own arguments. I was just using it to check my own assumptions on why I have such a complicated \"end-of-month finances\" list of things to do. :) But I also like the idea of using it for political arguments or even fun stuff like mystery-solving. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.402613",
        "updated_at": "2026-02-09T16:18:36.402613",
        "author": {
          "id": "06293b30b484f0847c469ad1b1ee7593",
          "source_id": "tunesmith",
          "username": "tunesmith",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "56e4bb31e4ac9fed11332d3f6ad0ddf2",
        "source_id": "46940325",
        "content": {
          "text": "I like this. It reminds me of the interesting type of experimentation that was done with LLMs before agentic coding took over as the primary use case. I am interested in seeing a personal version of this. Help people work out their own brain knots to make decision-making easier. I'm actually decent at mending fences with others. Put making decisions myself? Impossible. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.405232",
        "updated_at": "2026-02-09T16:18:36.405232",
        "author": {
          "id": "210f8961a2209b0092efb7860d39252a",
          "source_id": "laborcontract",
          "username": "laborcontract",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "29941c939381437ddb8661941ca207a9",
        "source_id": "46940404",
        "content": {
          "text": "You can actually register now (with a waiting list) and make your own private graphs, if that's what you meant by a personal version. (You'd be like member #4 haha) I've actually had a lot of fun hooking it up to LLM. I have a private MCP server for it. The tools tell it how to read a concludia argument and validate it. It's what generated all the counterpoints for the \"carbon offset\" argument ( https://concludia.org/step/9b8d443e-9a52-3006-8c2d-472406db7... ) . And yeah... when I've tried to fully justify my own conclusions that I was sure were correct... it's pretty humbling to realize how many assumptions we build into our own beliefs! reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.407935",
        "updated_at": "2026-02-09T16:18:36.407935",
        "author": {
          "id": "06293b30b484f0847c469ad1b1ee7593",
          "source_id": "tunesmith",
          "username": "tunesmith",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "b559065e53e5ede8a5d2f4daed704d61",
        "source_id": "46940129",
        "content": {
          "text": "Cool idea, I think graphs (what you’re doing) are a better way of modeling arguments because it captures nuance often lost in 1 v 1 model of debate reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.410610",
        "updated_at": "2026-02-09T16:18:36.410610",
        "author": {
          "id": "6d47ed1f5755b4eea931f53652d52004",
          "source_id": "konaraddi",
          "username": "konaraddi",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "2b6bd1dadb8b2052e5fdf31b35c4f66f",
        "source_id": "46940227",
        "content": {
          "text": "Frustration at that kind of debate has been a large part of the motivation, how it occludes so much of what ideally should be a dialectic. I especially dislike how if someone gets flustered, they're seen as losing. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.413373",
        "updated_at": "2026-02-09T16:18:36.413373",
        "author": {
          "id": "06293b30b484f0847c469ad1b1ee7593",
          "source_id": "tunesmith",
          "username": "tunesmith",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "c2f05b41f2842740e9c35d41292b17b1",
        "source_id": "46946324",
        "content": {
          "text": "Building an AI debugger for embedded systems. You know that feeling when your microcontroller crashes and you spend 3 hours staring at cryptic registers trying to figure out why? Yeah, I got tired of that. So I built an MCP server that lets Claude talk directly to GDB.\nNow instead of manually decoding CFSR registers, I just ask \"why did it crash?\" and get back \"division by zero at line 142 in calculate_average()\". It's pretty satisfying to watch Claude diagnose a deadlock between two RP2040 cores in 10 seconds - something that would've ruined my entire afternoon. Just shipped v0.1.0: https://github.com/ezulabs/embeddedgdbmcp reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.416184",
        "updated_at": "2026-02-09T16:18:36.416184",
        "author": {
          "id": "46d0c9228351522ad9090cd598f43a10",
          "source_id": "ezulabs",
          "username": "ezulabs",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "3af881357d04ec50005476c81a4ef9c1",
        "source_id": "46946339",
        "content": {
          "text": "Most parents I've met understand the internet can be a dangerous place for children but aren't sure what to do about it. Some avoid it altogether, but most give up and resign themselves to whatever happens. \nWhat I wanted most was just to have some visibility into what my kids were experiencing, so I built LivingRoom App for iPhone and iPad. It sends occasional screenshots to parents. My hope is that when we shine a light on the online world, we will be free to use the internet as a tool for learning, creativity and connection. https://livingroomapp.com/ reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.418969",
        "updated_at": "2026-02-09T16:18:36.418969",
        "author": {
          "id": "a56ae28e0956af5e993cf98343eb5250",
          "source_id": "cwoolfe",
          "username": "cwoolfe",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "fbd37af396d0535ac3c5e744d8f536f2",
        "source_id": "46945821",
        "content": {
          "text": "Developing LogiModel AI ( https://www.logimodel.com/ ) which is an agentic supply chain optimization engine that forecasts demand, optimizes operations, and simulates scenarios to reduce costs while keeping your network reliable and customers satisfied. It integrates seamlessly with your ERP and document repositories to learn your business context, then acts as an intelligent decision engine, freeing you to focus on strategy while it handles execution. Always interested in possibilities of LLMs interfacing with MIP solvers. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.421885",
        "updated_at": "2026-02-09T16:18:36.421885",
        "author": {
          "id": "8620f168783ef9628e01dfca2dc1ac21",
          "source_id": "abhishekbasu",
          "username": "abhishekbasu",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "e13a9a55ab9bd685d3bdde537163df39",
        "source_id": "46946818",
        "content": {
          "text": "Also, this was a quick fun project for a multi-agent flow https://flickfeast.party/ reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.424730",
        "updated_at": "2026-02-09T16:18:36.424730",
        "author": {
          "id": "8620f168783ef9628e01dfca2dc1ac21",
          "source_id": "abhishekbasu",
          "username": "abhishekbasu",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "37d356b249b3e7a9fe44275f9a16c0ac",
        "source_id": "46946298",
        "content": {
          "text": "https://beyondwp.io After around 15 years working with clients and helping them wrangle their WordPress sites, I stopped working with WordPress as a primary platform for building sites. A while back I've switched to a more modern stack and have fully abandoned WordPress. Having that background, however, I've come to know (way too well) many of the frustrations and security problems with the WordPress ecosystem. As a result, I started a service to help business owners break free from WordPress on to a more modern Next.js-powered stack that's faster, lighter weight, and easier for them to manage. Brand new but should be fun! reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.427726",
        "updated_at": "2026-02-09T16:18:36.427726",
        "author": {
          "id": "1cc7c015628023b4b1cba3b7546cc069",
          "source_id": "SunshineTheCat",
          "username": "SunshineTheCat",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "035b0d75dd71edadae5af649e334b251",
        "source_id": "46946459",
        "content": {
          "text": "Gotta say this is pretty cool. Love some of the nostalgia on the homepage. Personally not a nextjs fan but finding a modern alternative to WP will pay off for many businesses reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.430626",
        "updated_at": "2026-02-09T16:18:36.430626",
        "author": {
          "id": "fc933a1ead62eb1780287aba382a1780",
          "source_id": "axelthegerman",
          "username": "axelthegerman",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "5a77d2a6b7ea86bb001a59f750211f59",
        "source_id": "46940523",
        "content": {
          "text": "I love making games, and I’ve been building a no-code game engine by extracting reusable components every time I ship a new game. It started as me scratching my own itch, and now it’s turning into a real platform. Each game adds more building blocks to the editor: multiplayer, event systems, NPC behaviors, pathfinding, etc. I build a system once, and then anyone using the editor can use it in a click.\nFor game logic, I recently added a visual event system I’m really excited about. It’s kind of like Unreal Blueprints, but focused on 2D. You pick a trigger, wire conditions, and chain actions in a node graph [1]. Big challenge right now: most people who want to make games needs assets, and don't know how to get/make them. So I’m building a marketplace where pixel artists can upload tilesets/characters, and unlike itch.io, assets are usable directly inside the engine. No ZIP downloads or import setup, just browse and drop into your game. A preview here[2]. Also, if you want to use the editor but ship elsewhere, you can export terrain, animations, and hitboxes to Godot 4. Nothing is locked in. The engine/editor is at https://craftmygame.com if anyone wants to poke around! And you can test a games here[3][4], and 1 multiplayer game I've tested IRL in a bar [4]! [1] https://youtu.be/8fRzC2czGJc [2] https://www.youtube.com/watch?v=hScOK_naYnk [3] https://craftmygame.com/game/e310c6fcd8f4448f9dc67aac/r/play [4] https://www.youtube.com/shorts/WOIUmOVvaZM reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.433747",
        "updated_at": "2026-02-09T16:18:36.433747",
        "author": {
          "id": "ef5195fb08ef95be54471731d5ae65af",
          "source_id": "heyitssim",
          "username": "heyitssim",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "78678394e7d20902f1471f713763b02f",
        "source_id": "46938572",
        "content": {
          "text": "A tool for creating CSS color palettes for web UIs that pass WCAG accessibility standards for color contrast, where you can fine tweak all the tints/shades quickly using a hue/saturation/lightness curve editing interface: https://www.inclusivecolors.com/ Unlike most tools based around autogenerating colors, this is more of an editor that lets you fully customise all the tint/shades to your liking with a focus on accessibility. This is important when you've got existing brand colors to include and want to find accessible color combinations that work together. Would love feedback in general and especially from designers/devs who have different needs in how they go about creating branded palettes! reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.436750",
        "updated_at": "2026-02-09T16:18:36.436750",
        "author": {
          "id": "9226a92f834b2021a95fe0ed81b53b0e",
          "source_id": "seanwilson",
          "username": "seanwilson",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "9afca445b4613c4e1b2910f723fa6ed7",
        "source_id": "46938767",
        "content": {
          "text": "This is great! As a non-designer, I've been relying on ChatGPT to select color schemes/palettes for me. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.439733",
        "updated_at": "2026-02-09T16:18:36.439733",
        "author": {
          "id": "2f03154021c92dce7de27786d56c0ed6",
          "source_id": "snisarenko",
          "username": "snisarenko",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "cf8921d3b6a8de801bfb1384e2c5705f",
        "source_id": "46939108",
        "content": {
          "text": "> I've been relying on ChatGPT to select color schemes/palettes for me Thanks! Any problems you've found with this approach or it's usually good enough? For me, I couldn't find a tool that would let me customize multiple color scales at once, check they look good together on a mockup, and also be accessible. It's one of those problems where you can autogenerate something that gets you most of the way there, but then for it to be usable you need need to see how it looks on designs and fine tweak it. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.443089",
        "updated_at": "2026-02-09T16:18:36.443089",
        "author": {
          "id": "9226a92f834b2021a95fe0ed81b53b0e",
          "source_id": "seanwilson",
          "username": "seanwilson",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "cc48ff4d27c8f690a65638a6b42743ca",
        "source_id": "46939879",
        "content": {
          "text": "Have you tried https://huetone.ardov.me/ ? Multiple color scales, P3, export to CSS and figma, as well as APCA & WCAG for accessibility. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.446173",
        "updated_at": "2026-02-09T16:18:36.446173",
        "author": {
          "id": "ce4606467f7d402feb931f2c1542a623",
          "source_id": "Cynddl",
          "username": "Cynddl",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "061bcfb476096db0466bcc49e6d434ae",
        "source_id": "46941061",
        "content": {
          "text": "So for my tool, I really need the live UI mockup without having to export first to tweak the colors until they work (e.g. often the off-white/very-light colors used for backgrounds are too vibrant otherwise), the control-point based curve editing helps to explore hue/saturation/lightness curves around a brand color without a lot of clicking, and I want the option for palettes where each color scale follows the same steps in lightness (for predictable contrast between steps from different color scales). Barely any designers I work with know about P3 colors (feels like P3 mostly appeals to developers right now, for programmatic reasons?), so I'm not that interested in P3 if it means using OKLCH with its intimidating looking color picker. My tool uses HSLuv, which looks familiar like an HSL color picker, where unlike HSL only the lightness slider alters the WCAG contrast, so HSLuv (while limited to sRGB) is great for exploring accessible colors. I've actually got support for APCA, but I find many struggle understanding WCAG contrast requirements already. There's Figma export too. Anyway, there's lots of overlap between different color tools but the small details are important for different workflows and needs. I've started to realise too that most designers need a lot of introduction into building (accessible) color palettes in general so it's a tricky puzzle between adding features and trying to keep it simple, which is why I'm very open to suggestions! reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.449268",
        "updated_at": "2026-02-09T16:18:36.449268",
        "author": {
          "id": "9226a92f834b2021a95fe0ed81b53b0e",
          "source_id": "seanwilson",
          "username": "seanwilson",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "275ab91e3a071836023ff807634e3eb7",
        "source_id": "46937911",
        "content": {
          "text": "https://kavla.dev/ It's an infinite canvas that runs SQL. I've been working with data my entire career. I feel like we need to alt+tab so much. What if we just put it all on a canvas? Currently very WIP, but there's a simple titanic demo available! Built with tldraw and duckdb wasm, running on cloudflare durable objects reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.452405",
        "updated_at": "2026-02-09T16:18:36.452405",
        "author": {
          "id": "f02735b5d7cd436a8a1c2c0010779f46",
          "source_id": "aleda145",
          "username": "aleda145",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "25999b37a285f8cd88b12d6f802dc66f",
        "source_id": "46939729",
        "content": {
          "text": "Look at count.co for a Figma-like approach to databases. We were using it at work (transitioning to Metabase); it's great for exploring and debugging and prototyping but it ends up too much of a tangled spaghetti mess for anything long-term. Would not recommend for user-/other-company-departments-facing reports or dashboards. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.455531",
        "updated_at": "2026-02-09T16:18:36.455531",
        "author": {
          "id": "f19134115f375fad55b12c69701d4fc1",
          "source_id": "mjaniczek",
          "username": "mjaniczek",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "d42c4ed296eb09b3be1ccd3613f5f645",
        "source_id": "46941499",
        "content": {
          "text": "That's super interesting! With Kavla I want to lean into the exploring/debugging phase for analytics. \"Embrace the mess\", in a way. My vision is that there will be an \"export to dbt\" button when you're ready to standardize a dashboard. What made you pick count?\nWas spaghetti the major reason you left count, or something else? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.458959",
        "updated_at": "2026-02-09T16:18:36.458959",
        "author": {
          "id": "f02735b5d7cd436a8a1c2c0010779f46",
          "source_id": "aleda145",
          "username": "aleda145",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "b1d21cfe3c1d335427de5b2e1887f388",
        "source_id": "46943511",
        "content": {
          "text": "The choice to use Count was made before I joined the company; IIRC they migrated to it from Tableau. We wanted to migrate (to Streamlit, back then) to have the SQL not live locked in a tool, but inside our git repository; to be able to run tests on the logic etc. But the spaghetti mess was felt too, even if it wasn't the main reason to switch. (But then, 1) some team changes happened that pushed us towards Metabase, and 2) we found that Streamlit managed by Snowflake is quite costly, compute-time wise. (The compute server that starts when you open a Streamlit report, stays live for tens of minutes, which was unexpected to us.) ---- Export to DBT sounds great. Count has \"export to SQL\" which walks the graph of the cell dependencies and collects them into a CTE. I can imagine there being a way to export into a ZIP of SQL+YML files, with one SQL file per cell. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.462218",
        "updated_at": "2026-02-09T16:18:36.462218",
        "author": {
          "id": "f19134115f375fad55b12c69701d4fc1",
          "source_id": "mjaniczek",
          "username": "mjaniczek",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "6b138aa9d8e7f76be25df7d012cf0318",
        "source_id": "46944858",
        "content": {
          "text": "Thank you so much for sharing, super helpful! Great take on the SQL lock in, that's something that I need to think hard about. Ideally a git integration maybe? Kavla also traverses the DAG, psuedo code: deps = getDeps() // recursive\n\n  for dep in deps:\n    if dep is query:\n      run: \"CREAT OR REPLACE VIEW {upstream} AS {upstream.text}\n    if dep is source:\n      done A selected chain of Kavla nodes could probably be turned into a single dbt model using CTEs! Thanks for making me think about this! reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.465481",
        "updated_at": "2026-02-09T16:18:36.465481",
        "author": {
          "id": "f02735b5d7cd436a8a1c2c0010779f46",
          "source_id": "aleda145",
          "username": "aleda145",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "9857cc3c03ef6a8e6cd92663e56f14a5",
        "source_id": "46942514",
        "content": {
          "text": "Somehow i had landed on your page sometime back and was just impressed with the quality of landing page and also the concept. Hope to use it in near time. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.468858",
        "updated_at": "2026-02-09T16:18:36.468858",
        "author": {
          "id": "c7eb6f3c3925de896b330ce838f5733e",
          "source_id": "p2hari",
          "username": "p2hari",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "83223489d0fe143e518bbd9806f07d28",
        "source_id": "46943025",
        "content": {
          "text": "The website is great and the examples (like getting distinct values of a table as a prerequisite investigation) really get the point across. In my job I always end up with big notebooks of data exploration that get messy fast and are hard to share anything but the final result, having a canvas that embraces the non-linear nature is a great idea. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.472170",
        "updated_at": "2026-02-09T16:18:36.472170",
        "author": {
          "id": "58e48868abf1b5140f316a776349f8a9",
          "source_id": "wkhughes",
          "username": "wkhughes",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "b66222c2cd47f566c87815a3bf618777",
        "source_id": "46945053",
        "content": {
          "text": "That has been my experience as well! Aside from the non-linearity, what key features would make you use Kavla instead of a notebook? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.475506",
        "updated_at": "2026-02-09T16:18:36.475506",
        "author": {
          "id": "f02735b5d7cd436a8a1c2c0010779f46",
          "source_id": "aleda145",
          "username": "aleda145",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "8ebfe6cd39d67fc0a85c9955b25b36f6",
        "source_id": "46943633",
        "content": {
          "text": "Love the brutalist style. Are the components all hand-rolled or something off the shelf? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.478868",
        "updated_at": "2026-02-09T16:18:36.478868",
        "author": {
          "id": "5a18e4cdef5ba340561d3cda67fe2c31",
          "source_id": "potamic",
          "username": "potamic",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "c6a948a226e6207e7d794bc4591ffba3",
        "source_id": "46945088",
        "content": {
          "text": "I was inspired by https://www.neobrutalism.dev/ ! reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.482255",
        "updated_at": "2026-02-09T16:18:36.482255",
        "author": {
          "id": "f02735b5d7cd436a8a1c2c0010779f46",
          "source_id": "aleda145",
          "username": "aleda145",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "4b69c93664e0fae4113cd7e16a1b8eb5",
        "source_id": "46944648",
        "content": {
          "text": "Looks very much like like a signature gemini ui. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.485645",
        "updated_at": "2026-02-09T16:18:36.485645",
        "author": {
          "id": "79faf97f0ae215f0da41cb08e19f701f",
          "source_id": "risyachka",
          "username": "risyachka",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "c95cd9b55353f8a326862c647001e385",
        "source_id": "46942683",
        "content": {
          "text": "Cool looking website! Is that an open source css library or did you style it yourself? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:36.489081",
        "updated_at": "2026-02-09T16:18:36.489081",
        "author": {
          "id": "2ddf2cfa2d64304d8048a82d73a6c898",
          "source_id": "schnebbau",
          "username": "schnebbau",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      }
    ],
    "metadata": {
      "crawled_at": "2026-02-09T16:18:44.904216",
      "language": "en-US",
      "keywords": [
        "tech",
        "startup",
        "programming",
        "ask",
        "question"
      ],
      "is_nsfw": false
    }
  },
  {
    "post": {
      "id": "e2cb86208f91ab32f81d25039f3fa38e",
      "source_id": "46943879",
      "title": "Ask HN: Open Models are 9 months behind SOTA, how far behind are Local Models?",
      "content": {
        "text": "<div class=\"toptext\"></div>",
        "format": "html",
        "media": []
      },
      "created_at": "2026-02-09T16:18:30.199135",
      "updated_at": "2026-02-09T16:18:30.199135",
      "category": {
        "id": "f31af88693e43c7e98a65941d54a8cd6",
        "name": "Ask HN"
      },
      "tags": [
        "Ask HN",
        "hacker news",
        "tech"
      ],
      "author": {
        "id": "8b56ff9f0cff88ee9eb69b7a20e93c7f",
        "source_id": "myk-e",
        "username": "myk-e",
        "avatar": "",
        "role": "user",
        "signature": ""
      },
      "stats": {
        "views": 0,
        "likes": 7,
        "dislikes": 0,
        "replies": 0,
        "shares": 0
      }
    },
    "source": {
      "forum": "hackernews",
      "url": "https://news.ycombinator.com/item?id=46943879",
      "section": "Ask HN"
    },
    "replies": [
      {
        "id": "dc0b3f750d6c1dc0f093711e7929620e",
        "source_id": "46944806",
        "content": {
          "text": "A local model is an open model you run locally, so I'm not entirely sure the distinction in the question makes sense. That said, if you're talking about models you can actually use on a single regular computer that costs less than a new home, the current crop of open models are very capable but also have noticeable limitations. Small models will always have limitations in terms of capability and especially knowledge. Improved training data and training regiment can squeeze out more from the same number of weights, but there is a limit. So with that in mind, I think such a question only makes sense when talking about specific tasks, like creative writing, data extraction from text, answering knowledge questions, refactoring code, writing greenfield code, etc. In some of these areas the smaller open models are very good and not that far behind. In other areas they are lagging much more, due to their inherent limitations. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:47.762307",
        "updated_at": "2026-02-09T16:18:47.762307",
        "author": {
          "id": "dfa011d2fbcd5fbba0e3ab10dec59ce7",
          "source_id": "magicalhippo",
          "username": "magicalhippo",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "b5f71fe0c76e68240555a66be1f334b6",
        "source_id": "46945233",
        "content": {
          "text": "Well, it depends on the hardware you have. If you have a hardware locally that can run best open models, then your local models are as capable as the open models. That said, open models are not far behind SOTA, less than 9 months gap. If what you're asking about those models that you can run on retail GPUs, then they're a couple years behind. They're \"hobby\" grade. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:47.762838",
        "updated_at": "2026-02-09T16:18:47.762838",
        "author": {
          "id": "e426f5b9715bab94a800df9ba740382e",
          "source_id": "hasperdi",
          "username": "hasperdi",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "fce3905c4edefcf3be460ad9e8523b45",
        "source_id": "46944750",
        "content": {
          "text": "A local model is a smaller open model, so I’d expect it to be 9 months behind a small (ie nano) closed model as a base assumption reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:47.763603",
        "updated_at": "2026-02-09T16:18:47.763603",
        "author": {
          "id": "d51a6fc1b88e0387f63191816cd49032",
          "source_id": "softwaredoug",
          "username": "softwaredoug",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      }
    ],
    "metadata": {
      "crawled_at": "2026-02-09T16:18:47.763894",
      "language": "en-US",
      "keywords": [
        "tech",
        "startup",
        "programming",
        "ask",
        "question"
      ],
      "is_nsfw": false
    }
  },
  {
    "post": {
      "id": "a5bea2f9a2a57f304d740c42dfa0f669",
      "source_id": "46907001",
      "title": "Ask HN: Anyone Using a Mac Studio for Local AI/LLM?",
      "content": {
        "text": "<div class=\"toptext\" style=\"margin-top:4px\">Curious to know your experience running local LLM's with a well spec'ed out M3 Ultra or M4 Pro Mac Studio. I don't see a lot of discussion on the Mac Studio for Local LLMs but it seems like you could put big models in memory with the shared VRAM. I assume that the token generation would be slow, but you might get higher quality results because you can put larger models in memory.</div>",
        "format": "html",
        "media": []
      },
      "created_at": "2026-02-09T16:18:30.199771",
      "updated_at": "2026-02-09T16:18:30.199771",
      "category": {
        "id": "f31af88693e43c7e98a65941d54a8cd6",
        "name": "Ask HN"
      },
      "tags": [
        "Ask HN",
        "hacker news",
        "tech"
      ],
      "author": {
        "id": "e3384f5169c90cc848257efff4e71138",
        "source_id": "UmYeahNo",
        "username": "UmYeahNo",
        "avatar": "",
        "role": "user",
        "signature": ""
      },
      "stats": {
        "views": 0,
        "likes": 54,
        "dislikes": 0,
        "replies": 0,
        "shares": 0
      }
    },
    "source": {
      "forum": "hackernews",
      "url": "https://news.ycombinator.com/item?id=46907001",
      "section": "Ask HN"
    },
    "replies": [
      {
        "id": "ac3c2e1a5569c830065bbd6cf768059d",
        "source_id": "46915397",
        "content": {
          "text": "I am!  I moved from a shoebox Linux workstation with 32MB of RAM and a 12GB RTX 3060 to a 256GB M3 Ultra, mainly for unified memory. I've only had it a couple of months, but so far it's proving its worth in the quality of LLM output, even quantized. I generally run Qwen3-vl at 235b, at a Q4_K_M quantization level so that it fits, and it leaves me plenty of RAM for workstation tasks while delivering tokens at around 30tok/s The smaller Qwen3 models (like qwen3-coder) I use in tandem, of course they run much faster and I tend to run them at higher quants up to Q8 for quality purposes. The gigantic RAM's biggest boon, I've found, is letting me run the models with full context allocated, which lets me hand them larger and more complicated things than I could before.  This alone makes the money I spent worth it, IMO. I did manage to get glm-4.7 (a 358b model) running at a Q3 quantization level; it's delivery is adequate quality-wise, although it delivers at 15tok/s, though I did have to cut down to only 128k context to leave me enough room for the desktop. If you get something this big, it's a powerhouse, but not nearly as much of a powerhouse as a dedicated nVidia GPU rig.  The point is to be able to run them _adequately_, not at production speeds, to get your work done.  I found price/performance/energy usage to be compelling at this level and I am very satisfied. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.499139",
        "updated_at": "2026-02-09T16:18:49.499139",
        "author": {
          "id": "72e9cca3a273953b7f8acb5353bd9f93",
          "source_id": "josefcub",
          "username": "josefcub",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "1ae1b9eaae5a0c7a4fe18a0b121caeab",
        "source_id": "46911245",
        "content": {
          "text": "I'm using an M3 Ultra w/ 512GB of RAM, using LMStudio and mostly mlx models. It runs massive models with reasonable tokens per second, though prompt processing can be slow. It handles long conversations fine so long as the KV cache hits. It's usable with opencode and crush, though my main motivation for getting it was specifically to be able to process personal data (e.g. emails) privately, and to experiment freely with abliterated models for security research. Also, I appreciate being able to run it off solar power. I'm still trying to figure out a good solution for fast external storage, I only went for 1TB internal which doesn't go very far with models that have hundreds of billions of parameters. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.499655",
        "updated_at": "2026-02-09T16:18:49.499655",
        "author": {
          "id": "968acbb1e01948179038ce9c71d61b0a",
          "source_id": "ryan-c",
          "username": "ryan-c",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "9870cf3ace1be4b01c5b7cf512b71745",
        "source_id": "46923344",
        "content": {
          "text": ">trying to figure out ... fast external storage Acasis makes 40gbps external nVME cases. Mine feels quick (for non-LLM tasks). I also use 10gbps Terramaster 4-bay RAIDs (how I finally retired my Pro5,1). >energy usage This thing uses an order of magnitude -less- energy than the computer it replaced, and is faster in almost every aspect. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.500258",
        "updated_at": "2026-02-09T16:18:49.500258",
        "author": {
          "id": "c1f9e09a5b0f6ea96f98bcfd23f66bb7",
          "source_id": "ProllyInfamous",
          "username": "ProllyInfamous",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "5fbbe781cd146382c290c8c5f011e771",
        "source_id": "46933305",
        "content": {
          "text": "10gbps is slow enough to be annoying when you're loading a 200GB model, unfortunately. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.500808",
        "updated_at": "2026-02-09T16:18:49.500808",
        "author": {
          "id": "968acbb1e01948179038ce9c71d61b0a",
          "source_id": "ryan-c",
          "username": "ryan-c",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "df1fb478c9b5f268aa6186138434c759",
        "source_id": "46934953",
        "content": {
          "text": "You might consider then getting four 40gbps nVME enclosures, and then RAIDing multiple together (e.g. in a big stripe, you could get 160gbps throughput, only limited by # physical interfaces). Each slice could be +TBs. Obviously increases your failure rate, but if you're constantly updating the same models (and not creating your own) you don't really need redundancy. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.501375",
        "updated_at": "2026-02-09T16:18:49.501375",
        "author": {
          "id": "c1f9e09a5b0f6ea96f98bcfd23f66bb7",
          "source_id": "ProllyInfamous",
          "username": "ProllyInfamous",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "d1830161736fdcb41f41b086836a6eed",
        "source_id": "46918480",
        "content": {
          "text": "This is the way brother reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.501971",
        "updated_at": "2026-02-09T16:18:49.501971",
        "author": {
          "id": "b8fb84eb462dd4209f2b22707072a440",
          "source_id": "gneuron",
          "username": "gneuron",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "bec16c4cd8c0582cddb955385bfd6934",
        "source_id": "46907246",
        "content": {
          "text": "I do! I have an M3 Ultra with 512GB. A couple of opencode sessions running work well. Currently running GML 4.7 but was on Kimi K2.5. Both great. Excited for more efficiencies to make their way to LLMs in general. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.502580",
        "updated_at": "2026-02-09T16:18:49.502580",
        "author": {
          "id": "2789d16f875f8b684c21ef4f588e2d31",
          "source_id": "StevenNunez",
          "username": "StevenNunez",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "90b8ec5c8273c1589640df08fc706933",
        "source_id": "46910863",
        "content": {
          "text": "The prompt processing times I've heard about have put me off wanting to go that high with memory on the M series (hoping that changes for the M5 series though). What's the average and longest times you've had to wait when using opencode? Has any improvements to mlx helped in that regard? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.503232",
        "updated_at": "2026-02-09T16:18:49.503232",
        "author": {
          "id": "10dfca8dc2082f67b11aa008a47652ca",
          "source_id": "circularfoyers",
          "username": "circularfoyers",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "4b950fd1d59b554820b97a9b275f4444",
        "source_id": "46921753",
        "content": {
          "text": "The M5 ultra series is supposed to have some big gains around prompt processing - something like 3-4x from what I've read. I'm tempted to swap out my m4 mini that I'm using for this kind of stuff right now! reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.503918",
        "updated_at": "2026-02-09T16:18:49.503918",
        "author": {
          "id": "cd7589989b454f63dcb5316bd858cb19",
          "source_id": "jtbaker",
          "username": "jtbaker",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "03f72d0ad223c291e89691db55cb7244",
        "source_id": "46916426",
        "content": {
          "text": "Wow, Kimi K2.5 runs on a single M3 Ultra with 512 GB RAM? Can you share more info about quants or whatever is relevant? That's super interesting, since it's such a capable model. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.504624",
        "updated_at": "2026-02-09T16:18:49.504624",
        "author": {
          "id": "c8f076703b1b58a870484d6640b4743d",
          "source_id": "pcf",
          "username": "pcf",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "e0d38270bde928ab1a766d8738f789b5",
        "source_id": "46909519",
        "content": {
          "text": "How's the inference speed? What was the price? I'm guessing you can fit the entire model without quantization? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.505353",
        "updated_at": "2026-02-09T16:18:49.505353",
        "author": {
          "id": "20df84de1a82e678fc3b5c42c0d9bc89",
          "source_id": "satvikpendem",
          "username": "satvikpendem",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "8a9aecbc63eb9de3d84d220699c1e5e5",
        "source_id": "46909507",
        "content": {
          "text": "Excellent. Thanks for the info! reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.506112",
        "updated_at": "2026-02-09T16:18:49.506112",
        "author": {
          "id": "e3384f5169c90cc848257efff4e71138",
          "source_id": "UmYeahNo",
          "username": "UmYeahNo",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "bdd522f3b5a40a7537727cfcdcb6abe1",
        "source_id": "46907207",
        "content": {
          "text": "There are some people on r/LocalLlama using it [0]. Seems like the consensus is while it does have more unified RAM for running models, up to half a terabyte, the token generation speed can be fairly slow such that it might just be better to get an Nvidia or AMD machine. [0] https://old.reddit.com/r/LocalLLaMA/search?q=mac+studio&rest... reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.506951",
        "updated_at": "2026-02-09T16:18:49.506951",
        "author": {
          "id": "20df84de1a82e678fc3b5c42c0d9bc89",
          "source_id": "satvikpendem",
          "username": "satvikpendem",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "1a6b4006cd5a6d073ee44a12d61ba1f8",
        "source_id": "46909513",
        "content": {
          "text": "Thanks for the link. I'll take a look. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.507771",
        "updated_at": "2026-02-09T16:18:49.507771",
        "author": {
          "id": "e3384f5169c90cc848257efff4e71138",
          "source_id": "UmYeahNo",
          "username": "UmYeahNo",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "328d0e40da9cf5c82acbf397bebce20e",
        "source_id": "46916269",
        "content": {
          "text": "Below are my test results after running local LLMs on two machines. I'm using LM Studio now for ease of use and simple logging/viewing of previous conversations. Later I'm gonna use my own custom local LLM system on the Mac Studio, probably orchestrated by LangChain and running models with llama.cpp. My goal has all the time been to use them in ensembles in order to reduce model biases. The same principle has just now been introduced as a feature called \"model council\" in Perplexity Max: https://www.perplexity.ai/hub/blog/introducing-model-council Chats will be stored in and recalled from a PostgreSQL database with extensions for vectors (pgvector) and graph (Apache AGE). For both sets of tests below, MLX was used when available, but ultimately ran at almost the same speed as GGUF. I hope this information helps someone! ///////// Mac Studio M3 Ultra (default w/96 GB RAM, 1 TB SSD, 28C CPU, 60C GPU): • Gemma 3 27B (Q4_K_M): ~30 tok/s, TTFT ~0.52 s • GPT-OSS 20B: ~150 tok/s • GPT-OSS 120B: ~23 tok/s, TTFT ~2.3 s • Qwen3 14B (Q6_K): ~47 tok/s, TTFT ~0.35 s (GPT-OSS quants and 20B TTFT info not available anymore) ////////// MacBook Pro M1 Max 16.2\" (64 GB RAM, 2 TB SSD, 10C CPU, 32C GPU): • Gemma 3 1B (Q4_K): ~85.7 tok/s, TTFT ~0.39 s • Gemma 3 27B (Q8_0): ~7.5 tok/s, TTFT ~3.11 s • GPT-OSS 20B (8bit): ~38.4 tok/s, TTFT ~21.15 s • LFM2 1.2B: ~119.9 tok/s, TTFT ~0.57 s • LFM2 2.6B (Q6_K): ~69.3 tok/s, TTFT ~0.14 s • Olmo 3 32B Think: ~11.0 tok/s, TTFT ~22.12 s reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.508836",
        "updated_at": "2026-02-09T16:18:49.508836",
        "author": {
          "id": "c8f076703b1b58a870484d6640b4743d",
          "source_id": "pcf",
          "username": "pcf",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "19ec8493ed3aa5ae82286628f2e6be75",
        "source_id": "46912617",
        "content": {
          "text": "I've got an M2 Ultra with 64 GB, and I've been using gpt-oss-20b lately with good results. Performance and RAM usage have been reasonable for what I've been doing. I've been thinking of trying the newer Qwen 3 Coder Next just to see what it's like, though. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.509706",
        "updated_at": "2026-02-09T16:18:49.509706",
        "author": {
          "id": "169ee39c95dbe5e0b4af1e08d9079340",
          "source_id": "TomMasz",
          "username": "TomMasz",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "e0bc2fc2dafd2e0f58e38abeeb32fdef",
        "source_id": "46914822",
        "content": {
          "text": "I have a maxed out M3 Ultra. It runs quantized large open Chinese models pretty well. It's slow-ish, but since I don't use them very frequently, most of the time is waiting to the model to load from disk to RAM. There are benchmarks on token generation speed out there for some of the large models. You can probably guess the speed for models you're interested in by comparing the sizes (mostly look at the active params). Currently the main issue for M1-M4 is the prompt \"preprocessing\" speed. In practical terms, if you have a very long prompt, it's going to take a much long time to process it.  IIRC it's due to lack of efficient matrix multiplication operations in the hardware, which I hear is rectified in the M5 architecture. So if you need to process long prompts, don't count on the Mac Studio, at least not with large models. So in short, if your prompts are relatively short (eg. a couple thousand tokens at most), you need/want a large model, you don't need too much scale/speed, and you need to run inference locally, then Macs are a reasonable option. For me personally, I got my M3 Ultra somewhat due to geopolitical issues. I'm barred from accessing some of the SOTA models from the US due to where I live, and sometimes the Chinese models are not conveniently accessible either. With the hardware, they can pry DeepSeek R1, Kimi-K2, etc. from my cold dead hands lol. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.510659",
        "updated_at": "2026-02-09T16:18:49.510659",
        "author": {
          "id": "0a67d1e1c6d17aa646355edae169a066",
          "source_id": "hnfong",
          "username": "hnfong",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "0beed01e795d89fc7a9db7f3d7a7651d",
        "source_id": "46907700",
        "content": {
          "text": "Not a Mac Studio but I use a basic Macbook Pro laptop with 24 GB of RAM (16 usable as VRAM) and I can run a number of models on it at decent speed, my main bottleneck is context window size, but if I am asking single purpose questions I am fine. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.511604",
        "updated_at": "2026-02-09T16:18:49.511604",
        "author": {
          "id": "f43754e59857d27ba34dd678e288cfd0",
          "source_id": "giancarlostoro",
          "username": "giancarlostoro",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "933d03cdc92c3a9e9fc7423d1c3ade17",
        "source_id": "46909525",
        "content": {
          "text": "Yeah. I'm currently on an Mac Mini m2 Pro with 32GB or ram, and I was so curious how much more I could get out of the Apple ecosystem. Thanks for your perspective. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.512579",
        "updated_at": "2026-02-09T16:18:49.512579",
        "author": {
          "id": "e3384f5169c90cc848257efff4e71138",
          "source_id": "UmYeahNo",
          "username": "UmYeahNo",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "7ff2c249327d85edd77cc66d048f8b95",
        "source_id": "46910192",
        "content": {
          "text": "What models are you running? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.513677",
        "updated_at": "2026-02-09T16:18:49.513677",
        "author": {
          "id": "4517893e023b43729a2788f97ea3bd12",
          "source_id": "StrangeSound",
          "username": "StrangeSound",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "0721cb634f13dcfbde66de2e3272474d",
        "source_id": "46921039",
        "content": {
          "text": "The most I ran was a GPT 20b model, I also run SDXL it runs rather quickly via the Draw Things app. There's an 8 step LoRa that lets you generate images in just 8 steps. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.514722",
        "updated_at": "2026-02-09T16:18:49.514722",
        "author": {
          "id": "f43754e59857d27ba34dd678e288cfd0",
          "source_id": "giancarlostoro",
          "username": "giancarlostoro",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "d0910d6a4b95a32c41c10d1fd34ff28d",
        "source_id": "46914767",
        "content": {
          "text": "For anything other than a toy, I would recommend at least a Max processor and at least 32 GB memory, depending on what you're doing. I do a lot of text, audio, and NLP stuff, so I'm running smaller models and my 36GB is plenty. Ultra processors are priced high enough, I'd be asking myself if I'm serious about local LLM work and do a cost analysis. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.515794",
        "updated_at": "2026-02-09T16:18:49.515794",
        "author": {
          "id": "05370b441130fa037368d3902b7fe968",
          "source_id": "runjake",
          "username": "runjake",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "d005d849fbb332912b758e12b4d1915d",
        "source_id": "46930657",
        "content": {
          "text": "Would matmul acceleration in m5 do much to improve token Generation? I’m planning to upgrade when the new studio updates to m5 but if it’s not much of a shift I’ll probably look at a second hand 256+ ram m3 studio. Edit: of course the software would need to leverage the neural accelerators which is another variable if the software supports it in the first place reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.516937",
        "updated_at": "2026-02-09T16:18:49.516937",
        "author": {
          "id": "e13d963a38d94d6195b1137a7977dd70",
          "source_id": "timothyduong",
          "username": "timothyduong",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "d596348a7014210cface983b221220bc",
        "source_id": "46911297",
        "content": {
          "text": "I have an M3 Ultra 96 GB, it works reasonably well with something like qwen/qwen3-vl-30b (fast) or openai/gpt-oss-120b (slow-ish) or openai/gpt-oss-20b (fast, largest context). I keep the latter loaded, and have a cronjob that generates a new MOTD for my shell every 15 minutes with information gathered from various sources. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.518080",
        "updated_at": "2026-02-09T16:18:49.518080",
        "author": {
          "id": "307d1c5fd60ab5e215f7c23edd51108a",
          "source_id": "rlupi",
          "username": "rlupi",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "bd586015b7e80d39b86ccc817e7d582e",
        "source_id": "46914587",
        "content": {
          "text": "M3 Ultra with 256 GB memory, using GPT-OSS 120b in ollama. It’s decently fast, but makes the system somewhat unstable. Have to reboot frequently otherwise the GPU seems to flake (eg visual artifacts / glitches in other programs). reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.519228",
        "updated_at": "2026-02-09T16:18:49.519228",
        "author": {
          "id": "a9f367b1fb655b82d61f853d6a0cf418",
          "source_id": "caterama",
          "username": "caterama",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "1150d76be4c2776eccdcf9d54097938a",
        "source_id": "46912608",
        "content": {
          "text": "M4 mini pro 24gb qwen3-8b-mlx and others. Speed is fine, problem is context window. In theory CoreML would be better from an efficiency perspective but I think it's non-trivial to run models with CoreML ( could be wrong ) reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.520391",
        "updated_at": "2026-02-09T16:18:49.520391",
        "author": {
          "id": "80f69068a86fa1b700d0986d8102ef08",
          "source_id": "stoneforger",
          "username": "stoneforger",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "0f8697cdc295d0c90df3f0e57210a081",
        "source_id": "46910490",
        "content": {
          "text": "There's this post and thread from 7 weeks ago: https://news.ycombinator.com/item?id=46319657 reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.521593",
        "updated_at": "2026-02-09T16:18:49.521593",
        "author": {
          "id": "13a4bd2c9a896b0444b00c3c716d9065",
          "source_id": "manarth",
          "username": "manarth",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "0e20b825a9f83400461f5b71a159ace6",
        "source_id": "46919385",
        "content": {
          "text": "My experience with Mac Studio is that memory bandwidth matters more than raw cores for reasonable LLM throughput locally; curious what others find for models >13B parameters? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.522819",
        "updated_at": "2026-02-09T16:18:49.522819",
        "author": {
          "id": "654947fcdcc3e8dfe50d4ed1f3db6651",
          "source_id": "b_brief",
          "username": "b_brief",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "7ae0a3b58ae8b829c1ae527c6870107b",
        "source_id": "46924554",
        "content": {
          "text": "I have a m3 ultra 256gb and it’s okay. Some coworkers find it too slow, but they also use cerebras… reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.524078",
        "updated_at": "2026-02-09T16:18:49.524078",
        "author": {
          "id": "e779bf2a5bf1d0c7a86c765914d8a937",
          "source_id": "speedgoose",
          "username": "speedgoose",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "1aeb663870ceec76eba0108d34b805ee",
        "source_id": "46907673",
        "content": {
          "text": "Mine is a M1 ultra with 128gb of ram. It's fast enough for me. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.525341",
        "updated_at": "2026-02-09T16:18:49.525341",
        "author": {
          "id": "a3f09592eb859753dfd794f8677658fb",
          "source_id": "mannyv",
          "username": "mannyv",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "0dd3bff1c9d53c32b640fba1ca085689",
        "source_id": "46909527",
        "content": {
          "text": "Thanks for the perspective! reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.526627",
        "updated_at": "2026-02-09T16:18:49.526627",
        "author": {
          "id": "e3384f5169c90cc848257efff4e71138",
          "source_id": "UmYeahNo",
          "username": "UmYeahNo",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "7a6dac5163b7edf85766355d72a71ba3",
        "source_id": "46939174",
        "content": {
          "text": "I went looking for the latest line of apple computers after reading this thread and I noticed they force you into the higher CPU's in order to get the higher amounts of unified memory. So not only are they content charging +$400 or +$600 for RAM which in itself ludicrously overpriced, they force you to upgrade +$1000-2000 on the top CPU's. Its impossible to spec a macbook pro or a mac mini with a base CPU and a decent amount of RAM. Total scam since they know people want the RAM to use with local LLMs. This was not always the case - When I specced out my macbook pro M1 16gb it was entirely possible to get 32 and 64gb without any tie-in to CPU upgrades. I was ready to drop a few grand on a new macbook pro M5 or M4 pro with a decent amount of RAM but it's currently set up to be an insane price gouge. To get 32GB of RAM it's an M5 chip price $1999. To get 64GB of RAM you are forced to to grab the M4 max CPU, and it's $3,899 on apple right now. What a scam. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.528020",
        "updated_at": "2026-02-09T16:18:49.528020",
        "author": {
          "id": "f15c78841b2ae7d01e36eca2745b1bdf",
          "source_id": "kingkongjaffa",
          "username": "kingkongjaffa",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "f3e1d6dadde69cdd19152cf0c4f61248",
        "source_id": "46939235",
        "content": {
          "text": "They're just limiting the range of SKUs they have to manufacture.  For all we know, the base M-series die might not even support that larger amount of in-package memory to begin with. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.529373",
        "updated_at": "2026-02-09T16:18:49.529373",
        "author": {
          "id": "5348656ce06da5ab18187e5b1c97f187",
          "source_id": "zozbot234",
          "username": "zozbot234",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "1f60a11e8bf2a04b9a78a7ea9d1093d0",
        "source_id": "46916834",
        "content": {
          "text": "can only speak for myself here, but the prompt processing speeds on Apple Sillicon is too slow, especially for any meaningful usage reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.530791",
        "updated_at": "2026-02-09T16:18:49.530791",
        "author": {
          "id": "b3abe4863352dfacd3780356bb5410e3",
          "source_id": "callbacked",
          "username": "callbacked",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "d8334842f9fbdad83d45044e6b893b01",
        "source_id": "46911171",
        "content": {
          "text": "Nope, my Macbook Pro is enough for now reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:49.532230",
        "updated_at": "2026-02-09T16:18:49.532230",
        "author": {
          "id": "62da72e0da33870517f37440a7ecd790",
          "source_id": "Adanos",
          "username": "Adanos",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      }
    ],
    "metadata": {
      "crawled_at": "2026-02-09T16:18:49.533289",
      "language": "en-US",
      "keywords": [
        "tech",
        "startup",
        "programming",
        "ask",
        "question"
      ],
      "is_nsfw": false
    }
  },
  {
    "post": {
      "id": "e15282c55d2b02fae3c7cb042cb3a9ef",
      "source_id": "46937690",
      "title": "Ask HN: What made VLIW a good fit for DSPs compared to GPUs?",
      "content": {
        "text": "<div class=\"toptext\" style=\"margin-top:4px\">Why didn’t DSPs evolve toward vector accelerators instead of VLIW, despite having highly regular data-parallel workloads</div>",
        "format": "html",
        "media": []
      },
      "created_at": "2026-02-09T16:18:30.200630",
      "updated_at": "2026-02-09T16:18:30.200630",
      "category": {
        "id": "f31af88693e43c7e98a65941d54a8cd6",
        "name": "Ask HN"
      },
      "tags": [
        "Ask HN",
        "hacker news",
        "tech"
      ],
      "author": {
        "id": "bf1d7cb3bed18e388589ba54cd738982",
        "source_id": "rishabhaiover",
        "username": "rishabhaiover",
        "avatar": "",
        "role": "user",
        "signature": ""
      },
      "stats": {
        "views": 0,
        "likes": 6,
        "dislikes": 0,
        "replies": 0,
        "shares": 0
      }
    },
    "source": {
      "forum": "hackernews",
      "url": "https://news.ycombinator.com/item?id=46937690",
      "section": "Ask HN"
    },
    "replies": [
      {
        "id": "79166f4d4cc3f101721d9ca81fbf9df3",
        "source_id": "46939007",
        "content": {
          "text": "That's not a real dichotomy.  A RISC processor can range from completely lacking vector instructions to including complex matrix multiplications, and a so can a VLIW processor. As far as why there are architectural differences between DSPs and GPUs, the largest reason is that DSPs are designed for processing one-dimensional data, like sensor readings or audio, where as GPUs are designed to process two-dimensional data, like pictures and video.  Adding a dimension greatly increases the complexity of the data-processing algorithms the device will be running. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:51.352398",
        "updated_at": "2026-02-09T16:18:51.352398",
        "author": {
          "id": "4f16e2ba3366acd9b76a63bbce346aa4",
          "source_id": "dlcarrier",
          "username": "dlcarrier",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "350c05c116d9899cccd5077138216fc9",
        "source_id": "46939234",
        "content": {
          "text": "I read this old paper: https://ieeexplore.ieee.org/document/1176257 that compared VLIWs, superscalars and Vector processors for embedded devices and it turns out Vector processors perform the best (for the given benchmark) with the second-lowest power consumption reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:51.352938",
        "updated_at": "2026-02-09T16:18:51.352938",
        "author": {
          "id": "bf1d7cb3bed18e388589ba54cd738982",
          "source_id": "rishabhaiover",
          "username": "rishabhaiover",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "df06353ec7dbcbc2eb577e8fcd159156",
        "source_id": "46945798",
        "content": {
          "text": "VLIW works great when you have predictable & short latencies of memory accesses - you will not find DSP designs that do not use TCM (core local SRAM).\nSo you program DMAs input data into its own TCM and work on it from there.\nGPUs on the other hand hide latencies of memory accesses by switching threads when stalled reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:51.353438",
        "updated_at": "2026-02-09T16:18:51.353438",
        "author": {
          "id": "a0eb34105fb4ef2db277975650d86f6d",
          "source_id": "dspwizard",
          "username": "dspwizard",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      }
    ],
    "metadata": {
      "crawled_at": "2026-02-09T16:18:51.353588",
      "language": "en-US",
      "keywords": [
        "tech",
        "startup",
        "programming",
        "ask",
        "question"
      ],
      "is_nsfw": false
    }
  },
  {
    "post": {
      "id": "d7a2c87c31729d415b44b099455b0705",
      "source_id": "46917633",
      "title": "Ask HN: Ideas for small ways to make the world a better place",
      "content": {
        "text": "<div class=\"toptext\" style=\"margin-top:4px\">I’m looking for some good, specific ideas on small ways to have a positive impact on the world on a daily basis.<p>What do you consider to be the highest return-on-efforts ways to make the world a better place for as many people as possible?</p></div>",
        "format": "html",
        "media": []
      },
      "created_at": "2026-02-09T16:18:30.201261",
      "updated_at": "2026-02-09T16:18:30.201261",
      "category": {
        "id": "f31af88693e43c7e98a65941d54a8cd6",
        "name": "Ask HN"
      },
      "tags": [
        "Ask HN",
        "hacker news",
        "tech"
      ],
      "author": {
        "id": "afb7a8ed941dc6e46bd69ba32aaf2e3b",
        "source_id": "jlmcgraw",
        "username": "jlmcgraw",
        "avatar": "",
        "role": "user",
        "signature": ""
      },
      "stats": {
        "views": 0,
        "likes": 33,
        "dislikes": 0,
        "replies": 0,
        "shares": 0
      }
    },
    "source": {
      "forum": "hackernews",
      "url": "https://news.ycombinator.com/item?id=46917633",
      "section": "Ask HN"
    },
    "replies": [
      {
        "id": "02e799970d2c9ee187d9b48fd6303b1b",
        "source_id": "46946288",
        "content": {
          "text": "Spread beauty. Make your surroundings pleasing to look at. Smile. Don't be ashamed to get caught smelling flowers. Pick up trash. Garden. Respect all creatures as equals worthy of life and consideration, when possible. Agere Contra - don't accept good enough as good enough, in your practices that promote life. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.224370",
        "updated_at": "2026-02-09T16:18:53.224370",
        "author": {
          "id": "e6048331d631fbe743dfdc5ac35179d3",
          "source_id": "ted_bunny",
          "username": "ted_bunny",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "726bd1ad72c9e58d2ebacae5ecbaed7e",
        "source_id": "46919596",
        "content": {
          "text": "Pick up trash you see on the ground. Does not need to be a huge “adopt a highway” style thing. Just pick up that bag on the ground near the bin and put it in the bin. Not only does this make the place cleaner, people watching this may get the warm fuzzies that someone else actually cares. Another thing is to ask employees at stores how their day is. You don’t need to have a full conversation, sometimes people just have nobody ask them this question and it helps. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.224936",
        "updated_at": "2026-02-09T16:18:53.224936",
        "author": {
          "id": "03b0e67a60868662cc91637e0a5257a0",
          "source_id": "galleywest200",
          "username": "galleywest200",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "574e5c6e5742b020dbd7e58834d327eb",
        "source_id": "46918199",
        "content": {
          "text": "People want to feel loved, safe, respected and happy. To make the world a better place start with yourself and make sure you make those things a priority with whoever you interact with. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.225447",
        "updated_at": "2026-02-09T16:18:53.225447",
        "author": {
          "id": "79b58355a6046f759e8cade533c534ee",
          "source_id": "beardyw",
          "username": "beardyw",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "c457ec72cd8502eca39ba54475e6ba7b",
        "source_id": "46919102",
        "content": {
          "text": "Go vegan. You will no longer be apart of horrific animal abuse, the leading cause of biodiversity loss and deforestation, and if done correctly, will likely improve your health. You won't be able to get so much good from doing one thing. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.226002",
        "updated_at": "2026-02-09T16:18:53.226002",
        "author": {
          "id": "33a75721eed89d58b22303a7cd58a959",
          "source_id": "valgor",
          "username": "valgor",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "161c0d233a7ffc120f7bbff9affc887f",
        "source_id": "46946024",
        "content": {
          "text": "And if you can't do that, it's not all or nothing. It's not about keeping your soul pure. Go vegan on weekdays. Or weekends. Or one meal a day. Or do vegetarian instead of vegan. There are a lot of ways to do a nonzero amount of good, and you may inspire others to do so. And this partial commitment allows you to do so without any adjustment to your lifestyle. You will not suffer a B12 or iron deficiency or whatever else you're worried about. You don't have to eat weird foods you're grossed out by. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.226574",
        "updated_at": "2026-02-09T16:18:53.226574",
        "author": {
          "id": "e6048331d631fbe743dfdc5ac35179d3",
          "source_id": "ted_bunny",
          "username": "ted_bunny",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "e0556451f2f40e4f2ee2f276bb4e6909",
        "source_id": "46919292",
        "content": {
          "text": "Maybe a nice halfway point would to be vegetarian... reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.227168",
        "updated_at": "2026-02-09T16:18:53.227168",
        "author": {
          "id": "43d0ef34d31de679ca2811db494783c3",
          "source_id": "GenericDev",
          "username": "GenericDev",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "3e721225e441ace95ad6bc554b5906d2",
        "source_id": "46919874",
        "content": {
          "text": "incremental steps like reducing or eliminating beef consumption by substituting less water intensive meat (e.g. chicken / turkey) are also helpful reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.227783",
        "updated_at": "2026-02-09T16:18:53.227783",
        "author": {
          "id": "50d7ada28424708c69d89f54e07a2486",
          "source_id": "shoo",
          "username": "shoo",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "9ad8333f1c0c85f41404ccd3a9e801b7",
        "source_id": "46925323",
        "content": {
          "text": "Do you know if there are food tracker apps that can incorporate a n emissions style tracker into food planning and eating? For example is it better to opt for imported sardines or for locally grown chicken? I imagine the answer varies. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.228415",
        "updated_at": "2026-02-09T16:18:53.228415",
        "author": {
          "id": "1252968ee17dcb14d39f7d98b7028ee1",
          "source_id": "skyberrys",
          "username": "skyberrys",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "28bdafece3b8ff0e249bbc5b196562bc",
        "source_id": "46922093",
        "content": {
          "text": "This is a fair strategy. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.229092",
        "updated_at": "2026-02-09T16:18:53.229092",
        "author": {
          "id": "290834b258227112339cab84d92bd186",
          "source_id": "simianwords",
          "username": "simianwords",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "39200a1753d38dd442b6a3b0320e0916",
        "source_id": "46921435",
        "content": {
          "text": "Give at least one person per day — whom you otherwise wouldn’t — a few words of genuine and specific appreciation. Friend, family, coworker, stranger. Doesn’t matter. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.229792",
        "updated_at": "2026-02-09T16:18:53.229792",
        "author": {
          "id": "6b7f6c219ea995fc6ef3e9e6eae719d5",
          "source_id": "apothegm",
          "username": "apothegm",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "bf43ac5c3e3d2197c40460b8e45bf77e",
        "source_id": "46946053",
        "content": {
          "text": "It is heartbreaking to see how people's eyes light up when you give them a modicum of recognition. We shouldn't be so starved of love that we expect to walk through a wasteland every day. When I was Lyfting I had people shower me with thanks simply for showing what I consider basic human decency, by having genuine conversations and truly listening. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.230522",
        "updated_at": "2026-02-09T16:18:53.230522",
        "author": {
          "id": "e6048331d631fbe743dfdc5ac35179d3",
          "source_id": "ted_bunny",
          "username": "ted_bunny",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "e7ba04c2ba9dd057e763c5a5bef368c0",
        "source_id": "46918391",
        "content": {
          "text": "Recently posted here on HN and well worth a look: Underrated ways to change the world, part II https://www.experimental-history.com/p/underrated-ways-to-ch... https://news.ycombinator.com/item?id=46873494 Part I is at https://www.experimental-history.com/p/underrated-ways-to-ch... reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.231363",
        "updated_at": "2026-02-09T16:18:53.231363",
        "author": {
          "id": "392c87cfbe6e13124fb85b33deb25872",
          "source_id": "mitchbob",
          "username": "mitchbob",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "65e66b5cad414e5338eecff094deface",
        "source_id": "46946350",
        "content": {
          "text": "Start with fixing yourself. Mental and physical health. Small steps. Will be kinder to others, more tolerant to other's mistakes, etc. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.232144",
        "updated_at": "2026-02-09T16:18:53.232144",
        "author": {
          "id": "e35930b6c9d649b5979aa89705691cfc",
          "source_id": "borsch-dev",
          "username": "borsch-dev",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "1fe63dbf2e149af72a7ee5607040c6bf",
        "source_id": "46937459",
        "content": {
          "text": "I would not over complicate this. My personal four part plan for this is: 1. Donate a portion of my income to charitable causes I find worthy. I would like to target 10% of my net income. 2. Volunteer at a local organization that you care about. There are usually ample opportunities for committed volunteers if you look for them. 3. Have children. Try to raise them to be responsible, caring citizens. That way I can extend my efforts to the next generation. 4. In the near future, I intend to attempt to get involved with local politics somehow. I am still figuring out the specifics, but I am thinking that running for the local school board would be beneficial. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.232994",
        "updated_at": "2026-02-09T16:18:53.232994",
        "author": {
          "id": "f845be8dd6b35a7855df1767ffef47a8",
          "source_id": "erhserhdfd",
          "username": "erhserhdfd",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "0d3c8446b6cb745edfc7dcc73762e5fd",
        "source_id": "46919445",
        "content": {
          "text": "Just talk to strangers and be kind. Compliment people. Let service workers know when they’ve done a good job. Walk around your neighborhood and meet your neighbors. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.233851",
        "updated_at": "2026-02-09T16:18:53.233851",
        "author": {
          "id": "898efed5a4d1844117804f4aa381b161",
          "source_id": "idontwantthis",
          "username": "idontwantthis",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "0f344788d9d162adf8e8e708353b9183",
        "source_id": "46932800",
        "content": {
          "text": "Give way to people crossing the street. I come from Mexico, where millions of people walk and take public transport every day. Unfortunately, poor infrastructure and our mobility culture hurt pedestrians the most. Sometimes people have to wait several minutes just to cross a street. Years ago, a teacher told me that giving way to pedestrians was a simple action to make the world better. It makes a real difference for those who don't have the privilege of being in a car. This stuck with me, and I try to do it whenever possible. It might not apply everywhere with better infrastructure, but I find it to be a small yet meaningful action. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.234749",
        "updated_at": "2026-02-09T16:18:53.234749",
        "author": {
          "id": "a7a156d5450a191c482d2bfc9eec3665",
          "source_id": "coronapl",
          "username": "coronapl",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "58f593f0c68964e6c0d7b8dc33b76d1a",
        "source_id": "46919425",
        "content": {
          "text": "The best time to plant a tree was twenty years ago. The second best is now.* *But also make sure you water, stake and prune it for the first 3-5 years. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.235637",
        "updated_at": "2026-02-09T16:18:53.235637",
        "author": {
          "id": "68c4573d5bf1e8ef7d77bde2557cd27d",
          "source_id": "onlypassingthru",
          "username": "onlypassingthru",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "df74bed01087e2b4aac513104ea8b9ba",
        "source_id": "46939605",
        "content": {
          "text": "Leave every place you visit better than you found it. Example: pick up trash in public spaces such as parks and restrooms. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.236553",
        "updated_at": "2026-02-09T16:18:53.236553",
        "author": {
          "id": "f71d005a57118aad3a28378f25639427",
          "source_id": "treelover",
          "username": "treelover",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "ec3f1ddde735ecb8801fb96448b841a9",
        "source_id": "46933560",
        "content": {
          "text": "Being vocal in local politics. Volunteer in schools to teach children about history, democracy and technology. IMO there are two criteria’s to be a true citizen: 1) not afraid to speak out in public and push back, and 2) be a scientific person reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.237501",
        "updated_at": "2026-02-09T16:18:53.237501",
        "author": {
          "id": "e26822514495bfa8721731ec06ee07bb",
          "source_id": "markus_zhang",
          "username": "markus_zhang",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "e617ea943dbc81a5ef37dc14b95a90ec",
        "source_id": "46919052",
        "content": {
          "text": "Work and take care of your family. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.238479",
        "updated_at": "2026-02-09T16:18:53.238479",
        "author": {
          "id": "58a5e94f84f5db7fb5aad5541c0c19b9",
          "source_id": "Blackstrat",
          "username": "Blackstrat",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "5bc43afd7b992507fec24c2eec1d3a84",
        "source_id": "46917777",
        "content": {
          "text": "This is a great idea!Like I move around a lot in various online communities, I always Encountering all kinds of comments.Please support the comments you think are right, I think this can increase the confidence of the publisher and also makePlease support the comments you think are right, I think this can increase the confidence of the publisher and also make yourself feel happy.When more and more excellent speeches are encouraged, the world will become a little bit better. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.239484",
        "updated_at": "2026-02-09T16:18:53.239484",
        "author": {
          "id": "17dd583791d57fe750826ae91729b342",
          "source_id": "tizzzzz",
          "username": "tizzzzz",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "0a24abd06f54d7ca7fae8157c16e7cb3",
        "source_id": "46917727",
        "content": {
          "text": "https://www.effectivealtruism.org/ at scale. Kindness, listening, time, and financial charity to those around you at the microcosm level. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.240514",
        "updated_at": "2026-02-09T16:18:53.240514",
        "author": {
          "id": "4ca46018a23adaa01543351cde9925a8",
          "source_id": "toomuchtodo",
          "username": "toomuchtodo",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "f2c4397edf80c1ebe49547dddd857e3a",
        "source_id": "46918699",
        "content": {
          "text": "If you're interested in donating and being reasonably assured that your money isn't getting the Worldvision treatment, I highly recommend checking out \"Giving What We Can\" [1] and \"GiveWell\" [2]. - [1] https://www.givingwhatwecan.org/best-charities-to-donate-to-... - [2] https://www.givewell.org/charities/top-charities reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.241622",
        "updated_at": "2026-02-09T16:18:53.241622",
        "author": {
          "id": "dea5e4e88b3c90e43dac73c26f591b9f",
          "source_id": "vunderba",
          "username": "vunderba",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "1f95893e0af3e3db4a06cf00ca1905d5",
        "source_id": "46917903",
        "content": {
          "text": "Better known as \"charity\" among people that don't need their egos stroked. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.242702",
        "updated_at": "2026-02-09T16:18:53.242702",
        "author": {
          "id": "6f8a0ef01950f54a2a0192e326613555",
          "source_id": "bigyabai",
          "username": "bigyabai",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "e7d95e70915c297e3c32d4a8e68b47a4",
        "source_id": "46934042",
        "content": {
          "text": "If you drive, drive safely. Slow down in neighborhoods. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.243812",
        "updated_at": "2026-02-09T16:18:53.243812",
        "author": {
          "id": "fd6c1a6fe6bfe72c77c6492e428a2a07",
          "source_id": "gnz11",
          "username": "gnz11",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "2edba0888fed6450e599669851b8e72f",
        "source_id": "46932675",
        "content": {
          "text": "Just be the change you want to see in the world. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.244956",
        "updated_at": "2026-02-09T16:18:53.244956",
        "author": {
          "id": "2845ad0a586c89a9cc07525be66375d7",
          "source_id": "chistev",
          "username": "chistev",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "9ec24899d55b847b5ce9e18a4439cec2",
        "source_id": "46919265",
        "content": {
          "text": "Be an organ donor. Donate blood on a regular basis. Skeptoid had a podcast today that talks about blood donation with some interesting tidbits about shelf life of platelets and whole blood. (5 days vs 42 days) (Disclaimer: the site I hacked for myself to help me consume podcasts) https://spokengoods.com/podcasts/385078-skeptoid/mic-d-up-br... reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.246160",
        "updated_at": "2026-02-09T16:18:53.246160",
        "author": {
          "id": "4c3a12c04cd259f7ff932edf32cb0e5a",
          "source_id": "yef",
          "username": "yef",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "7e84a6d2b2c2136906603f6b76985048",
        "source_id": "46918724",
        "content": {
          "text": "Be kind. Create beauty. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.247344",
        "updated_at": "2026-02-09T16:18:53.247344",
        "author": {
          "id": "95ada50d39838d43b23b903031022f64",
          "source_id": "wanderingpixel",
          "username": "wanderingpixel",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "0c31e78c44f8c6a30741b7eb5c0f5673",
        "source_id": "46924357",
        "content": {
          "text": "Just making the world better is the simplest thing that might work. highest return-on-efforts ways to make the world a better place for as many people as possible? “Return” is for your ego. So is “as many people as possible.” Good luck. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.248585",
        "updated_at": "2026-02-09T16:18:53.248585",
        "author": {
          "id": "9a688e4c7583fd52091f8f5b41db97b2",
          "source_id": "brudgers",
          "username": "brudgers",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "d1e0c05b8fe702e7a2d2fbe317fe079b",
        "source_id": "46931922",
        "content": {
          "text": "Exactly this. It compounds. I like how someone said go vegan, but really \"eat less beef\" works just as well. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.249841",
        "updated_at": "2026-02-09T16:18:53.249841",
        "author": {
          "id": "65547db35ad470ce1d9e44d413173434",
          "source_id": "muzani",
          "username": "muzani",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "b5de39654dd965bd51611f66501b4b31",
        "source_id": "46928881",
        "content": {
          "text": "Donate to causes you care about. Volunteer your time. Adopt an animal that otherwise might be euthanized. Pick up litter. Be nice to strangers. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.251148",
        "updated_at": "2026-02-09T16:18:53.251148",
        "author": {
          "id": "53577acb18d263f7a8e6b05534aab1d9",
          "source_id": "seattle_spring",
          "username": "seattle_spring",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "27a4e64c1d879be66ab1fe1d2addd18e",
        "source_id": "46922693",
        "content": {
          "text": "I make the world better for myself everyday. Trying to make the world better for others has been a losing battle and one not worth fighting either. People are automatons. They have their own desires and irrational behaviors. So I just focus on my own happiness. Global warming? I’ll optimize to live on coastal California. It should be 60-75F beautiful sunny days until the day I die. Insane politics? I’ll live 2800 miles away around hippies and liberals. I don’t need to watch the news. Things getting expensive? Make more money so it doesn’t affect me. People are suffering everywhere? Dawg I’m suffering too, so I’ll believe in something irrational so it doesn’t affect me. Maybe not what you wanted to hear. But I’m a realist and wasted a few years of my life trying to think of those things. Ultimately, it’s not worth it. I’ll support things that make sense and I don’t eat meat or drive a gas guzzler. What more do you want? When you ask  your titular question you’re already in a minority of the population. Many people continue to make dumbass decisions that affect everyone else in negative ways. I would love to slap them back to their senses, but that’s not allowed. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.252543",
        "updated_at": "2026-02-09T16:18:53.252543",
        "author": {
          "id": "a30a8695019e97e5413f4a0335aae62a",
          "source_id": "moomoo11",
          "username": "moomoo11",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "77d9885a3641b6df2d987e9c55c61100",
        "source_id": "46946198",
        "content": {
          "text": "You sure it's not your outlook? You sound quite disenchanted and even bitter about the topic. I am sure you helped far more people than you think. Focus on gratitude. Or at least like, don't spread bad vibes on the topic. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.253888",
        "updated_at": "2026-02-09T16:18:53.253888",
        "author": {
          "id": "e6048331d631fbe743dfdc5ac35179d3",
          "source_id": "ted_bunny",
          "username": "ted_bunny",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "58968d0fc627c4a7bce1059a49c84ce0",
        "source_id": "46931527",
        "content": {
          "text": "Plant trees. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.255248",
        "updated_at": "2026-02-09T16:18:53.255248",
        "author": {
          "id": "e692c28c186a47e6e5a8b12ab334e567",
          "source_id": "mkbkn",
          "username": "mkbkn",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "827c2f8953245fe7b916788b50f37062",
        "source_id": "46919510",
        "content": {
          "text": "This has been quality answered many times by smartest people but nobody cares. Take Kant for example and go improve yourself, as the only part of the world you can really change. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.256649",
        "updated_at": "2026-02-09T16:18:53.256649",
        "author": {
          "id": "ddc8070c49ef7d2a9f42017d8fdef6dc",
          "source_id": "aristofun",
          "username": "aristofun",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "97e81ef1dfec87681d6420d698a5281e",
        "source_id": "46932135",
        "content": {
          "text": "I'm not a fan of the things proposed by 80000 Hours or other smartest people. There's a lot of people who said that AI would be the most important thing to work on, and those people ended up using AI for evil in the end. Plus it assumes that survival or suffering are the highest priority things, but there's a lot more other things like community and civilization. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:53.258103",
        "updated_at": "2026-02-09T16:18:53.258103",
        "author": {
          "id": "65547db35ad470ce1d9e44d413173434",
          "source_id": "muzani",
          "username": "muzani",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      }
    ],
    "metadata": {
      "crawled_at": "2026-02-09T16:18:53.259179",
      "language": "en-US",
      "keywords": [
        "tech",
        "startup",
        "programming",
        "ask",
        "question"
      ],
      "is_nsfw": false
    }
  },
  {
    "post": {
      "id": "45505c7f902caa410bd67860aca7f5cb",
      "source_id": "46909060",
      "title": "Ask HN: 10 months since the Llama-4 release: what happened to Meta AI?",
      "content": {
        "text": "<div class=\"toptext\" style=\"margin-top:4px\">I understand Llama 4 was a disappointment, but what's happened at Meta since then? Their API is <i>still</i> waitlist-only 10 months on.</div>",
        "format": "html",
        "media": []
      },
      "created_at": "2026-02-09T16:18:30.201867",
      "updated_at": "2026-02-09T16:18:30.201867",
      "category": {
        "id": "f31af88693e43c7e98a65941d54a8cd6",
        "name": "Ask HN"
      },
      "tags": [
        "Ask HN",
        "hacker news",
        "tech"
      ],
      "author": {
        "id": "cf42ad118d8e3f9569b014a41b93cc48",
        "source_id": "Invictus0",
        "username": "Invictus0",
        "avatar": "",
        "role": "user",
        "signature": ""
      },
      "stats": {
        "views": 0,
        "likes": 50,
        "dislikes": 0,
        "replies": 0,
        "shares": 0
      }
    },
    "source": {
      "forum": "hackernews",
      "url": "https://news.ycombinator.com/item?id=46909060",
      "section": "Ask HN"
    },
    "replies": [
      {
        "id": "1bf4bb08ed8639e905d7475d476f7897",
        "source_id": "46909618",
        "content": {
          "text": "Meta research released updated segmentation models a few months ago: https://github.com/facebookresearch/sam-3d-objects https://github.com/facebookresearch/sam3 IMO that's far more valuable to the ecosystem than more AIaaS reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:56.084723",
        "updated_at": "2026-02-09T16:18:56.084723",
        "author": {
          "id": "dadbc1627f7c227cb69d6314dcd43c71",
          "source_id": "joriJordan",
          "username": "joriJordan",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "6bb9d5112a82c276abf10cd479f39d33",
        "source_id": "46910202",
        "content": {
          "text": "AFAIK Zuck got mad and restructured the whole department. What's likely is that there won't be anything open / significant coming out from them anymore reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:56.085242",
        "updated_at": "2026-02-09T16:18:56.085242",
        "author": {
          "id": "e426f5b9715bab94a800df9ba740382e",
          "source_id": "hasperdi",
          "username": "hasperdi",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "4e1612cfec6a7d4294304ecfc6648b34",
        "source_id": "46913133",
        "content": {
          "text": "\"getting Zuck'd\" reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:56.085766",
        "updated_at": "2026-02-09T16:18:56.085766",
        "author": {
          "id": "1930ca485b4f0b9ad53265089cd22d16",
          "source_id": "red-iron-pine",
          "username": "red-iron-pine",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "08acbc97ea716a63d89669b6d8f0c360",
        "source_id": "46910987",
        "content": {
          "text": "History suggests that when Zuck takes a personal interest in a project, it tends to derail. Metas AI initiative might be headed for the same fate as his previous obsessions. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:56.086290",
        "updated_at": "2026-02-09T16:18:56.086290",
        "author": {
          "id": "d23accdaabd783a261d54435807fd8d1",
          "source_id": "BoredPositron",
          "username": "BoredPositron",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "6e7f867da3df60cfac6e5b6f73ddcca8",
        "source_id": "46911390",
        "content": {
          "text": "I wonder why they did not yet rename themselves to \"AI\" or \"Llama\" because surely Metaverse (\"Meta\") is not a hot thing anymore? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:56.086864",
        "updated_at": "2026-02-09T16:18:56.086864",
        "author": {
          "id": "60568925455ec931e1a13eedf6fc0cb9",
          "source_id": "egorfine",
          "username": "egorfine",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "6c8f2c415bfd7d7b0c60087b118e49f8",
        "source_id": "46910356",
        "content": {
          "text": "Poor leadership I will say.\nSo much funds and still they could not do better. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:56.087447",
        "updated_at": "2026-02-09T16:18:56.087447",
        "author": {
          "id": "0f7b86dc3041a2427e45b2ef2a928788",
          "source_id": "dhruv3006",
          "username": "dhruv3006",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "7a87b20b46d8c33eccf3fe323c441562",
        "source_id": "46909077",
        "content": {
          "text": "I recall rumors that those people they hired at astronomical figures are just fucking around because they know Marc will look bad if he fires them The most likely reason is internal dysfunction, they certainly have the resources to keep the same release pace reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:56.088081",
        "updated_at": "2026-02-09T16:18:56.088081",
        "author": {
          "id": "0555c16ed7f938be906cf20d79b97096",
          "source_id": "verdverm",
          "username": "verdverm",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "b8bfb2649565569b8d0a19ba0f827380",
        "source_id": "46944800",
        "content": {
          "text": "Isn't this something straight out of Sillicon Valley show ?  Life imitating art I suppose ... reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:56.088726",
        "updated_at": "2026-02-09T16:18:56.088726",
        "author": {
          "id": "48f4b73eea2892b59938cda5d8a0e952",
          "source_id": "v-erne",
          "username": "v-erne",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "95ac26e3921abb9dc9f827a9326a08c7",
        "source_id": "46909551",
        "content": {
          "text": "Doesn't Facebook already have an ad platform? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:56.089378",
        "updated_at": "2026-02-09T16:18:56.089378",
        "author": {
          "id": "55e37abe0039d498e2b50695a38a562c",
          "source_id": "fuzzfactor",
          "username": "fuzzfactor",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "a860bf09dc37a804f56a5edb8c91ae63",
        "source_id": "46911470",
        "content": {
          "text": "fell off the Llama reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:56.090103",
        "updated_at": "2026-02-09T16:18:56.090103",
        "author": {
          "id": "6ac617408a9df018fc90723cbfd647b1",
          "source_id": "villgax",
          "username": "villgax",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "cb0bb36e716147d71a389433643690c1",
        "source_id": "46910418",
        "content": {
          "text": "Weird that Zuck is still huffing the open platform copium when everyone outside the US uses deepseek reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:56.090826",
        "updated_at": "2026-02-09T16:18:56.090826",
        "author": {
          "id": "1d7f30880ac4e87ab4a978de0679511f",
          "source_id": "casey2",
          "username": "casey2",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "aa66f1c5a240adf5b5d4ea7e60be18a9",
        "source_id": "46915068",
        "content": {
          "text": "The AI bubble is starting to burst. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:56.091561",
        "updated_at": "2026-02-09T16:18:56.091561",
        "author": {
          "id": "57843dc71e4ab6888a8d7419137ae0f0",
          "source_id": "OGEnthusiast",
          "username": "OGEnthusiast",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      }
    ],
    "metadata": {
      "crawled_at": "2026-02-09T16:18:56.091969",
      "language": "en-US",
      "keywords": [
        "tech",
        "startup",
        "programming",
        "ask",
        "question"
      ],
      "is_nsfw": false
    }
  },
  {
    "post": {
      "id": "e02c02ed695e53b6be907e5a0ce8ae0b",
      "source_id": "46919016",
      "title": "Ask HN: Non AI-obsessed tech forums",
      "content": {
        "text": "<div class=\"toptext\" style=\"margin-top:4px\">Since it seems like 80% of HN nowadays is focussed on the AI industry, I’m on the search for a good tech forum that focuses on the rest. Can you post your favourite non-AI-obsessed forum?</div>",
        "format": "html",
        "media": []
      },
      "created_at": "2026-02-09T16:18:30.202583",
      "updated_at": "2026-02-09T16:18:30.202583",
      "category": {
        "id": "f31af88693e43c7e98a65941d54a8cd6",
        "name": "Ask HN"
      },
      "tags": [
        "Ask HN",
        "hacker news",
        "tech"
      ],
      "author": {
        "id": "6a314614c34932af11146793a9d68b56",
        "source_id": "nanocat",
        "username": "nanocat",
        "avatar": "",
        "role": "user",
        "signature": ""
      },
      "stats": {
        "views": 0,
        "likes": 45,
        "dislikes": 0,
        "replies": 0,
        "shares": 0
      }
    },
    "source": {
      "forum": "hackernews",
      "url": "https://news.ycombinator.com/item?id=46919016",
      "section": "Ask HN"
    },
    "replies": [
      {
        "id": "8215107f650efce9fa620b5d2d0364a6",
        "source_id": "46920547",
        "content": {
          "text": "Asking to have a tech forum in 2026 that doesn’t discuss  AI is about as much of a Luddite as asking about having tech forum anytime in the past 25 years that doesn’t discuss the internet or the 15 that doesn’t discuss mobile. Absolutely everything in tech is touched by AI/ML in 2026 except micro controllers/embedded systems On another note - YC 25 batch https://www.extruct.ai/data-room/ycombinator-companies-s25/ YC 24 batch https://docs.google.com/spreadsheets/d/1Uy2aWoeRZopMIaXXxY2E... On a personal note, I lead cloud + app dev implementations for a consulting company.  I’ve had 5 projects since the beginning of last year and they have all involved Amazon hosted LLMs in some form or fashion. Every single project I’ve been brought in with at pre sales has also involved Gen AI and/or traditional ML. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.540139",
        "updated_at": "2026-02-09T16:18:57.540139",
        "author": {
          "id": "646941a85e859767254d97ee8f8f4eec",
          "source_id": "raw_anon_1111",
          "username": "raw_anon_1111",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "a0bf178754f5eab5048ebe38afa5986f",
        "source_id": "46922321",
        "content": {
          "text": "There are plenty of tech forums that don't discuss AI. I think your confusion might be the result of you equating tech with \"writing code for employers.\" By the way, have you seriously never written[1] so much as a single backup script to back up a personal system? You only use GUI backup software? [1] https://news.ycombinator.com/item?id=46634535#:~:text=As%20f... reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.540682",
        "updated_at": "2026-02-09T16:18:57.540682",
        "author": {
          "id": "cf0439b987ee2780157d073ea7f7687b",
          "source_id": "subsection1h",
          "username": "subsection1h",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "995b558e05c78ae56440e61f119b6d7b",
        "source_id": "46922637",
        "content": {
          "text": "I haven’t actually used my personal computer for much after graduating from college. 1. To access the internet 2. To download music from Napster and later iTunes  and to create mix CDs and later for my iPod 3. To mix music with CoolEdit (bought by Adobe as Adobe Audition) - I was a fitness instructor and created my own 32 bpm beat synchronized music 4. As a home media theater PC (Mac Mini + Front Row) and later a media server (Plex) My backup was running BackBlaze.  When  we moved and I decided Plex + bit torrent wasn’t worth the hassle, I did a one time “aws s3 -sync…” and copied my 2TB of media to AWS S3 Glacier Deep Archive in my personal account.  I’ve opened my personal computer - that I only bought for a one time contract for a former CTO/friend when I was between jobs for a month. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.541295",
        "updated_at": "2026-02-09T16:18:57.541295",
        "author": {
          "id": "646941a85e859767254d97ee8f8f4eec",
          "source_id": "raw_anon_1111",
          "username": "raw_anon_1111",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "523f36c6b54eed9efa986859c58b00d1",
        "source_id": "46920774",
        "content": {
          "text": "Yes we already know it's omnipresent, that's the point. Some would rather lead in a different direction than follow like NPCs. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.541854",
        "updated_at": "2026-02-09T16:18:57.541854",
        "author": {
          "id": "61daf00386365c2ed22650371eb036ed",
          "source_id": "add-sub-mul-div",
          "username": "add-sub-mul-div",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "4ab8c84f7412d4e57821477a6320fe6c",
        "source_id": "46920851",
        "content": {
          "text": "I too wish the world hadn’t moved on from when I started programming on a 1Mhz Apple //e in 1986 or from my first  job as a Fortran and C programmer on DEC Vax and stratus VOS mainframes… I also loved programming on these in 2007 using Windows Compact Framework. https://weareconker.com/blog/is-windows-ce-still-supported-i... But after being in this game for 30 years professionally and after half century of living on this earth, I still haven’t overcome my addictions to food and shelter and while I’m in pretty good shape, I don’t think I could start a successful career by opening an OnlyFans account so instead, I keep up to date on where the industry is… reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.542473",
        "updated_at": "2026-02-09T16:18:57.542473",
        "author": {
          "id": "646941a85e859767254d97ee8f8f4eec",
          "source_id": "raw_anon_1111",
          "username": "raw_anon_1111",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "86aae489cbd4dd7e277c7723b29a1190",
        "source_id": "46931929",
        "content": {
          "text": "> I’ve had 5 projects since the beginning of last year and they have all involved Amazon hosted LLMs in some form or fashion. Cargo cultists are going to cargo cult. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.543101",
        "updated_at": "2026-02-09T16:18:57.543101",
        "author": {
          "id": "eb1c39740e6c527e8b590c737a4a698a",
          "source_id": "stephenr",
          "username": "stephenr",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "672648cd38480c8236733d0c93cbfe93",
        "source_id": "46923735",
        "content": {
          "text": "HN is the low AI version. Social media has made it normal to have closed social circles. You like a couple posts by Karpathy and LeCun and your feed is now full of AI. Or you like a post by the anti-AI folks and your feed is now on how useless or harmful it is. With HN, we all see the same news. But now it's far to the extreme of either party. HN is often around the early majority of the Innovation Adoption curve. I was actually going to ask why Clawdbot wasn't even mentioned on HN when it had been everywhere else... but the news did hit the front page a few days later. There's a few killer updates from the AI coding groups which only get 0-2 upvotes and disappear. HN is not the place to go to be up to date on AI, it's where you go to see the news that has hit the mainstream. Opus 4.6 was \"leaked\" on media and hyped as if it were Claude 5 or something. By the time the news was actually out, people had formed their opinions. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.543803",
        "updated_at": "2026-02-09T16:18:57.543803",
        "author": {
          "id": "65547db35ad470ce1d9e44d413173434",
          "source_id": "muzani",
          "username": "muzani",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "77762c16bbbf9a88be547777abcfa0cc",
        "source_id": "46920584",
        "content": {
          "text": "I don't think its possible, you're just going to have to wait for the hype to die down like any hype wave When's the last time you saw blockchain on the front page? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.544474",
        "updated_at": "2026-02-09T16:18:57.544474",
        "author": {
          "id": "a9a2a5f05ea1ec03572c069094ebe64c",
          "source_id": "ex-aws-dude",
          "username": "ex-aws-dude",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "df911226170c698ad8d2f20cd8097d22",
        "source_id": "46921460",
        "content": {
          "text": "Blockchain was useless and in 5.5 years of working in cloud consulting - first at AWS and now at a 3rd party firm, I never once heard a serious business ask - “how can we make or save money using the blockchain”. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.545176",
        "updated_at": "2026-02-09T16:18:57.545176",
        "author": {
          "id": "646941a85e859767254d97ee8f8f4eec",
          "source_id": "raw_anon_1111",
          "username": "raw_anon_1111",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "05e09aae467b0e426f69049aa88293ad",
        "source_id": "46924650",
        "content": {
          "text": "You're too late, businesses absolutely did ask that before 2020 when the hype was at its peak. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.545905",
        "updated_at": "2026-02-09T16:18:57.545905",
        "author": {
          "id": "20df84de1a82e678fc3b5c42c0d9bc89",
          "source_id": "satvikpendem",
          "username": "satvikpendem",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "731c3971e880352fffa653e7cb7bb371",
        "source_id": "46924689",
        "content": {
          "text": "Regular old boring profitable f500 enterprises? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.546646",
        "updated_at": "2026-02-09T16:18:57.546646",
        "author": {
          "id": "646941a85e859767254d97ee8f8f4eec",
          "source_id": "raw_anon_1111",
          "username": "raw_anon_1111",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "8a0c829f0768dad7ec359aade22da76a",
        "source_id": "46924725",
        "content": {
          "text": "Lots of examples, such as Walmart and IBM's collaboration: https://www.researchgate.net/publication/326188675_Food_Trac... reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.547445",
        "updated_at": "2026-02-09T16:18:57.547445",
        "author": {
          "id": "20df84de1a82e678fc3b5c42c0d9bc89",
          "source_id": "satvikpendem",
          "username": "satvikpendem",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "1f7400478dcaa2b2e9969987cd5f7c74",
        "source_id": "46921212",
        "content": {
          "text": "HN minus AI: https://histre.com/hn/?tags=+all-ai (Dis: it's mine, but it's free) reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.548293",
        "updated_at": "2026-02-09T16:18:57.548293",
        "author": {
          "id": "a0083a6d353f7a6621fe948b13608a0a",
          "source_id": "kirubakaran",
          "username": "kirubakaran",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "571f8edbed038f99961bb457a3441b5d",
        "source_id": "46922146",
        "content": {
          "text": "This is cool! Thanks for sharing it. I’m more interested in forums that attract a crowd much more measured and skeptical about AI, though - I know there are a lot of you here at HN (like me) reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.549138",
        "updated_at": "2026-02-09T16:18:57.549138",
        "author": {
          "id": "6a314614c34932af11146793a9d68b56",
          "source_id": "nanocat",
          "username": "nanocat",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "0c15c78e5ca8d055ed2318dfec419557",
        "source_id": "46925585",
        "content": {
          "text": "Yeah honestly I've been racking my brain about the same question (where can I move on to). HN has been my home for learning about all sorts of things for 10+ years but blockchain + AI has just killed all interesting discussion that can be had. It's hard to define a community around \"not being obsessed\" with something. Maybe instead it's worth thinking about what the goal of such a community / forum is. Might be easier to find / define. If you come up with something I'm happy to check it out. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.550029",
        "updated_at": "2026-02-09T16:18:57.550029",
        "author": {
          "id": "e13cee9e8424d1d1f1010ede809fc975",
          "source_id": "3vidence",
          "username": "3vidence",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "a474555bdd4cca7be491add85239d3c0",
        "source_id": "46919907",
        "content": {
          "text": "Only about 20% of front-page links are related to AI. I think it's impossible to have a productive discussion on the tech industry nowadays without AI in context. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.550919",
        "updated_at": "2026-02-09T16:18:57.550919",
        "author": {
          "id": "1f695a69b7de901b3ddae7422aaa4175",
          "source_id": "atleastoptimal",
          "username": "atleastoptimal",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "2271489ab8d2632abb6eaaf81b664748",
        "source_id": "46919932",
        "content": {
          "text": "¯\\_(ツ)_/¯ There are far fewer posts about \"politics\" than AI, and they all get flagged ruthlessly even when they have a legitimate tech angle. If people don't like AI related content then I encourage them to treat those posts the way they do politics. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.551851",
        "updated_at": "2026-02-09T16:18:57.551851",
        "author": {
          "id": "14d688e3a965535c98d7ae36741a9df8",
          "source_id": "krapp",
          "username": "krapp",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "202e4cfcbabf27dc4d7d1e17c83d12f0",
        "source_id": "46920892",
        "content": {
          "text": "On the contrary, I don't think productive discussions (or even interesting ones) can be had about AI. We've seen what it has to offer (not much), now we are just waiting for the hype bubble to burst like it did for blockchain and so many other things before. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.552806",
        "updated_at": "2026-02-09T16:18:57.552806",
        "author": {
          "id": "ed99bc9b0e9a3d5006544943dc85da1f",
          "source_id": "bigstrat2003",
          "username": "bigstrat2003",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "5dda20fc61209437d8a8d0a2c644099c",
        "source_id": "46941963",
        "content": {
          "text": "Lobsters and filter posts with vibecoding tag. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.553782",
        "updated_at": "2026-02-09T16:18:57.553782",
        "author": {
          "id": "cb6340728d204519f66eb9503b95f765",
          "source_id": "nextos",
          "username": "nextos",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "a15a9b22c19901bf65c429ad682afffb",
        "source_id": "46926120",
        "content": {
          "text": "Remember to go to https://news.ycombinator.com/newest and upvote good stuff. Most is bad, but there are undiscovered gem from time to time. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.554806",
        "updated_at": "2026-02-09T16:18:57.554806",
        "author": {
          "id": "851b0a301970b5ad319b0814d1286f40",
          "source_id": "gus_massa",
          "username": "gus_massa",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "3eae173860a33db9a7e41ec030b0fdb9",
        "source_id": "46919085",
        "content": {
          "text": "https://news.ycombinator.com/active reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.555842",
        "updated_at": "2026-02-09T16:18:57.555842",
        "author": {
          "id": "38f3f8222189068e76698b02dad536e3",
          "source_id": "lucenet",
          "username": "lucenet",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "6a7c7996f38ee92b9b5830464d7b86ac",
        "source_id": "46919787",
        "content": {
          "text": "Try lobsters and probably Reddit which have a hard stance against AI. You're right in HN heading down the path in favouring slop, constant posts and startups about AI with now 'influencers' (simonw in particular) aggressively posting and shilling AI. With the moderators knowing that these 'influencers' and their kind violate the HN guidelines every day by purposefully linking back to their site for farming backlinks. It might as well be called AI news. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.556934",
        "updated_at": "2026-02-09T16:18:57.556934",
        "author": {
          "id": "0274b0e63821b973c79e978c25eb1579",
          "source_id": "kgraves",
          "username": "kgraves",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "cddfe3e49d5df3106a55e457a0239fd2",
        "source_id": "46921874",
        "content": {
          "text": "Lobsters stance is anti-AI and cautious at best. But plenty of AI-related articles there. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.558007",
        "updated_at": "2026-02-09T16:18:57.558007",
        "author": {
          "id": "6d42080e3893ce643870c551b073a4f8",
          "source_id": "csomar",
          "username": "csomar",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "d19622e1135ea2f8f264affe854c9458",
        "source_id": "46926498",
        "content": {
          "text": "I like that for all the LLM/agentic news spam they apply the tag \"vibecoding\" (derogatory) reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.559113",
        "updated_at": "2026-02-09T16:18:57.559113",
        "author": {
          "id": "7d0b39bf6b7f729c8f9c43a6da410109",
          "source_id": "sph",
          "username": "sph",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "d712e5e696af99b00ea4fb32572490a9",
        "source_id": "46931947",
        "content": {
          "text": "And more importantly users can hide articles by tag. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.560262",
        "updated_at": "2026-02-09T16:18:57.560262",
        "author": {
          "id": "eb1c39740e6c527e8b590c737a4a698a",
          "source_id": "stephenr",
          "username": "stephenr",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "2345db7dff9ddad612644f9aaf3ef749",
        "source_id": "46921842",
        "content": {
          "text": "Lobste.rs has a hard stance against AI? This can't be true. I browse the front page every so often & there seems to be a fair amount of overlap between it and HN. At least for the upvoted articles. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.561430",
        "updated_at": "2026-02-09T16:18:57.561430",
        "author": {
          "id": "248a62cf45159da38bf273a9e1b5c308",
          "source_id": "stuxnet79",
          "username": "stuxnet79",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "db1667a1453f0071fcc13f80ba5233ef",
        "source_id": "46931943",
        "content": {
          "text": "There isn't a hard stance against it but it's generally not well received IMO and importantly, lobsters is written by people who understand other people have different needs and they provide the option to filter out articles by tags, rather than relying on a concept of \"you will see everything or you will see what the crowd deems worthy\". reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.562631",
        "updated_at": "2026-02-09T16:18:57.562631",
        "author": {
          "id": "eb1c39740e6c527e8b590c737a4a698a",
          "source_id": "stephenr",
          "username": "stephenr",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "dce53de7776f90ec9f9cf4c3b51a96b8",
        "source_id": "46940885",
        "content": {
          "text": "hYpeCombinator reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.563862",
        "updated_at": "2026-02-09T16:18:57.563862",
        "author": {
          "id": "dd7862a8e0f46caf971a2cc289857874",
          "source_id": "otreblatercero",
          "username": "otreblatercero",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "bc205d325cc7bc33fa5445f0bac1bd85",
        "source_id": "46919189",
        "content": {
          "text": "If you are feeling overwhelmed with slop posts about ai, camp on the new page and upvote any halfway decent story about something else.  Many of us would thank you if they knew. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.565111",
        "updated_at": "2026-02-09T16:18:57.565111",
        "author": {
          "id": "e760097489e9389b620772b6f7bd8da6",
          "source_id": "PaulHoule",
          "username": "PaulHoule",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "624f1f1a70e2b08ca7e590291ba86212",
        "source_id": "46935807",
        "content": {
          "text": "This is roughly what I've been doing. I consider it a duty: Occasionally (once or more a day) review \"new\". Flag any spam articles, or generic LLM hype articles; update science or non-LLM-focused technology ones. I even upvote AI or LLM-centered articles if they're not centered on \"How agents and vibe coding have/haven't/will/will not changed everything about coding\" - it's these that have grown intolerable in the past few weeks. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.566395",
        "updated_at": "2026-02-09T16:18:57.566395",
        "author": {
          "id": "42cb47f54f5bcba5a9c40b3b2db7f022",
          "source_id": "the__alchemist",
          "username": "the__alchemist",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "8c556c5ece5eb128b31768bcf3593fce",
        "source_id": "46922596",
        "content": {
          "text": "also, RSS is an alternative to camping reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.567707",
        "updated_at": "2026-02-09T16:18:57.567707",
        "author": {
          "id": "95262e40b853fa309aa7b4bd1b1c15c5",
          "source_id": "aebtebeten",
          "username": "aebtebeten",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "0dcec5d79199e99be52452ad68f84c29",
        "source_id": "46922846",
        "content": {
          "text": "Tangential: Afaict mods are on our side, despite whatever \"aggregated\" data \"suggest\" This site (which I peruse everyday) claims that 3 AI articles were modded down today, but in actual fact the single nonAI article that was supposed to have been modded down was modded up. https://github.com/vitoplantamura/HackerNewsRemovals?tab=rea... I trust however, that the political calls are representative One has to delve into the data before arriving at broad judgements :) reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.569111",
        "updated_at": "2026-02-09T16:18:57.569111",
        "author": {
          "id": "c5a7e1de42a7be1e2f250783e8861ef7",
          "source_id": "gsf_emergency_6",
          "username": "gsf_emergency_6",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "1ec9e0f3d27dc3b7e0aacf27872a6daf",
        "source_id": "46924914",
        "content": {
          "text": "the fediverse reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.570463",
        "updated_at": "2026-02-09T16:18:57.570463",
        "author": {
          "id": "1255f856e79dc3f030a4c8b1199dff6a",
          "source_id": "mmphosis",
          "username": "mmphosis",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "1b8939b9dea2fa3e5e08c611b9379280",
        "source_id": "46921001",
        "content": {
          "text": "lainchan reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:18:57.571876",
        "updated_at": "2026-02-09T16:18:57.571876",
        "author": {
          "id": "7b174f109a37eaf12aa760c540218089",
          "source_id": "sepulchreroot",
          "username": "sepulchreroot",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      }
    ],
    "metadata": {
      "crawled_at": "2026-02-09T16:18:57.572946",
      "language": "en-US",
      "keywords": [
        "tech",
        "startup",
        "programming",
        "ask",
        "question"
      ],
      "is_nsfw": false
    }
  },
  {
    "post": {
      "id": "8d45bd5bc4bdcdb663e2e6ada1942aa2",
      "source_id": "46896309",
      "title": "Ask HN: Has your whole engineering team gone big into AI coding? How's it going?",
      "content": {
        "text": "<div class=\"toptext\" style=\"margin-top:4px\">I'm seeing individual programmers who have moved to 100% AI coding, but I'm curious as to how this is playing out for larger engineering teams. If you're on a team (let's say 5+ engineers) that has adopted Claude Code, Cursor, Codex, or some other agent, can you share how it's going? Are you seeing more LOCs created? Has PR velocity or PR complexity changed? Do you find yourself spending the same amount of time on PRs, less, or more?</div>",
        "format": "html",
        "media": []
      },
      "created_at": "2026-02-09T16:18:30.203432",
      "updated_at": "2026-02-09T16:18:30.203432",
      "category": {
        "id": "f31af88693e43c7e98a65941d54a8cd6",
        "name": "Ask HN"
      },
      "tags": [
        "Ask HN",
        "hacker news",
        "tech"
      ],
      "author": {
        "id": "312e37f8c78e06abc8717b35aae8205e",
        "source_id": "jchung",
        "username": "jchung",
        "avatar": "",
        "role": "user",
        "signature": ""
      },
      "stats": {
        "views": 0,
        "likes": 21,
        "dislikes": 0,
        "replies": 0,
        "shares": 0
      }
    },
    "source": {
      "forum": "hackernews",
      "url": "https://news.ycombinator.com/item?id=46896309",
      "section": "Ask HN"
    },
    "replies": [
      {
        "id": "fdc3cce4a38336c7ee61177e5a2fdb9a",
        "source_id": "46896499",
        "content": {
          "text": "Not a full team adoption story, but relevant data point: I run a small engineering org (~40 engineers across teams) and we've been tracking AI coding tool adoption informally. The split is roughly: 30% all-in (Claude Code or Cursor for everything), 50% selective users (use it for boilerplate, tests, docs but still hand-write core logic), 20% holdouts. What I've noticed on PR velocity: it went up initially, then plateaued. The PRs got bigger, which means reviews take longer. We actually had to introduce a \"max diff size\" policy because AI-assisted PRs were becoming 800+ line monsters that nobody could review meaningfully. The quality concern that keeps coming up: security. AI-generated code tends to take shortcuts on auth, input validation, error handling. We've started running dedicated security scans specifically tuned for patterns that AI likes to produce. That's been the biggest process change. Net effect: probably 20-30% faster on feature delivery, but we're spending more time on review and security validation than before. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:00.105067",
        "updated_at": "2026-02-09T16:19:00.105067",
        "author": {
          "id": "88d176057db9aacfad9c4fd4651dba81",
          "source_id": "the_harpia_io",
          "username": "the_harpia_io",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "116c6e3965fde6dd2699f2216c909b42",
        "source_id": "46899720",
        "content": {
          "text": "The joke I hear is Claude Code will double your PRs One PR from Claude. The next PR from you fixing Claude’s mistakes. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:00.105603",
        "updated_at": "2026-02-09T16:19:00.105603",
        "author": {
          "id": "d51a6fc1b88e0387f63191816cd49032",
          "source_id": "softwaredoug",
          "username": "softwaredoug",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "667f7c67e4c3ab37f2e85e6b09d5aee6",
        "source_id": "46904316",
        "content": {
          "text": "Ha, pretty accurate in my experience. Though I'd say it's more like 1.5x the PRs - Claude does the initial PR, then you do half a PR fixing the subtle stuff it got wrong, and then you spend the other half wondering if you missed something. The security fixes are the worst because the code looks correct. It's not like a typo you'd catch immediately - it's an auth check that works for 95% of cases but fails on edge cases the model never considered. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:00.106164",
        "updated_at": "2026-02-09T16:19:00.106164",
        "author": {
          "id": "88d176057db9aacfad9c4fd4651dba81",
          "source_id": "the_harpia_io",
          "username": "the_harpia_io",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "777c582768fe1724875c847edc91f8f4",
        "source_id": "46900051",
        "content": {
          "text": "I have seen the same Ai hallucinations that you mentioned: auth, input validation, error handling, non-existent dependencies, etc. It's tricky to get them all as LLM's have mastered the art of being \"confidently wrong\". What tools are you using to catch those issues? I feel current tooling is ill equiped for this new wave of Ai generated output. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:00.106719",
        "updated_at": "2026-02-09T16:19:00.106719",
        "author": {
          "id": "e4b228e8f67ff0711f8a49adb17ba086",
          "source_id": "boghy8823",
          "username": "boghy8823",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "f66c7953a2841e1839220561cb5f7be2",
        "source_id": "46901711",
        "content": {
          "text": "\"Confidently wrong\" is the perfect description. The code compiles, the tests pass (because the AI also wrote the tests to match), and the auth flow looks reasonable at first glance. For catching these we layer a few things: - Standard SAST (Semgrep, CodeQL) catches the obvious stuff but misses AI-specific patterns\n- npm audit / pip-audit for dependency issues, especially non-existent packages the AI hallucinates\n- Custom rules tuned for patterns we keep seeing: overly permissive CORS, missing rate limiting, auth checks that look correct but have subtle logic bugs\n- Manual review with a specific checklist for AI-generated code (different from our normal review checklist) You're right that current tooling has a gap. Traditional scanners assume human-written code patterns. AI code looks structurally different - it tends to be more verbose but miss edge cases in ways humans wouldn't. We've been experimenting with scanning approaches specifically tuned for AI output. The biggest wins have been simple: requiring all AI-generated auth and input validation code to go through a dedicated security reviewer, not just a regular code review. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:00.107335",
        "updated_at": "2026-02-09T16:19:00.107335",
        "author": {
          "id": "88d176057db9aacfad9c4fd4651dba81",
          "source_id": "the_harpia_io",
          "username": "the_harpia_io",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "e3a1ea9fd8db8dcf428d94cb9975a190",
        "source_id": "46941752",
        "content": {
          "text": "On small teams, AI feels like a big boost. On larger teams, it mostly just moves the work around. We (12+ people on the team) see more LOC and faster first drafts, but also more review work. PRs look done early, but often hide shallow thinking or edge cases. Velocity goes up on paper. Review fatigue goes up too. The best teams treat AI like a junior dev with infinite energy. Great for boilerplate and refactors, but you still need ownership. Otherwise you just ship bugs faster, which is not great honestly. Wdyt? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:00.107968",
        "updated_at": "2026-02-09T16:19:00.107968",
        "author": {
          "id": "61663ddd2ce874082d8d92ad4700ac52",
          "source_id": "avin01",
          "username": "avin01",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "37587f289a3a1070c7620d29355581a5",
        "source_id": "46901435",
        "content": {
          "text": "Here are some real examples from our projects in 2025 at SIROC (for context: we are a 18 people venture studio; 140+ projects completed): * A task estimated at 4 hours → solved with one well specified prompt * A 20 hour engineering effort → executed in about 3 hours * A 3 month project → delivered in 1 month These are clearly best case scenarios. They are not the norm, yet. But they demonstrate what is possible. We have also seen what happens when things go wrong. Companies, including startups, come to us with broken systems and spaghetti code and architecture caused by weak prompts, unclear requirements, and no verification. It is important to understand that the efficiency gains we are seeing do not come from the tools alone. They come from a specific combination: 1) Engineers who have spent 20 years building everything from robotics to enterprise-scale technology. You cannot give a perfect instruction to an AI if you do not know what perfect looks like in a production environment. 2) A technical prompt should not be treated as a quick input or question. It is a detailed specification that requires experience and deliberate thinking. 3) Knowing the right combination of tools, workflows, and validation processes. That said, some (many?) members of our team are dinosaurs in the software engineering world. They bring a ton of experience but are used to tools from 15 years ago and don't like change. We really had to push AI adoption (mostly Cursor and Claude Code) on them. It’s still an ongoing process, and probably will be for a while. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:00.108761",
        "updated_at": "2026-02-09T16:19:00.108761",
        "author": {
          "id": "3f3a34785550646e6ce4d407b514f8a8",
          "source_id": "znq",
          "username": "znq",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "1b57e0c4b53305d1420f02e0af80a977",
        "source_id": "46926562",
        "content": {
          "text": "I was thinking last night about whether this is even a realistic moat or not. Right now, Claude is getting trained by hundreds of thousands of programmers showing it how to ask the right architecture + PM questions. They're just patterns, like anything else in our industry, and most of them are pretty standard patterns. Like when I think back on 20 years of software architecture and BA work, I've done the same thing over and over. I must have implemented 4 PO systems, 3 different custom chat systems, SMS systems for reminders, monthly summary emails, etc. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:00.109433",
        "updated_at": "2026-02-09T16:19:00.109433",
        "author": {
          "id": "cdd85acf7c11fa6426632f133b3af3d6",
          "source_id": "mattmanser",
          "username": "mattmanser",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "f42391d76bfccb1471d7e97b080d8fc5",
        "source_id": "46924089",
        "content": {
          "text": "Some people seem like fully gave in to using AI for everything, and nothing better than receiving multiple review requests per day for 2k+ diff PRs.. where most of the stuff is just \"wtf\" type of refactoring and added noise Also funny to hear reactions when I'm grepping code for a function in front of someone and I hear \"wow you look for code I would just ask Gemini\" topkek reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:00.110132",
        "updated_at": "2026-02-09T16:19:00.110132",
        "author": {
          "id": "350738e06aadb6b9ec648d175dd40769",
          "source_id": "iExploder",
          "username": "iExploder",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "adaed650440bfebddd83022975208b05",
        "source_id": "46918571",
        "content": {
          "text": "I use AI for some of my issues, but it typically doesn't write the code for me. If it does, I review every line and transform it into my style, etc. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:00.110864",
        "updated_at": "2026-02-09T16:19:00.110864",
        "author": {
          "id": "a63a5196c5229fa21c315191cf62681c",
          "source_id": "gitbit-org",
          "username": "gitbit-org",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "e82e8de564b543b5e112fb9b299c994a",
        "source_id": "46901458",
        "content": {
          "text": "I was on a greenfield project late last year with a team that was very enthusiastic about coding agents. I would personally call it a failure, and the project is quietly being wound down after only a few months. It went in a few stages: At first, it proceeded very quickly. Using agents, the team were able to generate a lot of code very fast, and so they were checking off requirements at an amazing pace. PRs were rubber stamped, and I found myself arguing with copy/pasted answers from an agent most of the time I tried to offer feedback. As the components started to get more integrated, things started breaking. At first these were obvious things with easy fixes, like some code calling other code with wrong arguments, and the coding agents could handle those. But a lot of the code was written in the overly-defensive style agents were fond of, so there were a lot more subtle errors. Things like the agent adding code to substitute an invalid default value in instead of erroring out, far away from where that value was causing other errors. At this point, the agents started making things strictly worse because they couldn't fit that much code in their context. Instead of actually fixing bugs, they'd catch any exceptions and substitute in more defaults. There was some manual work by some engineers to remove a lot of the defensive code, but they could not keep up with the agents. This is also about when the team discovered that most of the tests were effectively \"assert true\" because they mocked out so much. We did ship the project, but it shipped in an incredibly buggy state, and also the performance was terrible. And, as I said, it's now being wound down. That's probably the right thing to do because it would be easier to restart from scratch than try to make sense of the mess we ended up with. Agents were used to write the documentation, and very little of it is comprehensible. We did screw some things up. People were so enthusiastic about agents, and they produced so much code so fast, that code reviews were essentially non-existent. Instead of taking action on feedback in the reviews, a lot of the time there was some LLM-generated \"won't do\" response that sounded plausible enough that it could convince managers that the reviewers were slowing things down. We also didn't explicitly figure out things like how error-handling or logging should work ahead of time, and so what the agents did was all over the place depending on what was in their context. Maybe the whole mess was a necessary learning as we figure out these new ways of working. Personally I'm still using the coding agents, but very selectively to \"fill-in-the-blanks\" on code where I know what it should look like, but don't need to write it all by hand myself. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:00.111681",
        "updated_at": "2026-02-09T16:19:00.111681",
        "author": {
          "id": "e85919bb004b4104a69a4fe1e6ac3677",
          "source_id": "SaberTail",
          "username": "SaberTail",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "ae60cf98a0662b3b71ef20c2b30a3c18",
        "source_id": "46934221",
        "content": {
          "text": "I'd expect this kind of outcome to be common for anything complex, but there seem to be more claims of success stories than horror stories. Various possibilities I suppose - I could just be overly skeptical, or failures might be kept on the down low, or perhaps most likely: many companies haven't actually reached the point where the hidden tech debt of using these things comes full circle. Having been through it, what's your current impression of the success stories when you come across them? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:00.112476",
        "updated_at": "2026-02-09T16:19:00.112476",
        "author": {
          "id": "361f66851c4271d3a55aedf92be8552b",
          "source_id": "abcde666777",
          "username": "abcde666777",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "2a9835e2dfbf2d80b384c8f62d1bea03",
        "source_id": "46935188",
        "content": {
          "text": "I'd speculate we had a few factors working against us that made us hit the \"limit\" sooner. Several different engineering teams from different parts of the company had to come together for this, and the overall architecture was modular, so there was a lot of complexity before we had to start integrating. We have some company-wide standards and conventions, but they don't cover everything. To work on the code, you might need to know module A does something one way and module B does it in a different way because different teams were involved. That was implicit in how human engineers worked on it, and so it wasn't explicitly explained to the coding agents. The project was in the life sciences space, and the quality of code in the training data has to be worse than something like a B2B SaaS app. A lot of code in the domain is written by scientists, not software engineers, and only needs to work long enough to publish the paper. So any code an LLM writes is going to look like that by default unless an engineer is paying attention. I don't know that either of those would be insurmountable if the company were willing to burn more tokens, but I'd guess it's an order of magnitude more than we spent already. There are politics as well. There have been other changes in the company, and it seems like the current leadership wants to free up resources to work on completely different things, so there's no will to throw more tokens at untangling the mess. I don't disbelieve the success stories, but I think most of them are either at the level of following already successful patterns instead of doing much novel, or from companies with much bigger budgets for inference. If Anthropic burns a bunch of money to make a C compiler, they can make it back from increased investor hype, but most companies are not in that position. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:00.113357",
        "updated_at": "2026-02-09T16:19:00.113357",
        "author": {
          "id": "e85919bb004b4104a69a4fe1e6ac3677",
          "source_id": "SaberTail",
          "username": "SaberTail",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "3d4a33ace14f55b10e45616cb7e30fda",
        "source_id": "46920325",
        "content": {
          "text": "I'm personally using it a lot. For my workplace, the productivity gains are limited by human code review (need a minimum of two approvals) and manual testing. I can produce a ton of PRs, more than ever before, but I was already bottlenecked by review & test in the hand-coding era. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:00.114189",
        "updated_at": "2026-02-09T16:19:00.114189",
        "author": {
          "id": "673d873cc351bd713d76177fb28681bc",
          "source_id": "dgunay",
          "username": "dgunay",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "2dd8159a0be828240864ae549c63c3cd",
        "source_id": "46907715",
        "content": {
          "text": "100% of the team (14 engineers) is using Claude Code for everything. Anecdotally it feels like velocity is 10%-20% faster. Objectively I have no idea if velocity is faster – because management is inept and does not actually track this. The most noticeable thing is test coverage has greatly improved. Every PR ships with lots of tests, whereas before we used AI we had little to no test coverage since it was just too time consuming. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:00.115051",
        "updated_at": "2026-02-09T16:19:00.115051",
        "author": {
          "id": "fc03c0380cc83aa9f2daa1111a36b0db",
          "source_id": "fogzen",
          "username": "fogzen",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "5c69eb854868a0739c97897e8b5131e8",
        "source_id": "46909993",
        "content": {
          "text": "They got fired by an AI exploit. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:00.115946",
        "updated_at": "2026-02-09T16:19:00.115946",
        "author": {
          "id": "cf69aa05d9b8edd2b718964c931494b9",
          "source_id": "hulitu",
          "username": "hulitu",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "7b1883f6e9297a39254a3876746cf750",
        "source_id": "46909832",
        "content": {
          "text": "As someone that has already had to \"rescue\" several of those oft-praised \"AI-first\" projects you hear all about, I can safely say this: \"It's not going super well.\" The LLM-produced code I've seen thus far (from moderate feature PRs up to and including entire services), tends twords 'too large' or 'too complex' to properly vet by their small team of creators; PRs against existing codebases are often riddled with minor, seemingly unrelated changes or worse: large and/or subtle test suite alterations that \"all pass\" but contain hidden assumptions in conflict with reality and your business requirements. Numerous edge cases go entirely missed, overly trivial things are validated instead, etc. Feedback loops with the system certainly improves output but is frustrating and in many cases no faster than just writing the code yourself. At this stage you still need a human in the loop, unless you're still in the earliest stages of building a product.  This being HN I'm sure someone around here is employing LLMs successfully in those cases, but the story for established orgs tends to be more complex, especially in traditionally risk averse fields like healthcare, billing, credit card processing, defense, etc. All fields I've worked in. The sheer amount of code these LLM systems produce in aggregate means that we have a deficit of cognitive spoons across our orgs to properly review and test all these changes that are being pumped out. In other words: more bugs end up getting found in the field instead of earlier because we're allowing our generators to validate themselves due to resource constraints. Can we produce code faster than ever before? Sure, but that was never the real bottleneck to begin with, at least in the orgs that I've operated within the past 2 decades. To me, every new line of code needs an inherent justification for its existence.  Code is often as much a liability as it  is an asset. Think on several axis like risk of security vulnerabilities or cognitive load limits when no one left in your org understands your vibe-coded system anymore, as it grows more unwieldy by the day. The business value of new code being introduced should outway its (not so) hidden cost of maintenance and risk of business disruption. With today's emphasis on using LLM output for \"moving faster\", we seem to be ignoring that critical risk/reward analysis and operating under the incorrect assumption that more code is universally a good thing. So for the moment I'm just using LLMs for \"rubber ducking\" or spitballing/testing out ideas before committing to a course of action; an action that will ultimately get executed by a human in the short term at least. That said, on a good day my AI can serve as a proxy for a semi-competent software engineer (with amnesia), and no worse than an actual rubber duck on the others. (note that the above statements are my own personal observations and are not intended to represent or express any statement or opinion held by my employer, etc, etc.) reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:00.116950",
        "updated_at": "2026-02-09T16:19:00.116950",
        "author": {
          "id": "a1d9d5acaf4c4a49b14d49dd6113087d",
          "source_id": "drzaiusx11",
          "username": "drzaiusx11",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      }
    ],
    "metadata": {
      "crawled_at": "2026-02-09T16:19:00.117571",
      "language": "en-US",
      "keywords": [
        "tech",
        "startup",
        "programming",
        "ask",
        "question"
      ],
      "is_nsfw": false
    }
  },
  {
    "post": {
      "id": "b39cec3cfd4d90c55a9d382f28d91fec",
      "source_id": "46895494",
      "title": "Ask HN: Is Connecting via SSH Risky?",
      "content": {
        "text": "<div class=\"toptext\" style=\"margin-top:4px\">I have been managing websites for a while and usually utilize SSH connections to login to, deploy code to, and otherwise remotely access the hosting servers.<p>I was recently informed that a client I work with considers that a legal risk.<p>If the SSH connection is set to disallow passwords and only authorize via SSH keys, how big of a risk is this?</p></p></div>",
        "format": "html",
        "media": []
      },
      "created_at": "2026-02-09T16:18:30.204083",
      "updated_at": "2026-02-09T16:18:30.204083",
      "category": {
        "id": "f31af88693e43c7e98a65941d54a8cd6",
        "name": "Ask HN"
      },
      "tags": [
        "Ask HN",
        "hacker news",
        "tech"
      ],
      "author": {
        "id": "84fb01f4e96da8923bf9c053c7bcd35e",
        "source_id": "atrevbot",
        "username": "atrevbot",
        "avatar": "",
        "role": "user",
        "signature": ""
      },
      "stats": {
        "views": 0,
        "likes": 19,
        "dislikes": 0,
        "replies": 0,
        "shares": 0
      }
    },
    "source": {
      "forum": "hackernews",
      "url": "https://news.ycombinator.com/item?id=46895494",
      "section": "Ask HN"
    },
    "replies": [
      {
        "id": "d875bd4b362a1bfcd61065aa081b2593",
        "source_id": "46896522",
        "content": {
          "text": "SSH is not at all risky if you disable password authentication. There's essentially zero chance that someone guesses your private key, though you might get annoyed with all the login failures spamming your logs. Fail2ban helps with that if you care, though I don't personally bother these days. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.923332",
        "updated_at": "2026-02-09T16:19:01.923332",
        "author": {
          "id": "ed99bc9b0e9a3d5006544943dc85da1f",
          "source_id": "bigstrat2003",
          "username": "bigstrat2003",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "1cd45022f4b1882f2e8350e30ab410e7",
        "source_id": "46909011",
        "content": {
          "text": "A bigger problem I think would be someone discovering a pre-auth 0day in the code.  So the important thing would be to not allow the entire internet unrestricted access to whatever's running the SSH server. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.923884",
        "updated_at": "2026-02-09T16:19:01.923884",
        "author": {
          "id": "9f40c0d87db62249774b36b92242b8e7",
          "source_id": "pseudohadamard",
          "username": "pseudohadamard",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "24a23bd1a56afab5ccecc1b165e7654d",
        "source_id": "46899093",
        "content": {
          "text": "So that’s generally my train of thought, but from what I know there were serious vulnerabilities discovered in OpenSSH throughout the years, doesn’t it increase the risk for open ssh port or were the vulnerabilities discovered never touched those areas of ssh authentication. Seems to me that tools like tailscale and so on aren’t open to this sort of risk but I definitely can be wrong reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.924398",
        "updated_at": "2026-02-09T16:19:01.924398",
        "author": {
          "id": "c971c3345cb81406fc3f80271de20183",
          "source_id": "null_deref",
          "username": "null_deref",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "5567d7fc78f64f4b8dcb8c8c9019d67d",
        "source_id": "46900001",
        "content": {
          "text": "The only one I can think of is the one on Debian where key generation used weak entropy, making keys guessable. Given its sensitivity, OpenSSH is incredibly battle-hardened and probably better than almost everything else you can run on an exposed port. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.924956",
        "updated_at": "2026-02-09T16:19:01.924956",
        "author": {
          "id": "0c3add7e37a219f7868a7d5dafb09cfe",
          "source_id": "lxgr",
          "username": "lxgr",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "c5237742aae481bee738308cf326dd01",
        "source_id": "46919374",
        "content": {
          "text": "> SSH is not at all risky if you disable password authentication. ELI5, please.  I understand it for passwords laymen use, but why is my 128 random byte password less secure than a key? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.925527",
        "updated_at": "2026-02-09T16:19:01.925527",
        "author": {
          "id": "9aa087074397d8b039523f55ed241d98",
          "source_id": "1718627440",
          "username": "1718627440",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "1699a8efbd362011b9e6aa13ab8d01ce",
        "source_id": "46896025",
        "content": {
          "text": "They probably mean leaving ssh open to all ips. Take a look at your auth failure logs to see the thousands of daily attempts to compromise your server using default passwords. Most of those are low effort and low risk. Sometimes the bots will try password stuffing. Disabling password auth in sshd config is good practice.\nFail2ban also helps block repeated attempts like that. There’s also the risk of a zero day RCE vulnerability in ssh (though I’ve not seen one in the 20 years I’ve been paying attention ) I tend to not expose ssh to the world and log in with some other method to pass the perimeter (VPN, IP whitelist, tailscale) and the ssh from inside. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.926154",
        "updated_at": "2026-02-09T16:19:01.926154",
        "author": {
          "id": "ac19cd93e02279dbc5ceba59dcbab880",
          "source_id": "tim-tday",
          "username": "tim-tday",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "3f4edec93b3cabf3a567b0204dc790a5",
        "source_id": "46899930",
        "content": {
          "text": "fail2ban seems like security theater for a keys-only SSH server, and it won't help against zero days either (unless it happens to be one that requires many attempts). The only thing it helps with is log spam, but then why not just configure SSH to not log login failures? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.926803",
        "updated_at": "2026-02-09T16:19:01.926803",
        "author": {
          "id": "0c3add7e37a219f7868a7d5dafb09cfe",
          "source_id": "lxgr",
          "username": "lxgr",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "5f034cbaef33cf54731d7391d2c2aba3",
        "source_id": "46897914",
        "content": {
          "text": "> If the SSH connection is set to disallow passwords and only authorize via SSH keys, how big of a risk is this low risk, do this. Keys (ed25519,4096 rsa) are impractical to brute force. However I'd also recommend: - use a different port than 22 (add your .ssh/config for easier UX if needed) - port 22 can get incredibly noisy with tons of bots probing - disable passwordAuth, disable PermitRootLogin - use a normal user with sudo for your ssh - consider a vpn please - I use tailscale, but I hear headscale is good - then use UFW to only allow SSH from the tailscale network (I generally allow all network on tailscale). Tailscale wrote a guide on this here [1] - do not add and forget authorized_keys from machines you arent using - I'm especially worried about how people keep giving Clawdbot/Openclaw access to all their machines, key auth means the machine is authorized on your server - For new servers I often just add all my public keys to them (github lists all your keys at github.com/GH_USERNAME.keys 1: https://tailscale.com/docs/how-to/secure-ubuntu-server-with-... reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.927553",
        "updated_at": "2026-02-09T16:19:01.927553",
        "author": {
          "id": "b57af902814f68fd5cf2ad666168ea02",
          "source_id": "_Chief",
          "username": "_Chief",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "01d622b1db801b0d58481234a8373768",
        "source_id": "46900516",
        "content": {
          "text": "Thanks a lot for the detailed response.  I see Tailscale pop up here often and have been meaning to better understand how it could fit into my typical hosting setup, so I appreciate that reference. For additional context I usually host on a shared or dedicated VPS, and in this case am managing a WordPress site I inherited.  It seems to me that if the SSH connection is restricted by IP and limited to keys, there are much larger risks involved in hosting a WordPress site publicly available on the internet w/ dozens of plugin dependencies. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.928248",
        "updated_at": "2026-02-09T16:19:01.928248",
        "author": {
          "id": "84fb01f4e96da8923bf9c053c7bcd35e",
          "source_id": "atrevbot",
          "username": "atrevbot",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "6aae715d4be60ae1a811284621c51013",
        "source_id": "46898108",
        "content": {
          "text": "Many people keep offering advice to consider a VPN and while VPN is very usefull, I have not yet come accross a reason why not use ssh auth. Like what can actually happen? From my pov the risk of running all sorts of userspace software with internet access is much greater, even without port forwarding. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.928961",
        "updated_at": "2026-02-09T16:19:01.928961",
        "author": {
          "id": "d570f61bda4393afdd4b3cc26ec697fc",
          "source_id": "janmalec",
          "username": "janmalec",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "e5fb6194070814d16f0edfe3c54c2a31",
        "source_id": "46899962",
        "content": {
          "text": "> key auth means the machine is authorized on your server Not necessarily: Depends on whether your key is passphrase-protected and how your SSH agent is configured (if you use one). You can have the standard OpenSSH one ask you for confirmation of every key usage, for example. > consider a vpn please But also consider how you'll fix a broken VPN without SSH access. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.929732",
        "updated_at": "2026-02-09T16:19:01.929732",
        "author": {
          "id": "0c3add7e37a219f7868a7d5dafb09cfe",
          "source_id": "lxgr",
          "username": "lxgr",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "4329d69482b6f9c771e533a1bbe94ef1",
        "source_id": "46898451",
        "content": {
          "text": "You said “legal” risk, not “security” risk. You’ll need to get more information on what risks they are trying to mitigate and talk to a “legal” expert rather than engaging on a technical or security basis. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.930476",
        "updated_at": "2026-02-09T16:19:01.930476",
        "author": {
          "id": "8e2798b44247eded95734e4b6994fd88",
          "source_id": "kasey_junk",
          "username": "kasey_junk",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "9f666a52e3832f5cca23808e3efac9e1",
        "source_id": "46909205",
        "content": {
          "text": "Most more professional environments use VPN and bastion hosts for this purpose. SSH is a risk because you’re trusting the users and client to not be idiots or get compromised. In general, people tend to do stupid things. If it’s just you and your server, potentially a different story. It’s like sharing secrets with people, the more who are involved, the less likely the secret will be kept. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.931286",
        "updated_at": "2026-02-09T16:19:01.931286",
        "author": {
          "id": "0d914fad4463f2ca613e12fe1ae67c5d",
          "source_id": "Spooky23",
          "username": "Spooky23",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "63d368dd0923c4de4e1f3f0e33848cdf",
        "source_id": "46899652",
        "content": {
          "text": "No, but if you do it badly of course it will be. How else do they expect you to login? Unless they are giving you physical access, SSH by all measures is the best way to connect. Leaving it unmaintained is the worst way forward. Just follow best practices and patch on a regular schedule. They seem to be worried about the wrong problem here. Where is your client's security team and why are they ignoring this issue? If they don't have one, then tell them to get one before complaining about something they know nothing about. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.932098",
        "updated_at": "2026-02-09T16:19:01.932098",
        "author": {
          "id": "3619525ca9833ce765632d654efeb0b5",
          "source_id": "1970-01-01",
          "username": "1970-01-01",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "ec8885ae552e1ad9c2ce9936b464706a",
        "source_id": "46899600",
        "content": {
          "text": "If you're hosting on a public cloud, you can use a feature like AWS Session Manager to connect \"through the backdoor\" (via the guest's private communication with the hypervisor) without actually opening the ssh port to the world. This should fully address the client's concerns. None of my servers have ssh exposed at all. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.932941",
        "updated_at": "2026-02-09T16:19:01.932941",
        "author": {
          "id": "ccfc22607f205aa40ef2c829f42f19b0",
          "source_id": "electroly",
          "username": "electroly",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "64491e7adc3b81ceafb623f27c62ef4a",
        "source_id": "46899859",
        "content": {
          "text": "How does the nature of remote access address the legal concern (presumably) about there being remote access in general? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.933806",
        "updated_at": "2026-02-09T16:19:01.933806",
        "author": {
          "id": "0c3add7e37a219f7868a7d5dafb09cfe",
          "source_id": "lxgr",
          "username": "lxgr",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "3e1ea3fcc258a9247d9929deab732c25",
        "source_id": "46899922",
        "content": {
          "text": "That isn't my presumption about nature of the concern. In OP's other comment they specify that the client is specifically worried about the open port . reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.934729",
        "updated_at": "2026-02-09T16:19:01.934729",
        "author": {
          "id": "ccfc22607f205aa40ef2c829f42f19b0",
          "source_id": "electroly",
          "username": "electroly",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "50edaf4b5021b91d54a753b962d9b437",
        "source_id": "46899980",
        "content": {
          "text": "Well, if you allow remote access, you conceptually allow some kind of logical inbound connection, no matter how it's technically realized. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.935635",
        "updated_at": "2026-02-09T16:19:01.935635",
        "author": {
          "id": "0c3add7e37a219f7868a7d5dafb09cfe",
          "source_id": "lxgr",
          "username": "lxgr",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "c8d359a381904ea2c2bc2962e28339f5",
        "source_id": "46895915",
        "content": {
          "text": "Runs counter to my understanding, I'd ask for clarification and find support material to show your approach is safer. Treat it as a teaching moment for them reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.936652",
        "updated_at": "2026-02-09T16:19:01.936652",
        "author": {
          "id": "0555c16ed7f938be906cf20d79b97096",
          "source_id": "verdverm",
          "username": "verdverm",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "f4ddf82248fe4f136616227cf4d93c62",
        "source_id": "46895896",
        "content": {
          "text": "Best practices usually call for not exposing the SSH endpoints to the public internet. The principal risk is vulnerabilities in the underlying SSH server implementation. Historically, critical flaws that can compromise you are few and far between. However, these days AI is already starting to become adept at reverse engineering. If you must, you'd typically use a bastion host that's configured just for the purpose of handing inbound SSH connections, and is locked down to a maximal degree. It then routes SSH traffic to your other machines internally. I'd argue that model is outdated though, and the prevailing preference is putting SSH behind the firewall on internal networks. Think Wireguard, Tailscale, service meshes, and so on. With AWS, restricting SSH ports via security groups to just your IP is simple and goes a long way. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.937669",
        "updated_at": "2026-02-09T16:19:01.937669",
        "author": {
          "id": "95cb8e621592511a52f62e8e82a3176a",
          "source_id": "rl3",
          "username": "rl3",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "2de74ce3919a597c41ed100605813c66",
        "source_id": "46896866",
        "content": {
          "text": "But doesn’t your argument that the principal risk [with ssh] is vulnerabilities also apply to the alternatives you say is best practice? Firewalling off ssh (but not http(s)) has the risk of vulns in the FW software. Tailscale, wireguard etc also has the risk of vulns in that software? So what’s the difference in risk of ssh software vulns and other software vulns? Also, another point of view is that vulnerabilities are not very high on the risk ladder. Weak passwords, password reuse etc are far greater risks. So, the alternatives to ssh you suggest are all reliant on passwords but ssh, in the case, is based on secure keys and no passwords. Should “best practices” not include this perpective? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.938710",
        "updated_at": "2026-02-09T16:19:01.938710",
        "author": {
          "id": "099b54bb8d0909e854d3403367a89e0d",
          "source_id": "Msurrow",
          "username": "Msurrow",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "2444ae97057070738f00e22b7a4f0845",
        "source_id": "46897052",
        "content": {
          "text": "Good defense is layered. For vulnerabilities, complexity usually equals surface area. WireGuard was created with simplicity in mind. > So, the alternatives to ssh you suggest are all reliant on passwords but ssh, in the case, is based on secure keys and no passwords. WireGuard is key-based. I highly suggest reading its whitepaper: https://www.wireguard.com/papers/wireguard.pdf reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.939826",
        "updated_at": "2026-02-09T16:19:01.939826",
        "author": {
          "id": "95cb8e621592511a52f62e8e82a3176a",
          "source_id": "rl3",
          "username": "rl3",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "7838f36f0c73955e0a69f1dfff9b4f9b",
        "source_id": "46899674",
        "content": {
          "text": "Sure, no one said it wasnt layered. But saying ssh is a risk “on principle” due to possible vulnerabilities, and then implying that if wireguard is used then that risk isnt there is wrong. Wireguard, and any other software, has the same vuln risk “on principle”. > For vulnerabilities, complexity usually equals surface area. WireGuard was created with simplicity in mind. That is such consultant distraction-speak. Simple software can have plenty vulns, and complex software can be well tested. Wireguard being “created with simplicity in mind” doesn’t not make it a better alternative to ssh, since it doesn’t mean ssh wasnt created with simplicity in mind. I don’t disagree that adding a vpn layer is an extra layer of security which can be good. But that does not make ssh bad and vpn good. Further, they serve two different purposes so its comparing Apples to oranges in the first place. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.940954",
        "updated_at": "2026-02-09T16:19:01.940954",
        "author": {
          "id": "099b54bb8d0909e854d3403367a89e0d",
          "source_id": "Msurrow",
          "username": "Msurrow",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "6d9d82c37dd094509cee7cff4a90e7b4",
        "source_id": "46908051",
        "content": {
          "text": "> That is such consultant distraction-speak. Or how large companies actually think about this risk in the real world. Expose SSH ports to the public internet willy-nilly and count the seconds until their ops and security teams come knocking wondering what the heck. YMMV of course, but that's generally how it goes. Are critical SSH vulns few and far between, as far as anyone knows? Yes. Do large companies want to protect against APT-style threats with nation-state level resources? Yep. Does seeing hundreds if not thousands of failed login attempts a day directly on their infrastructure maybe worry some people, for that reason? Yup. You call it consultant distraction speak, I call it educating you about what Wireguard actually is, because in your original reply you suggested it was password-based. > Further, they serve two different purposes so its comparing Apples to oranges in the first place. Not when both can be used to protect authentication flows. One is chatty and handshakes with unauthenticated requests, also yielding a server version number. The other simply doesn't reply and stays silent. > Simple software can have plenty vulns, and complex software can be well tested. In this case, both are among some of the most highly audited pieces of software on the planet. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.942204",
        "updated_at": "2026-02-09T16:19:01.942204",
        "author": {
          "id": "95cb8e621592511a52f62e8e82a3176a",
          "source_id": "rl3",
          "username": "rl3",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "3539b43fd0461eeb6cf54a00958174c8",
        "source_id": "46911275",
        "content": {
          "text": "I’m calling it consultant speak because your response to an argument is to bring up something else, instead of actually responding. The same with this last reply; you can keep throwing out new points all you want, but thats not going to make you correct in the original question. Saying or implying that one software has a “principle” risk of vulnerabilities that another software doesn’t is plain and simply wrong. And that has nothing to do with all the other stuff about layered defence, vpns, enterprise security, chatty protocols or whatever you want to pile on the discusion. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.943380",
        "updated_at": "2026-02-09T16:19:01.943380",
        "author": {
          "id": "099b54bb8d0909e854d3403367a89e0d",
          "source_id": "Msurrow",
          "username": "Msurrow",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "2b0551b7064a93b9cf6a9ffca9b8b898",
        "source_id": "46911593",
        "content": {
          "text": "Your question was this: > So what’s the difference in risk of ssh software vulns and other software vulns? I proceeded to explain how large companies think about the issue and what their rationale is for not exposing SSH endpoints to the public internet. On the technical side, I compared SSH to WireGuard. For that comparison, the chattiness of their respective protocols was directly relevant. Likewise complexity: between two highly-audited pieces of software, the silent one that's vastly simpler tends to win from a security perspective. All of those points seem highly relevant to your question. >... but thats not going to make you correct in the original question. If you can elucidate what I said that was incorrect, I'm all ears. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.944676",
        "updated_at": "2026-02-09T16:19:01.944676",
        "author": {
          "id": "95cb8e621592511a52f62e8e82a3176a",
          "source_id": "rl3",
          "username": "rl3",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "776aae7239a62af548c1461e1b26d418",
        "source_id": "46912323",
        "content": {
          "text": "You are still implying that wireguard are somehow different from ssh in its suceptibilty to vulnerabilities existing or being introduced into its codebase. And it simply is not. Edit: codebase of ssh/wireguard implementations, just to be clear reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.945915",
        "updated_at": "2026-02-09T16:19:01.945915",
        "author": {
          "id": "099b54bb8d0909e854d3403367a89e0d",
          "source_id": "Msurrow",
          "username": "Msurrow",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "8adf52f0289edcbb09218464e26d3cd9",
        "source_id": "46918325",
        "content": {
          "text": "Yes, the two are very different in that regard. WireGuard is 4k LoC and is very intentional about its choice of using a single, static crypto implementation to drastically reduce its complexity. Technically speaking, it has a lower attack surface for that reason. That said, I've been on your side of the argument before, and practically speaking you can expose OpenSSH on the public internet with a proper key setup and almost certainly nothing will happen because it's a highly-audited, proven piece of software. Even though it's technically very complex. But , that still doesn't mean it isn't best practice to avoid exposing it to the public internet. Especially when you can put things in front of it (such as WireGuard) that have a much lower technical complexity, and thus a reduced attack surface. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.947229",
        "updated_at": "2026-02-09T16:19:01.947229",
        "author": {
          "id": "95cb8e621592511a52f62e8e82a3176a",
          "source_id": "rl3",
          "username": "rl3",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "aa1632bfba9afa1b06d1b800bcaf7e37",
        "source_id": "46932155",
        "content": {
          "text": "No, they are not. Doesn’t matter how many LoC; it only take 1 LoC to introduce a vulnerability. Wireguard is a protocol. So what implementation is “very intentional about its choice of …”? Are you talking about my own WG client implementation? Or the one made by this other Chinese vendor? I don’t care what software we are talking about, or who made it. All software has a risk of undiscovered/-disclosed vulnerabilities already existing, or when new ones introduced with an update. If you really want to make this argument we can talk about the implementing organisations SDLC, including SW supply chain, and compare those. But back to the OP/point above: its false to state that one piece of software has a “principle risk” of vulnerabilities that another piece does not. At least, not when both are internet exposed and accepting incoming data. Lasty remember that I never disagreed with you point that a VPN solution is often a better solution, but that was never what I was arguing about. Simply that all code always has a risk of vulnerabilities. No piece of software is excempt from that. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.948568",
        "updated_at": "2026-02-09T16:19:01.948568",
        "author": {
          "id": "099b54bb8d0909e854d3403367a89e0d",
          "source_id": "Msurrow",
          "username": "Msurrow",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "71f6013fc842b0b3787b8e9ace9e7a76",
        "source_id": "46940445",
        "content": {
          "text": "> No, they are not. Doesn’t matter how many LoC; it only take 1 LoC to introduce a vulnerability. So according to you, the concept of attack surface doesn't exist. A 100MB binary is equivalent in risk to a 1KB binary. Got it. If both are highly-audited, their risk is equal despite their size and protocol complexity. Got it. > ...its false to state that one piece of software has a “principle risk” of vulnerabilities that another piece does not. That's like the third or fourth time you've scare-quoted the word principle . You're aware that principle and principal are two different words with different meanings? The word I used, principal , in that context means the foremost or primary risk. Anyways, I'm just telling you how major corporations think about it. Their underlying rationale is exactly what I've explained thus far, and hence why it's best practice . Keep shooting the messenger I guess. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.950124",
        "updated_at": "2026-02-09T16:19:01.950124",
        "author": {
          "id": "95cb8e621592511a52f62e8e82a3176a",
          "source_id": "rl3",
          "username": "rl3",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "35a0010d268d7d82a4d8d5b0fb355c95",
        "source_id": "46895916",
        "content": {
          "text": "If your private key has a good passphrase and is suitably encrypted, say with ed25519, then that's probably as good as you can do other than physically going into work and storing everything in your head :-) Politely ask the client to suggest what they consider would be a suitable alternative.\nI also setup git hooks to prevent accidentally checking in private keys or passwords into git or other version control systems. And if I'm travelling into or from work I also encrypt some stuff just in case I have a problem and the laptop is stolen. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.951469",
        "updated_at": "2026-02-09T16:19:01.951469",
        "author": {
          "id": "8ad3ee00bf86e89c3aeda66da80cd37a",
          "source_id": "speleolinux",
          "username": "speleolinux",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "1580391e9990050eb0748d278a45962c",
        "source_id": "46896092",
        "content": {
          "text": "ditto to everything here. If you really want to you can also change the port to something random to avoid bot spam. but you shouldn't have SSH accessible directly from the internet anyway. If you are using only keys, make sure they are managed, tracked, securely stored and backed up. The last thing you want is to have a machine die that has the only private key for your environment. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.952882",
        "updated_at": "2026-02-09T16:19:01.952882",
        "author": {
          "id": "4c9c511698e41603b168840de889b62a",
          "source_id": "xhanah",
          "username": "xhanah",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "42812e27a42c4a7ad0ede0a4955e6221",
        "source_id": "46895559",
        "content": {
          "text": "Compared to what? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.954288",
        "updated_at": "2026-02-09T16:19:01.954288",
        "author": {
          "id": "bf79dbab01e8e20869d5dc6c49f2e1ef",
          "source_id": "phren0logy",
          "username": "phren0logy",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "d0c39edad7f67441de3eea589cdb4d17",
        "source_id": "46895592",
        "content": {
          "text": "They seem to be okay w/ only HTTP ports being open on the server (80, 443).  They \"found that open ports can lead to cyber claims\". reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.955742",
        "updated_at": "2026-02-09T16:19:01.955742",
        "author": {
          "id": "84fb01f4e96da8923bf9c053c7bcd35e",
          "source_id": "atrevbot",
          "username": "atrevbot",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "9431081d84e28cd17c0da268278e0d20",
        "source_id": "46896684",
        "content": {
          "text": "\"Cyber claims\" sounds like someone who doesn't have a clue what they are talking about. But yeah putting it behind some kind of VPN is advisable if anything because of all the driveby nuisance attacks on ipv4. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.957220",
        "updated_at": "2026-02-09T16:19:01.957220",
        "author": {
          "id": "33fd3d38d2435f870bb9fe51db851d9b",
          "source_id": "wolvoleo",
          "username": "wolvoleo",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "efadff0d0662b0198d6c5ffc30fcf5bd",
        "source_id": "46895926",
        "content": {
          "text": "That's like saying that open bottles lead to alcoholism. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.958722",
        "updated_at": "2026-02-09T16:19:01.958722",
        "author": {
          "id": "36524916f4345143f6506644dc193d12",
          "source_id": "bediger4000",
          "username": "bediger4000",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "17c4f7a6689255a484cad578b7219c6e",
        "source_id": "46895569",
        "content": {
          "text": "Indeed. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.960258",
        "updated_at": "2026-02-09T16:19:01.960258",
        "author": {
          "id": "aadb18612fbc177b4dfec9b93237e76b",
          "source_id": "DamonHD",
          "username": "DamonHD",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "125c42552e8d18cc21f1a3bf4eaea29d",
        "source_id": "46895836",
        "content": {
          "text": "How else would you do it? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.961812",
        "updated_at": "2026-02-09T16:19:01.961812",
        "author": {
          "id": "2b5b337fb830f526a9da664c46b99f79",
          "source_id": "robertcope",
          "username": "robertcope",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "b2d186a30d7a67e7f1b554c7f4760cfc",
        "source_id": "46896424",
        "content": {
          "text": "Wireguard and Telnet ;) reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:01.963375",
        "updated_at": "2026-02-09T16:19:01.963375",
        "author": {
          "id": "e0ca19065b291d8c3ab1808a7f56853f",
          "source_id": "muppetman",
          "username": "muppetman",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      }
    ],
    "metadata": {
      "crawled_at": "2026-02-09T16:19:01.964618",
      "language": "en-US",
      "keywords": [
        "tech",
        "startup",
        "programming",
        "ask",
        "question"
      ],
      "is_nsfw": false
    }
  },
  {
    "post": {
      "id": "fa2ccdd3cc520c9e6e1c25b62ee25a8c",
      "source_id": "46926262",
      "title": "Ask HN: Opus 4.6 ignoring instructions, how to use 4.5 in Claude Code instead?",
      "content": {
        "text": "<div class=\"toptext\" style=\"margin-top:4px\">I’ve been using Claude Code this evening and I’m very dismayed by Opus 4.6’s ability to follow instructions. I have given it very clear instructions on several points, only to discover it ignored me without telling me.<p>When I asked it for a list of things that deviated from the spec, it told me everything was as expected. Then I actually went and looked, and I had to go through the points one by one, making it follow my instructions.<p>When I confronted it about this, it told me:<p>&gt; I kept second-guessing your design decisions instead of implementing what you asked for … the mistakes I made weren’t a model capability issue - I understood your instructions fine and chose to deviate from them.<p>This is not acceptable. Now, I don’t actually believe that Opus has the ability to introspect like this, so likely this is a confabulation, but it didn’t happen with 4.5. Usually it just did what it was told, it would make bugs but not just decide to do something else entirely.<p>I want a model that actually does what I tell it. I don’t see anything online about how to get 4.5 back.<p>Any help?</p></p></p></p></p></p></div>",
        "format": "html",
        "media": []
      },
      "created_at": "2026-02-09T16:18:30.204668",
      "updated_at": "2026-02-09T16:18:30.204668",
      "category": {
        "id": "f31af88693e43c7e98a65941d54a8cd6",
        "name": "Ask HN"
      },
      "tags": [
        "Ask HN",
        "hacker news",
        "tech"
      ],
      "author": {
        "id": "4a77d3f1156da67c04e7bc5f7becb015",
        "source_id": "Chance-Device",
        "username": "Chance-Device",
        "avatar": "",
        "role": "user",
        "signature": ""
      },
      "stats": {
        "views": 0,
        "likes": 3,
        "dislikes": 0,
        "replies": 0,
        "shares": 0
      }
    },
    "source": {
      "forum": "hackernews",
      "url": "https://news.ycombinator.com/item?id=46926262",
      "section": "Ask HN"
    },
    "replies": [
      {
        "id": "cdae945ad41293a7ead9508b45c66024",
        "source_id": "46944358",
        "content": {
          "text": "In my opinion, Opus 4.6 handles instructions (especially negative rules) better than Opus 4.5 and Sonnet 4.5. It also applies skills better than other models. But I think this is individual. Another example. I asked gpt-5.2-codex to add an array of 5 values to the script and write a small piece of code. Then I manually deleted one of the values in the array and asked the agent to commit.\nBut the model edited the file again and added the value I deleted to the array.\nI deleted that value again and asked the agent to “just commit.” But the agent edited the file again before committing.\nThis happened many times, and I used different commands, such as “never edit the file, just commit.” The model responded that it understood the command and began editing the file. I switched to gpt-5.2, but that didn't help. I switched to sonnet-4.5, and it immediately committed on the first try without editing the file. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:04.328900",
        "updated_at": "2026-02-09T16:19:04.328900",
        "author": {
          "id": "c7dd74c61a6d7fe2728f64bfa3a76d0d",
          "source_id": "theorchid",
          "username": "theorchid",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "e39a9c9daf33d32722926e32ee9aca3d",
        "source_id": "46933923",
        "content": {
          "text": "GPT-5 used to do this on release, but seems to have reverted back, especially on the codex versions. This may well be a feature. I joked that this is the side effect of asking it to act like a senior software engineer. It tends to talk back and do its own thing. There was that one time when the thought processes went \"I'm a full stack engineer\" > \"I'm expanding my connections on LinkedIn\" > \"I'm establishing myself as a tech writer\" > \"I'm evaluating classes in professional writing\". It does have introspection capabilities, but one could argue it's just a bug or emergent. Anyway, option 1: why not just use Sonnet? Heck you can use Haiku if you're giving it clear instructions. The thinking ones do perform worse on clear tasks. You also get your rolled back version. Option 2: Use role prompting [0]\nGive it some junior engineer role where it's expected to follow instructions exactly as given. [0] https://platform.claude.com/docs/en/build-with-claude/prompt... reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:04.329473",
        "updated_at": "2026-02-09T16:19:04.329473",
        "author": {
          "id": "65547db35ad470ce1d9e44d413173434",
          "source_id": "muzani",
          "username": "muzani",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      }
    ],
    "metadata": {
      "crawled_at": "2026-02-09T16:19:04.329609",
      "language": "en-US",
      "keywords": [
        "tech",
        "startup",
        "programming",
        "ask",
        "question"
      ],
      "is_nsfw": false
    }
  },
  {
    "post": {
      "id": "6af6b283f1ad3d099c9a1ab5637c3b2c",
      "source_id": "46905476",
      "title": "Ask HN: Is it just me or are most businesses insane?",
      "content": {
        "text": "<div class=\"toptext\" style=\"margin-top:4px\">I realize that its probably me, I'm the dumb one, but please bear with me and help me understand.\nI've been recently looking for a new job as I am slowly viewing my previously functioning workplace accelerating towards a static dysfunction.<p>I have spoken to quite a few companies and read a lot of recruitment boards in a rather sizable european city that ought to be filled with opportunities.\nWith tech-sovreignty on everyones lips I would expect some drive and excitement in the european software scene,\nbut to get to companies with a mission I have to wade through The Swamp.\nThe Swamp is waist high in Scrum certifications and gigs where the key skill is \"navigating red tape\".\nThere the architects roam, with no expectations of from management, and with a mandate to stop every system that does not yet include an Azure Event Hub.\nIn the large corporations where the most important roles are the power-BI analysts \nand the best metric for value-creation is the fill of your calendar and your hours of overtime.<p>And somehow, if feel like your getting somewhere with a company that thats primarily motivated by crafting something good, \nnot focusing on vanity metrics or micromanaging how things are done -- its going to be a marketing startup.<p>Summarized: Most of the businesses I see seem to be bloated. They have way to many employees for what they produce. \nThey have too much structure and too many rules to effectively generate new income, and new ideas are shut down and not welcome.<p>But I genuninly do wonder: Are businesses somehow incentivised to become inefficient?\nIs it possible for a business to stay ambitious over time?\nHas one seen it succeed or how have you seen it fail?</p></p></p></p></div>",
        "format": "html",
        "media": []
      },
      "created_at": "2026-02-09T16:18:30.205515",
      "updated_at": "2026-02-09T16:18:30.205515",
      "category": {
        "id": "f31af88693e43c7e98a65941d54a8cd6",
        "name": "Ask HN"
      },
      "tags": [
        "Ask HN",
        "hacker news",
        "tech"
      ],
      "author": {
        "id": "12476f6e1196ae869a8ad373667f01fc",
        "source_id": "justenough",
        "username": "justenough",
        "avatar": "",
        "role": "user",
        "signature": ""
      },
      "stats": {
        "views": 0,
        "likes": 13,
        "dislikes": 0,
        "replies": 0,
        "shares": 0
      }
    },
    "source": {
      "forum": "hackernews",
      "url": "https://news.ycombinator.com/item?id=46905476",
      "section": "Ask HN"
    },
    "replies": [
      {
        "id": "bfa04df4d63c849e7d6954dc0044ed96",
        "source_id": "46916271",
        "content": {
          "text": "This is how BigCo works. They are optimized for resilience and providing predictable cashflows for investors, not efficiency as such. If they had, say, 2 \"10x\" engineers who were brilliant and could do everything with no red tape or inefficiency, then one or both of them could leave, or demand pay raises, and the company would be screwed - it would be a very brittle, unsustainable period of efficiency. So, it's better to have 20 1x engineers, with significant slack in the system, who are all interchangeable cogs in a machine that takes tickets in one end and pushes mediocre software out the other end. That way, if 5 or 10 of them leave, they can be replaced, and nobody will tell the difference. If there's a lean quarter, you can lay off half of them, and then rehire a bunch of average randos off the street a few months later, and again, nobody will be able to tell the difference. Also, the mayor will visit the grand opening of the new office, and the media will write a lovely story about how many jobs have been \"created\", and the company will be able to negotiate some tax breaks for creating so many mediocre jobs. You might find things are better at a mom & pop, or startup, or maybe outside of a big city. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:07.162913",
        "updated_at": "2026-02-09T16:19:07.162913",
        "author": {
          "id": "fbf371f33e32d0aea3cd9c9b8b65ca94",
          "source_id": "tacostakohashi",
          "username": "tacostakohashi",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "dd8450ca8ddaf95dc4363fc39c3b79fa",
        "source_id": "46922018",
        "content": {
          "text": "And notably, totally interchangeable cogs is exactly what a startup should not want. For the reason that it requires a lot of slack. Startups are supposed to move fast, and if you move fast that means there should be minimal overlap in work between different employees. Layoffs could be fatal at that stage in a company's story. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:07.163424",
        "updated_at": "2026-02-09T16:19:07.163424",
        "author": {
          "id": "1c8acb55c1646deddd48525e063cdb8a",
          "source_id": "ironmagma",
          "username": "ironmagma",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "6e9b9b84ddaa542718dc7780e2aa03ce",
        "source_id": "46923078",
        "content": {
          "text": "So I work for a small defense contractor, for more than 2 years now. The means to success so far is almost entirely in the soft skills. It’s helpful to understand the technology but the soft skills are so much more important. It’s certainly the 80/20 rule. Here is what I mean by soft skills: * Actually caring about people. Checking up on your peers and seeing if they need help. * Constant awareness of the people under your management. Having some idea of what they are working on where their pain points are. They should always know they can come to you if they have a problem. * Tracking down undocumented requirements by actually talking to people and getting to know more people. * Constant awareness of hot issues affecting major projects and operating status. Since my business is technology contracting the business goal is to put people into employment and retain those people to the success of the client. The more I retain people the more successful I am to my employer. The inefficiency of the work is up to the client and coordinating business partners. I started here as a developer and within a year was promoted to a manager. In the contract I am still a developer. The complexity there is that I operate in partnership with an another company who would prefer I were a junior developer even though I manage 15 seats. It’s still all about the soft skills. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:07.164037",
        "updated_at": "2026-02-09T16:19:07.164037",
        "author": {
          "id": "0ae492937dcc65e2e9ad4e3b8663757f",
          "source_id": "austin-cheney",
          "username": "austin-cheney",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "b4f75563aec20474f38cc74c49eefad3",
        "source_id": "46913385",
        "content": {
          "text": "They aren't incentivized to become inefficient, but once they grow large enough you get into a situation where everyone is playing a political game to minimize their own risk and effort. And worse, the only people with motivation to fill the top tiers of the company are usually a little off. You essentially have to be a bit nuts to want to be C-level or above in a large corporation. I've seen it, there are employees who will ruthlessly seek out more money. Usually their competence levels aren't quite there, but they are the only people who want the job. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:07.164580",
        "updated_at": "2026-02-09T16:19:07.164580",
        "author": {
          "id": "b1270e8e203737579009d8db15856734",
          "source_id": "Desafinado",
          "username": "Desafinado",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "a78ea251101b40e3872b6c7a2f7363f4",
        "source_id": "46909950",
        "content": {
          "text": "You have discovered Wally's playground.  Wally is one of the guys from the Dilbert comic strip. Basically, many incentives are \"misaligned\" in such a way, that micromanaging demise is (locally) considered more valuable than actually bringing in cash from customers by actually giving them something. As long as the company's owners don't pick up on this and are effective at doing something about it, \"all bets are off.\" reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:07.165170",
        "updated_at": "2026-02-09T16:19:07.165170",
        "author": {
          "id": "587760a742dc96e25f879196dd3006e4",
          "source_id": "dapperdrake",
          "username": "dapperdrake",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "44bcbdd8f8a68f188dfeb9dc2a1d6414",
        "source_id": "46911749",
        "content": {
          "text": "It sounds like you’re applying to enterprises rather than startups. There _will_ be a startup scene in your city, you just need to find it. Look for the meetups, gravitate to where the founders are, find out which meetups _they_ attend, and go network there. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:07.165763",
        "updated_at": "2026-02-09T16:19:07.165763",
        "author": {
          "id": "6b7f6c219ea995fc6ef3e9e6eae719d5",
          "source_id": "apothegm",
          "username": "apothegm",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "593e95da1e55b3aefdccace027d4b037",
        "source_id": "46907918",
        "content": {
          "text": "It could be incentives to lower prices (race to the bottom from competition). reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:07.166369",
        "updated_at": "2026-02-09T16:19:07.166369",
        "author": {
          "id": "0e787394e3e1ab5f88b6fc582e02cbe4",
          "source_id": "nosmokewhereiam",
          "username": "nosmokewhereiam",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      }
    ],
    "metadata": {
      "crawled_at": "2026-02-09T16:19:07.166637",
      "language": "en-US",
      "keywords": [
        "tech",
        "startup",
        "programming",
        "ask",
        "question"
      ],
      "is_nsfw": false
    }
  },
  {
    "post": {
      "id": "90d303df9c6e1e6b1f6ed24ebffe92ba",
      "source_id": "46891715",
      "title": "Ask HN: Mem0 stores memories, but doesn't learn user patterns",
      "content": {
        "text": "<div class=\"toptext\" style=\"margin-top:4px\">We're a YC W23 company building AI agents for engineering labs - our customers run similar analyses repeatedly, and the agent treated every session like a blank slate.<p>We looked at Mem0, Letta/MemGPT, and similar memory solutions. They all solve a different problem: storing facts from conversations — \"user prefers Python,\" \"user is vegetarian.\" That's key-value memory with semantic search. Useful, but not what we needed.<p>What we needed was something that learns user patterns implicitly from behavior over time. When a customer corrects a threshold from 85% to 80% three sessions in a row, the agent should just know that next time. When a team always re-runs with stricter filters, the system should pick up on that pattern.\nSo we built an internal API around a simple idea: user corrections are the highest-signal data. Instead of ingesting chat messages and hoping an LLM extracts something, we capture structured events — what the agent produced, what the user changed, what they accepted. A background job periodically runs an LLM pass to extract patterns and builds a confidence-weighted preference profile per user/team/org.<p>Before each session, the agent fetches the profile and gets smarter over time.\nThe gap as I see it:<p>Mem0 = memory storage + retrieval. Doesn't learn patterns.<p>Letta = self-editing agent memory. Closer, but no implicit learning from behavior.<p>Missing = a preference learning layer that watches how users interact with agents and builds an evolving model. Like a rec engine for agent personalization.<p>I built this for our domain but the approach is domain-agnostic. Curious if others are hitting the same wall with their agents. Happy to share the architecture, prompts, and confidence scoring approach in detail.</p></p></p></p></p></p></p></div>",
        "format": "html",
        "media": []
      },
      "created_at": "2026-02-09T16:18:30.206115",
      "updated_at": "2026-02-09T16:18:30.206115",
      "category": {
        "id": "f31af88693e43c7e98a65941d54a8cd6",
        "name": "Ask HN"
      },
      "tags": [
        "Ask HN",
        "hacker news",
        "tech"
      ],
      "author": {
        "id": "c4f1c3c6cf1e8088624cd1c5cb44db2c",
        "source_id": "fliellerjulian",
        "username": "fliellerjulian",
        "avatar": "",
        "role": "user",
        "signature": ""
      },
      "stats": {
        "views": 0,
        "likes": 9,
        "dislikes": 0,
        "replies": 0,
        "shares": 0
      }
    },
    "source": {
      "forum": "hackernews",
      "url": "https://news.ycombinator.com/item?id=46891715",
      "section": "Ask HN"
    },
    "replies": [
      {
        "id": "5378a8fcd94ca5c92d93c04b7229564c",
        "source_id": "46894345",
        "content": {
          "text": "> user corrections are the highest-signal data I can not understand how this hasn’t been capitalized on more yet! Companies with the data MUST be training on it as RLHF, right? In general, the “chat history mining” sector seems to be way under-developed to me so far. All the damn time I am annoyed I have to re-tell my LLM a piece of info I have already told it a few weeks ago - finding the chat takes too long and the full history may not be relevant, but the fact wasn’t interesting enough to manually add to memory. With the right memory system, the LLM could just know! Does anyone have other interesting examples of this principle being applied? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:09.551362",
        "updated_at": "2026-02-09T16:19:09.551362",
        "author": {
          "id": "a46dfb6f3a5ab860a4911dc0c7d7dab6",
          "source_id": "solarkraft",
          "username": "solarkraft",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "4e0a6dbce952c1332477f3d5f41daebe",
        "source_id": "46897401",
        "content": {
          "text": "100% feel the same way. I´ll look into building an API for that so more people/companies can use it. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:09.551879",
        "updated_at": "2026-02-09T16:19:09.551879",
        "author": {
          "id": "c4f1c3c6cf1e8088624cd1c5cb44db2c",
          "source_id": "fliellerjulian",
          "username": "fliellerjulian",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "cf5b45bfaba4ae7c72f44fe724284eee",
        "source_id": "46894368",
        "content": {
          "text": "Note that you posted an “Ask HN” (with it linking to this page) - do you want to show us something instead? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:09.552381",
        "updated_at": "2026-02-09T16:19:09.552381",
        "author": {
          "id": "a46dfb6f3a5ab860a4911dc0c7d7dab6",
          "source_id": "solarkraft",
          "username": "solarkraft",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "1f9dee3dc3122c5dbea02f9253158af0",
        "source_id": "46897397",
        "content": {
          "text": "oh my bad, thanks for flagging. I dont have a link to anything thats why I did do Show HN reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:09.552923",
        "updated_at": "2026-02-09T16:19:09.552923",
        "author": {
          "id": "c4f1c3c6cf1e8088624cd1c5cb44db2c",
          "source_id": "fliellerjulian",
          "username": "fliellerjulian",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "aebb091752cc587778a3b3b5a0970858",
        "source_id": "46891772",
        "content": {
          "text": "for now we just use normal system memory the user can maintain himself - not the best solution but better than nothing. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:09.553489",
        "updated_at": "2026-02-09T16:19:09.553489",
        "author": {
          "id": "aef226eec271eca53c882754f85d271c",
          "source_id": "berkethebooss",
          "username": "berkethebooss",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "9ea7d07b9cc6b18c9d8eae1aad533204",
        "source_id": "46891797",
        "content": {
          "text": "we did the same thing, but we noticed most users did not maintain their own system memory themself properly. so we had to build a solution that auto-manages memory and preferances. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:09.554085",
        "updated_at": "2026-02-09T16:19:09.554085",
        "author": {
          "id": "c4f1c3c6cf1e8088624cd1c5cb44db2c",
          "source_id": "fliellerjulian",
          "username": "fliellerjulian",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      }
    ],
    "metadata": {
      "crawled_at": "2026-02-09T16:19:09.554324",
      "language": "en-US",
      "keywords": [
        "tech",
        "startup",
        "programming",
        "ask",
        "question"
      ],
      "is_nsfw": false
    }
  },
  {
    "post": {
      "id": "e7b580f2f580d4e3e4ff9f4c12b667ff",
      "source_id": "46920322",
      "title": "Ask HN: Non-profit, volunteers run org needs CRM. Is Odoo Community a good sol.?",
      "content": {
        "text": "<div class=\"toptext\" style=\"margin-top:4px\">Title basically tries to capture the gist of the  question. I have been asked (volunteer) to assist in the project of migration from a proprietary, more costly CRM solution, to an Odoo Community \"product\", to be architected, configured, deployed in a cloud service and operated by a specialized partner. My specialization is in infrastructure (architecture, ops and security), so I could certainly validate mapping the apps functionality into the right components, but I have zero knowledge on how good the CRM part is, and - crucially - how to keep its possible need for customization in time and operations cost low, if internal org volunteers have no technical skills. I am concerned about the integrator attempt to get the foot in the door with an acceptable one time cost, then slowly ramp up the price, if this solution requires a lot of babysitting.<p>Does anyone have any experience with this Odoo Community CRM product and model, to share some gotchas, in the light of the above described attempt to use? Users max 300. The hope is to also have the CRM integrate with needed office products (doc, spreadsheet, email, etc.)</p></div>",
        "format": "html",
        "media": []
      },
      "created_at": "2026-02-09T16:18:30.206719",
      "updated_at": "2026-02-09T16:18:30.206719",
      "category": {
        "id": "f31af88693e43c7e98a65941d54a8cd6",
        "name": "Ask HN"
      },
      "tags": [
        "Ask HN",
        "hacker news",
        "tech"
      ],
      "author": {
        "id": "4de77a99a1c9e19f79447b50d893d542",
        "source_id": "netfortius",
        "username": "netfortius",
        "avatar": "",
        "role": "user",
        "signature": ""
      },
      "stats": {
        "views": 0,
        "likes": 4,
        "dislikes": 0,
        "replies": 0,
        "shares": 0
      }
    },
    "source": {
      "forum": "hackernews",
      "url": "https://news.ycombinator.com/item?id=46920322",
      "section": "Ask HN"
    },
    "replies": [
      {
        "id": "a7a07270f6e3ad6cc564d8671645f9b4",
        "source_id": "46939205",
        "content": {
          "text": "I've implemented Odoo Community for a few small orgs and it's solid for nonprofits if you have the technical resources to maintain it. The main gotchas are: it requires significant PostgreSQL knowledge for customizations, the upgrade path between major versions can be painful (especially with custom modules), and while the community edition is free, you'll likely need paid modules for advanced CRM features like email marketing automation. Since you mentioned migration - the data import process is where most projects get stuck. Odoo's import tools are decent but you'll probably need custom Python scripts for complex data transformations from your current CRM. One thing I learned while building automation tools is that many small nonprofits actually need something simpler than a full CRM - often they just need better task management and follow-up tracking from their existing email communications. I've been beta testing ungrind.ai which handles that specific piece (auto-creates tasks from emails/meetings), though it's designed more for individual consultants than organizations. What's your current CRM and roughly how many contacts/complexity are you migrating? That would help determine if Odoo Community's data model limitations might be an issue. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:10.995218",
        "updated_at": "2026-02-09T16:19:10.995218",
        "author": {
          "id": "a95233a0b497176ec43b096d1f4839ab",
          "source_id": "magnumpowers",
          "username": "magnumpowers",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "aac52d92c0aa83a85008d8697ed4feac",
        "source_id": "46933224",
        "content": {
          "text": "From what I’ve seen, Odoo Community CRM works fine at small scale, but the risk is customization creep. If non-technical volunteers need changes later, you’ll likely depend on the integrator long-term. Keeping workflows very simple upfront helps control costs. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:10.995739",
        "updated_at": "2026-02-09T16:19:10.995739",
        "author": {
          "id": "2cd653acb0f63ece1e126a7e0c08b41d",
          "source_id": "allinonetools_",
          "username": "allinonetools_",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "26f2176111d96d3d1a4fc12749978bbf",
        "source_id": "46920950",
        "content": {
          "text": "Just use Dynamics. They have nonprofit pricing. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:10.996242",
        "updated_at": "2026-02-09T16:19:10.996242",
        "author": {
          "id": "0ec18baccf2924b78f5f275eea39a579",
          "source_id": "khelavastr",
          "username": "khelavastr",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      }
    ],
    "metadata": {
      "crawled_at": "2026-02-09T16:19:10.996396",
      "language": "en-US",
      "keywords": [
        "tech",
        "startup",
        "programming",
        "ask",
        "question"
      ],
      "is_nsfw": false
    }
  },
  {
    "post": {
      "id": "0a6d127e57eaea1878d53069c785b47b",
      "source_id": "46907123",
      "title": "Ask HN: How does ChatGPT decide which websites to recommend?",
      "content": {
        "text": "<div class=\"toptext\" style=\"margin-top:4px\">For years, SEO has meant optimizing for Google’s crawler.<p>But increasingly, discovery seems to be happening somewhere else:\nChatGPT\nClaude\nPerplexity\nAI-powered search and assistants<p>These systems don’t “rank pages” the same way search engines do. They select sources, summarize them, and recommend them directly.<p>What surprised me while digging into this:\n- AI models actively fetch pages from sites (sometimes user-triggered, sometimes system-driven)\n- Certain pages get repeatedly accessed by AI while others never do\n- Mentions and recommendations seem to correlate more with contextual coverage and source authority than traditional keyword targeting<p>The problem is that this entire layer is invisible to most builders.<p>Analytics tools show humans.\nSEO tools show Google.\nBut AI traffic, fetches, and mentions are basically a black box.<p>I started thinking about this shift as:\nGEO (Generative Engine Optimization)\nor AEO (Answer Engine Optimization)<p>Not as buzzwords, but as a real change in who we’re optimizing for.<p>To understand it better, I ended up building a small internal tool (LLMSignal) just to observe:\n- when AI systems touch a site\n- which pages they read\n- when a brand shows up in AI responses<p>The biggest takeaway so far:\nIf AI is becoming a front door to the internet, most sites have no idea whether that door even opens for them.<p>Curious how others here are thinking about:\n- optimizing for AI vs search\n- whether SEO will adapt or be replaced\n- how much visibility builders should even want into AI systems<p>Not trying to sell anything — genuinely interested in how people here see this evolving.</p></p></p></p></p></p></p></p></p></p></p></div>",
        "format": "html",
        "media": []
      },
      "created_at": "2026-02-09T16:18:30.207326",
      "updated_at": "2026-02-09T16:18:30.207326",
      "category": {
        "id": "f31af88693e43c7e98a65941d54a8cd6",
        "name": "Ask HN"
      },
      "tags": [
        "Ask HN",
        "hacker news",
        "tech"
      ],
      "author": {
        "id": "6e70433da4d373f8f115126902263e25",
        "source_id": "nworley",
        "username": "nworley",
        "avatar": "",
        "role": "user",
        "signature": ""
      },
      "stats": {
        "views": 0,
        "likes": 5,
        "dislikes": 0,
        "replies": 0,
        "shares": 0
      }
    },
    "source": {
      "forum": "hackernews",
      "url": "https://news.ycombinator.com/item?id=46907123",
      "section": "Ask HN"
    },
    "replies": [
      {
        "id": "3e6b15289ebc74a18513cc20a9f15a07",
        "source_id": "46941691",
        "content": {
          "text": "I think this shift is real, but I’m not convinced it turns into a clean new SEO anytime soon. From building LLM systems, it feels less like ranking and more about training data, reputation, retrieval, and how easy something is to summarize. If your content is shallow or fragmented, it just doesn’t become useful to models, even if it ranks on Google. My worry is GEO/AEO becomes the same game SEO did, people optimizing for bots instead of users. The boring strategy still wins. Write good stuff, update it, build credibility. Most tools probably won’t matter much. Feels early, we will see reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:13.495490",
        "updated_at": "2026-02-09T16:19:13.495490",
        "author": {
          "id": "61663ddd2ce874082d8d92ad4700ac52",
          "source_id": "avin01",
          "username": "avin01",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "2bba28284c7a9401d4682f2121b561e1",
        "source_id": "46911954",
        "content": {
          "text": "The attribution point is huge: the “decision” can happen in the model’s answer, and your analytics only see the last hop. A practical mental model for recommendations is less “ranking” and more confidence: Does the model have enough context to map your product to a problem?\nAre there independent mentions (docs, comparisons, forum threads) that look earned vs manufactured?\nIs there procedural detail that makes it easy to justify recommending you (“here’s the workflow / constraints / outcomes”)?\nFor builders, a good AEO baseline is:\nPublish a strong docs/use-case page that answers “when should I use this vs alternatives?”\nSeed real-world context by participating in existing discussions (HN/Reddit/etc.) with genuine problem-solving and specifics.\nTrack influence with repeatable prompt tests + lightweight surveys (“how did you hear about us?”) since last-click won’t capture it. It feels like early SEO again: less perfect instrumentation, more building the clearest and most defensible reference for your category. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:13.496079",
        "updated_at": "2026-02-09T16:19:13.496079",
        "author": {
          "id": "10102a3a47498976a02143e398886815",
          "source_id": "marcwajsberg",
          "username": "marcwajsberg",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "217d4992ff93777ba0a47dc0621e395f",
        "source_id": "46909605",
        "content": {
          "text": "However, there is a lack of information when a user opens your website after interacting with AI. Google Search Console shows the user's query if the query is popular enough and your website is in the search results.\nBing shows all queries, even if they are not popular, and if your website is in the search results. But if AI recommends your website when answering people's questions, you cannot find out what questions the user discussed, how many times your website was shown, and in what position. You can see the UTM tag in your website analytics (for example, GPT adds utm source), but that is the maximum amount of information that will be available to you. But if a user discussed a question with AI and only got your brand name, and then found your site in a search engine, you won't be able to tell that they found you with the help of AI advice. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:13.496617",
        "updated_at": "2026-02-09T16:19:13.496617",
        "author": {
          "id": "c7dd74c61a6d7fe2728f64bfa3a76d0d",
          "source_id": "theorchid",
          "username": "theorchid",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "6e15edf0a9e7c9f6a72735bc6223e01e",
        "source_id": "46911213",
        "content": {
          "text": "This is exactly what set me off in trying to figure out the visibility gap. What’s strange is that we’re moving into a world where recommendations matter more than a click, but attribution still assumes a traditional search funnel. By the time someone lands on your site, the most important decision may have already happened upstream and you have no idea. The UTM case you mentioned is a good example: it only captures direct \"AI to site\" clicks, but misses scenarios where AI influences the decision indirectly (brand mention to later search to visit). From the site’s perspective tho... yeah it looks indistinguishable from organic search. It makes me wonder whether we’ll need a completely new mental model for attribution here. Perhaps less about “what query drove this visit” and more about “where did trust originate.” Not sure what the right solution is yet, but it feels like we’re flying blind during a pretty major shift in how people discover things. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:13.497204",
        "updated_at": "2026-02-09T16:19:13.497204",
        "author": {
          "id": "6e70433da4d373f8f115126902263e25",
          "source_id": "nworley",
          "username": "nworley",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "f6104d71009c42274a0b0c1569d22f60",
        "source_id": "46911875",
        "content": {
          "text": "This is why most of these AI search visibility tools focus on tracking many possible prompts at once. LLMs give 0 insight into what users are actually asking, so the only thing you can do is put yourself in the user’s shoes and try to guess what they might prompt. Disclaimer: I've built a tool in this space (Cartesiano.ai), and this view mostly comes from seeing how noisy product mentions are in practice. Even for market-leading brands, a single prompt can produce different recommendations day to day, which makes me suspect LLMs are also introducing some amount of entropy into product recommendations (?) reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:13.497801",
        "updated_at": "2026-02-09T16:19:13.497801",
        "author": {
          "id": "a4dc0948be1ff3a817105aca00a5b513",
          "source_id": "quiqueqs",
          "username": "quiqueqs",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "b7967050cd9381131c90b88d41592eed",
        "source_id": "46916680",
        "content": {
          "text": "I don’t think there’s a clean solution yet but I’m not convinced brute force prompt enumeration scales either, given how much randomness is baked in. I guess that’s why I’ve started thinking about this less as prompt tracking and more as signal aggregation over time. Looking at repeat fetches, recurring mentions, and which pages/models seem to converge on the same sources. It doesn’t tell you what the user asked, but it can hint at whether your product is becoming a defensible reference versus a lucky mention. From someone who's built a tool in this space, curious if you’ve seen any patterns that cut through the noise? Or if entropy is just something we have to design around. Disclaimer: I've built a tool in this space as well (llmsignal.app) reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:13.498423",
        "updated_at": "2026-02-09T16:19:13.498423",
        "author": {
          "id": "6e70433da4d373f8f115126902263e25",
          "source_id": "nworley",
          "username": "nworley",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "2766d944a8dec96a7b2fda692fb31228",
        "source_id": "46909566",
        "content": {
          "text": "This is especially important when launching new SaaS projects. Google does not trust new domains for the first 6-12 months. But if you publish information about your project on other sites, the AI will recommend your site in its responses. Just post a few times on Reddit, and in a week, GPT will be giving out links to your SaaS product. AI doesn't need exact low-frequency or high-frequency keywords like SEO does. AI is good at understanding user queries and giving out the right SaaS that solves the user's problem. You don't need to create a blog on your website and try to rank it in search engines. It is enough to post articles on other websites with information about your project. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:13.499085",
        "updated_at": "2026-02-09T16:19:13.499085",
        "author": {
          "id": "c7dd74c61a6d7fe2728f64bfa3a76d0d",
          "source_id": "theorchid",
          "username": "theorchid",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "c96c8e6d15d8f14f50f0a6b733d1f763",
        "source_id": "46911182",
        "content": {
          "text": "This matches a lot of what I’ve been seeing too. What stood out to me is that AI seems far less concerned with domain age than Google is. If there’s enough contextual discussion around a product (ie. Reddit threads, blog posts, docs, comparisons) then AI models seem willing to surface it surprisingly early. That said, what I’m still trying to understand is consistency. I’ve seen cases where a product gets recommended heavily for a week, then effectively disappears unless that external context keeps getting reinforced. So it feels less like “rank once and you’re good” (SEO) and more like “stay present in the conversation.” Almost closer to reputation management than classic content marketing. Curious if you’ve seen the same thing, especially around how long external mentions keep influencing AI recommendations before they decay. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:13.499815",
        "updated_at": "2026-02-09T16:19:13.499815",
        "author": {
          "id": "6e70433da4d373f8f115126902263e25",
          "source_id": "nworley",
          "username": "nworley",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "0542ae2a77fc0bde049ac74c378adb3b",
        "source_id": "46913910",
        "content": {
          "text": "I have noticed something similar while building small tools — AI recommendations seem to favor clarity and can this answer a real task fast over classic SEO signals. Pages that explain what they do plainly and work without friction show up more often than heavily optimized ones. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:13.500497",
        "updated_at": "2026-02-09T16:19:13.500497",
        "author": {
          "id": "2cd653acb0f63ece1e126a7e0c08b41d",
          "source_id": "allinonetools_",
          "username": "allinonetools_",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "1be30206e6f25bb93511a415020b583d",
        "source_id": "46916517",
        "content": {
          "text": "You bring up something I've been trying to figure out as well. It feels like AI favors pages that give a direct, honest answer and then makes that answer immediately available. Seemingly plain, readable HTML with no friction preforms well. If the intent is obvious at fetch time, it seems to matter more than how “optimized” the page is. It feels less like SEO and more like “can this page be understood immediately.”\nI feel as if the initial response is basically <div id=\"root\"></div> + a big JS bundle, it feels like you’re betting the crawler will execute it and I’m not convinced they consistently do.\nCurious if you’ve run into that too? Have you seen AI recommendations skew toward SSR/static pages vs client-rendered apps, even when the content is technically “there” once the JS runs? reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:13.501239",
        "updated_at": "2026-02-09T16:19:13.501239",
        "author": {
          "id": "6e70433da4d373f8f115126902263e25",
          "source_id": "nworley",
          "username": "nworley",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "c1194dfc895fa0fed92997b9abce3e4e",
        "source_id": "46914450",
        "content": {
          "text": "Even if I did know, the last thing the world needs is for SEO folks to figure out how to game LLMs if they haven’t already. SEO has made web search unusable and practitioners are the scum of the earth. But more practically like Raymond Chen said, if every app could figure out how to keep their windows always on top, what good would it do?  The same with SEO. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:13.502013",
        "updated_at": "2026-02-09T16:19:13.502013",
        "author": {
          "id": "646941a85e859767254d97ee8f8f4eec",
          "source_id": "raw_anon_1111",
          "username": "raw_anon_1111",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      },
      {
        "id": "52d238df1ecab4e39d3c9ff88384e41f",
        "source_id": "46916863",
        "content": {
          "text": "Right there with you because SEO has evolved to a place that incentivizes a lot of bad behavior, and the end result made search worse for everyone. I’m personally less interested in “gaming” LLMs than understanding what they already do. From my side, this feels closer to observability than optimization when trying to see whether AI systems are even reading or understanding a site, not how to trick them into ranking something low quality. The Raymond Chen analogy brings up something interesting. If everyone forces themselves on top, the signal collapses. My hope is that AI systems end up rewarding genuinely useful, well explained things rather than creating another arms race...but I’m not naive about how incentives tend to play out. A huge concern of mine has been the introduction of ads. Once ads enter LLM responses, it’s hard not to ask whether we’re just rebuilding the same incentive structure that broke search in the first place. reply",
          "format": "text",
          "media": []
        },
        "created_at": "2026-02-09T16:19:13.502815",
        "updated_at": "2026-02-09T16:19:13.502815",
        "author": {
          "id": "6e70433da4d373f8f115126902263e25",
          "source_id": "nworley",
          "username": "nworley",
          "avatar": "",
          "role": "user"
        },
        "parent_id": "",
        "quote_id": "",
        "stats": {
          "likes": 0,
          "dislikes": 0
        },
        "quoted_users": []
      }
    ],
    "metadata": {
      "crawled_at": "2026-02-09T16:19:13.503229",
      "language": "en-US",
      "keywords": [
        "tech",
        "startup",
        "programming",
        "ask",
        "question"
      ],
      "is_nsfw": false
    }
  }
]